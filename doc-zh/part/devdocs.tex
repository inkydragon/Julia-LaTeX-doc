
\part{Developer Documentation}


\hypertarget{10788491312865149564}{}


\chapter{反射 与 自我检查}



Julia 提供了多种运行时的反射功能。



\hypertarget{14842331990094437788}{}


\section{模块绑定}



由 \texttt{Module} 导出的名称可用 \hyperlink{6473328671144201991}{\texttt{names(m::Module)}} 获得，它会返回一个元素为 \hyperlink{18332791376992528422}{\texttt{Symbol}} 的数组来表示模块导出的绑定。不管导出状态如何，\texttt{names(m::Module, all = true)} 返回 \texttt{m} 中所有绑定的符号。



\hypertarget{3191587172542435875}{}


\section{DateType 字段}



\texttt{DataType} 的所有字段名称可以使用 \hyperlink{17481253338332315021}{\texttt{fieldnames}} 来获取。例如，对于下面给定的类型，\texttt{fieldnames(Point)} 会返回一个表示字段名称的 \hyperlink{18332791376992528422}{\texttt{Symbol}} 元组：




\begin{minted}{jlcon}
julia> struct Point
           x::Int
           y
       end

julia> fieldnames(Point)
(:x, :y)
\end{minted}



\texttt{Point} 对象中每个字段的类型存储在 \texttt{Point} 本身的 \texttt{types} 变量中：




\begin{minted}{jlcon}
julia> Point.types
svec(Int64, Any)
\end{minted}



虽然 \texttt{x} 被注释为 \texttt{Int}，但 \texttt{y} 在类型定义里没有注释，因此 \texttt{y} 默认为 \texttt{Any} 类型。



类型本身表示为一个叫做 \texttt{DataType} 的结构：




\begin{minted}{jlcon}
julia> typeof(Point)
DataType
\end{minted}



注意 \texttt{fieldnames(DataType)} 给出了 \texttt{DataType} 本身的每个字段的名称，其中的一个字段是上面示例中提到的 \texttt{types} 字段。



\hypertarget{13277644863207512265}{}


\section{子类型}



任何 \texttt{DataType} 的\emph{直接}子类型都可以通过使用 \hyperlink{13112219412833772146}{\texttt{subtypes}} 来列出。 例如抽象 \texttt{DataType} \hyperlink{11465394427882483091}{\texttt{AbstractFloat}} 有四个（具体的）子类型：




\begin{minted}{jlcon}
julia> subtypes(AbstractFloat)
4-element Array{Any,1}:
 BigFloat
 Float16
 Float32
 Float64
\end{minted}



任何抽象子类型也包括此列表中，但子类型的子类型不在其中。递归使用 \hyperlink{13112219412833772146}{\texttt{subtypes}} 可以遍历出整个类型树。



\hypertarget{7724659828636149961}{}


\section{DataType 布局}



用 C 代码接口时，\texttt{DataType} 的内部表现非常重要。有几个函数可以检查这些细节。



\hyperlink{12980593021531333073}{\texttt{isbits(T::DataType)}} 如果 \texttt{T} 类型是以 C 兼容的对齐方式存储，则为 true。    \hyperlink{6956980533195055227}{\texttt{fieldoffset(T::DataType, i::Integer)}} 返回字段 \emph{i} 相对于类型开始的 (字节) 偏移量。



\hypertarget{15829703883389410283}{}


\section{函数方法}



任何泛型函数的方法都可以使用 \hyperlink{3025953302266245919}{\texttt{methods}} 来列出。用 \hyperlink{1845157398882896709}{\texttt{methodswith}} 搜索 方法调度表 来查找 接收给定类型的方法。



\hypertarget{12369440035598215363}{}


\section{扩展和更底层}



As discussed in the \href{@ref}{Metaprogramming} section, the \hyperlink{8018172489611994488}{\texttt{macroexpand}} function gives the unquoted and interpolated expression (\hyperlink{17120496304147995299}{\texttt{Expr}}) form for a given macro. To use \texttt{macroexpand}, \texttt{quote} the expression block itself (otherwise, the macro will be evaluated and the result will be passed instead!). For example:




\begin{minted}{jlcon}
julia> macroexpand(@__MODULE__, :(@edit println("")) )
:(InteractiveUtils.edit(println, (Base.typesof)("")))
\end{minted}



The functions \texttt{Base.Meta.show\_sexpr} and \hyperlink{15981569052160951906}{\texttt{dump}} are used to display S-expr style views and depth-nested detail views for any expression.



Finally, the \hyperlink{6644553029841096787}{\texttt{Meta.lower}} function gives the \texttt{lowered} form of any expression and is of particular interest for understanding how language constructs map to primitive operations such as assignments, branches, and calls:




\begin{minted}{jlcon}
julia> Meta.lower(@__MODULE__, :( [1+2, sin(0.5)] ))
:($(Expr(:thunk, CodeInfo(
    @ none within `top-level scope'
1 ─ %1 = 1 + 2
│   %2 = sin(0.5)
│   %3 = Base.vect(%1, %2)
└──      return %3
))))
\end{minted}



\hypertarget{12950313890789848047}{}


\section{中间表示和编译后表示}



检查函数的底层形式 需要选择所要显示的特定方法，因为泛型函数可能会有许多具有不同类型签名的方法。为此， 用 \hyperlink{18235967286596219009}{\texttt{code\_lowered}} 可以指定代码底层中的方法。 并且可以用  \hyperlink{14801595959157535515}{\texttt{code\_typed}} 来进行类型推断。 \hyperlink{5565852192659724503}{\texttt{code\_warntype}} 增加 \hyperlink{14801595959157535515}{\texttt{code\_typed}} 输出的高亮。



更加接近于机器， 一个函数的 LLVM-IR 可以通过使用 \hyperlink{1749471484368489435}{\texttt{code\_llvm}} 打印出。 最终编译的机器码使用 \hyperlink{2534314152947301270}{\texttt{code\_native}} 查看（这将触发 之前未调用过的任何函数的 JIT 编译/代码生成）。



为方便起见，上述函数有 宏的版本，它们接受标准函数调用并自动展开参数类型：




\begin{minted}{jlcon}
julia> @code_llvm +(1,1)

define i64 @"julia_+_130862"(i64, i64) {
top:
    %2 = add i64 %1, %0
    ret i64 %2
}
\end{minted}



For more informations see \hyperlink{1376948972689074219}{\texttt{@code\_lowered}}, \hyperlink{6823997547688846780}{\texttt{@code\_typed}}, \hyperlink{8092893264277772840}{\texttt{@code\_warntype}}, \hyperlink{18039596607712979441}{\texttt{@code\_llvm}}, and \hyperlink{2629340111434042067}{\texttt{@code\_native}}.



\hypertarget{4254640328057635583}{}


\subsection{Printing of debug information}



The aforementioned functions and macros take the keyword argument \texttt{debuginfo} that controls the level debug information printed.




\begin{lstlisting}
julia> @code_typed debuginfo=:source +(1,1)
CodeInfo(
    @ int.jl:53 within `+'
1 ─ %1 = Base.add_int(x, y)::Int64
└──      return %1
) => Int64
\end{lstlisting}



Possible values for \texttt{debuginfo} are: \texttt{:none}, \texttt{:source}, and\texttt{:default}. Per default debug information is not printed, but that can be changed by setting \texttt{Base.IRShow.default\_debuginfo[] = :source}.



\chapter{Documentation of Julia's Internals}


\hypertarget{4805065256470472206}{}


\section{Julia 运行时的初始化}



How does the Julia runtime execute \texttt{julia -e {\textquotesingle}println({\textquotedbl}Hello World!{\textquotedbl}){\textquotesingle}} ?



\hypertarget{6651980781302015874}{}


\subsection{\texttt{main()}}



Execution starts at \href{https://github.com/JuliaLang/julia/blob/master/ui/repl.c}{\texttt{main()} in \texttt{ui/repl.c}}.



\texttt{main()} calls \href{https://github.com/JuliaLang/julia/blob/master/src/support/libsupportinit.c}{\texttt{libsupport\_init()}} to set the C library locale and to initialize the {\textquotedbl}ios{\textquotedbl} library (see \href{https://github.com/JuliaLang/julia/blob/master/src/support/ios.c}{\texttt{ios\_init\_stdstreams()}} and \hyperlink{3841537160196121279}{Legacy \texttt{ios.c} library}).



Next \href{https://github.com/JuliaLang/julia/blob/master/src/jloptions.c}{\texttt{jl\_parse\_opts()}} is called to process command line options. Note that \texttt{jl\_parse\_opts()} only deals with options that affect code generation or early initialization. Other options are handled later by \href{https://github.com/JuliaLang/julia/blob/master/base/client.jl}{\texttt{process\_options()} in \texttt{base/client.jl}}.



\texttt{jl\_parse\_opts()} stores command line options in the \href{https://github.com/JuliaLang/julia/blob/master/src/julia.h}{global \texttt{jl\_options} struct}.



\hypertarget{10951200599627901176}{}


\subsection{\texttt{julia\_init()}}



\href{https://github.com/JuliaLang/julia/blob/master/src/task.c}{\texttt{julia\_init()} in \texttt{task.c}} is called by \texttt{main()} and calls \href{https://github.com/JuliaLang/julia/blob/master/src/init.c}{\texttt{\_julia\_init()} in \texttt{init.c}}.



\texttt{\_julia\_init()} begins by calling \texttt{libsupport\_init()} again (it does nothing the second time).



\href{https://github.com/JuliaLang/julia/blob/master/src/signals-unix.c}{\texttt{restore\_signals()}} is called to zero the signal handler mask.



\href{https://github.com/JuliaLang/julia/blob/master/src/init.c}{\texttt{jl\_resolve\_sysimg\_location()}} searches configured paths for the base system image. See \hyperlink{15513456349900674098}{Building the Julia system image}.



\href{https://github.com/JuliaLang/julia/blob/master/src/gc.c}{\texttt{jl\_gc\_init()}} sets up allocation pools and lists for weak refs, preserved values and finalization.



\href{https://github.com/JuliaLang/julia/blob/master/src/ast.c}{\texttt{jl\_init\_frontend()}} loads and initializes a pre-compiled femtolisp image containing the scanner/parser.



\href{https://github.com/JuliaLang/julia/blob/master/src/jltypes.c}{\texttt{jl\_init\_types()}} creates \texttt{jl\_datatype\_t} type description objects for the \href{https://github.com/JuliaLang/julia/blob/master/src/julia.h}{built-in types defined in \texttt{julia.h}}. e.g.




\begin{lstlisting}
jl_any_type = jl_new_abstracttype(jl_symbol("Any"), core, NULL, jl_emptysvec);
jl_any_type->super = jl_any_type;

jl_type_type = jl_new_abstracttype(jl_symbol("Type"), core, jl_any_type, jl_emptysvec);

jl_int32_type = jl_new_primitivetype(jl_symbol("Int32"), core,
                                     jl_any_type, jl_emptysvec, 32);
\end{lstlisting}



\href{https://github.com/JuliaLang/julia/blob/master/src/task.c}{\texttt{jl\_init\_tasks()}} creates the \texttt{jl\_datatype\_t* jl\_task\_type} object; initializes the global \texttt{jl\_root\_task} struct; and sets \texttt{jl\_current\_task} to the root task.



\href{https://github.com/JuliaLang/julia/blob/master/src/codegen.cpp}{\texttt{jl\_init\_codegen()}} initializes the \href{http://llvm.org}{LLVM library}.



\href{https://github.com/JuliaLang/julia/blob/master/src/staticdata.c}{\texttt{jl\_init\_serializer()}} initializes 8-bit serialization tags for builtin \texttt{jl\_value\_t} values.



If there is no sysimg file (\texttt{!jl\_options.image\_file}) then the \texttt{Core} and \texttt{Main} modules are created and \texttt{boot.jl} is evaluated:



\texttt{jl\_core\_module = jl\_new\_module(jl\_symbol({\textquotedbl}Core{\textquotedbl}))} creates the Julia \texttt{Core} module.



\href{https://github.com/JuliaLang/julia/blob/master/src/intrinsics.cpp}{\texttt{jl\_init\_intrinsic\_functions()}} creates a new Julia module \texttt{Intrinsics} containing constant \texttt{jl\_intrinsic\_type} symbols. These define an integer code for each \href{https://github.com/JuliaLang/julia/blob/master/src/intrinsics.cpp}{intrinsic function}. \href{https://github.com/JuliaLang/julia/blob/master/src/intrinsics.cpp}{\texttt{emit\_intrinsic()}} translates these symbols into LLVM instructions during code generation.



\href{https://github.com/JuliaLang/julia/blob/master/src/builtins.c}{\texttt{jl\_init\_primitives()}} hooks C functions up to Julia function symbols. e.g. the symbol \texttt{Core.:(===)()} is bound to C function pointer \texttt{jl\_f\_is()} by calling \texttt{add\_builtin\_func({\textquotedbl}==={\textquotedbl}, jl\_f\_is)}.



\href{https://github.com/JuliaLang/julia/blob/master/src/toplevel.c}{\texttt{jl\_new\_main\_module()}} creates the global {\textquotedbl}Main{\textquotedbl} module and sets \texttt{jl\_current\_task->current\_module = jl\_main\_module}.



Note: \texttt{\_julia\_init()} \href{https://github.com/JuliaLang/julia/blob/master/src/init.c}{then sets} \texttt{jl\_root\_task->current\_module = jl\_core\_module}. \texttt{jl\_root\_task} is an alias of \texttt{jl\_current\_task} at this point, so the \texttt{current\_module} set by \texttt{jl\_new\_main\_module()} above is overwritten.



\href{https://github.com/JuliaLang/julia/blob/master/src/init.c}{\texttt{jl\_load({\textquotedbl}boot.jl{\textquotedbl}, sizeof({\textquotedbl}boot.jl{\textquotedbl}))}} calls \href{https://github.com/JuliaLang/julia/blob/master/src/ast.c}{\texttt{jl\_parse\_eval\_all}} which repeatedly calls \href{https://github.com/JuliaLang/julia/blob/master/src/toplevel.c}{\texttt{jl\_toplevel\_eval\_flex()}} to execute \href{https://github.com/JuliaLang/julia/blob/master/base/boot.jl}{\texttt{boot.jl}}. <!– TODO – drill down into eval? –>



\href{https://github.com/JuliaLang/julia/blob/master/src/init.c}{\texttt{jl\_get\_builtin\_hooks()}} initializes global C pointers to Julia globals defined in \texttt{boot.jl}.



\href{https://github.com/JuliaLang/julia/blob/master/src/datatype.c}{\texttt{jl\_init\_box\_caches()}} pre-allocates global boxed integer value objects for values up to 1024. This speeds up allocation of boxed ints later on. e.g.:




\begin{lstlisting}
jl_value_t *jl_box_uint8(uint32_t x)
{
    return boxed_uint8_cache[(uint8_t)x];
}
\end{lstlisting}



\href{https://github.com/JuliaLang/julia/blob/master/src/init.c}{\texttt{\_julia\_init()} iterates} over the \texttt{jl\_core\_module->bindings.table} looking for \texttt{jl\_datatype\_t} values and sets the type name{\textquotesingle}s module prefix to \texttt{jl\_core\_module}.



\href{https://github.com/JuliaLang/julia/blob/master/src/toplevel.c}{\texttt{jl\_add\_standard\_imports(jl\_main\_module)}} does {\textquotedbl}using Base{\textquotedbl} in the {\textquotedbl}Main{\textquotedbl} module.



Note: \texttt{\_julia\_init()} now reverts to \texttt{jl\_root\_task->current\_module = jl\_main\_module} as it was before being set to \texttt{jl\_core\_module} above.



Platform specific signal handlers are initialized for \texttt{SIGSEGV} (OSX, Linux), and \texttt{SIGFPE} (Windows).



Other signals (\texttt{SIGINFO, SIGBUS, SIGILL, SIGTERM, SIGABRT, SIGQUIT, SIGSYS} and \texttt{SIGPIPE}) are hooked up to \href{https://github.com/JuliaLang/julia/blob/master/src/signals-unix.c}{\texttt{sigdie\_handler()}} which prints a backtrace.



\href{https://github.com/JuliaLang/julia/blob/master/src/staticdata.c}{\texttt{jl\_init\_restored\_modules()}} calls \href{https://github.com/JuliaLang/julia/blob/master/src/module.c}{\texttt{jl\_module\_run\_initializer()}} for each deserialized module to run the \texttt{\_\_init\_\_()} function.



Finally \href{https://github.com/JuliaLang/julia/blob/master/src/signals-unix.c}{\texttt{sigint\_handler()}} is hooked up to \texttt{SIGINT} and calls \texttt{jl\_throw(jl\_interrupt\_exception)}.



\texttt{\_julia\_init()} then returns \href{https://github.com/JuliaLang/julia/blob/master/ui/repl.c}{back to \texttt{main()} in \texttt{ui/repl.c}} and \texttt{main()} calls \texttt{true\_main(argc, (char**)argv)}.



\begin{quote}
\textbf{sysimg}

If there is a sysimg file, it contains a pre-cooked image of the \texttt{Core} and \texttt{Main} modules (and whatever else is created by \texttt{boot.jl}). See \hyperlink{15513456349900674098}{Building the Julia system image}.

\href{https://github.com/JuliaLang/julia/blob/master/src/staticdata.c}{\texttt{jl\_restore\_system\_image()}} deserializes the saved sysimg into the current Julia runtime environment and initialization continues after \texttt{jl\_init\_box\_caches()} below...

Note: \href{https://github.com/JuliaLang/julia/blob/master/src/staticdata.c}{\texttt{jl\_restore\_system\_image()} (and \texttt{staticdata.c} in general)} uses the \hyperlink{3841537160196121279}{Legacy \texttt{ios.c} library}.

\end{quote}


\hypertarget{8052465870854670365}{}


\subsection{\texttt{true\_main()}}



\href{https://github.com/JuliaLang/julia/blob/master/ui/repl.c}{\texttt{true\_main()}} loads the contents of \texttt{argv[]} into \hyperlink{2567473177880607455}{\texttt{Base.ARGS}}.



If a \texttt{.jl} {\textquotedbl}program{\textquotedbl} file was supplied on the command line, then \href{https://github.com/JuliaLang/julia/blob/master/ui/repl.c}{\texttt{exec\_program()}} calls \href{https://github.com/JuliaLang/julia/blob/master/src/toplevel.c}{\texttt{jl\_load(program,len)}} which calls \href{https://github.com/JuliaLang/julia/blob/master/src/ast.c}{\texttt{jl\_parse\_eval\_all}} which repeatedly calls \href{https://github.com/JuliaLang/julia/blob/master/src/toplevel.c}{\texttt{jl\_toplevel\_eval\_flex()}} to execute the program.



However, in our example (\texttt{julia -e {\textquotesingle}println({\textquotedbl}Hello World!{\textquotedbl}){\textquotesingle}}), \href{https://github.com/JuliaLang/julia/blob/master/src/module.c}{\texttt{jl\_get\_global(jl\_base\_module, jl\_symbol({\textquotedbl}\_start{\textquotedbl}))}} looks up \href{https://github.com/JuliaLang/julia/blob/master/base/client.jl}{\texttt{Base.\_start}} and \href{https://github.com/JuliaLang/julia/blob/master/src/julia.h}{\texttt{jl\_apply()}} executes it.



\hypertarget{12561163861893339364}{}


\subsection{\texttt{Base.\_start}}



\href{https://github.com/JuliaLang/julia/blob/master/base/client.jl}{\texttt{Base.\_start}} calls \href{https://github.com/JuliaLang/julia/blob/master/base/client.jl}{\texttt{Base.process\_options}} which calls \href{https://github.com/JuliaLang/julia/blob/master/src/ast.c}{\texttt{jl\_parse\_input\_line({\textquotedbl}println({\textquotedbl}Hello World!{\textquotedbl}){\textquotedbl})}} to create an expression object and \hyperlink{7507639810592563424}{\texttt{Base.eval()}} to execute it.



\hypertarget{5161519074100035363}{}


\subsection{\texttt{Base.eval}}



\hyperlink{7507639810592563424}{\texttt{Base.eval()}} was \href{https://github.com/JuliaLang/julia/blob/master/src/builtins.c}{mapped to \texttt{jl\_f\_top\_eval}} by \texttt{jl\_init\_primitives()}.



\href{https://github.com/JuliaLang/julia/blob/master/src/builtins.c}{\texttt{jl\_f\_top\_eval()}} calls \href{https://github.com/JuliaLang/julia/blob/master/src/builtins.c}{\texttt{jl\_toplevel\_eval\_in(jl\_main\_module, ex)}}, where \texttt{ex} is the parsed expression \texttt{println({\textquotedbl}Hello World!{\textquotedbl})}.



\href{https://github.com/JuliaLang/julia/blob/master/src/builtins.c}{\texttt{jl\_toplevel\_eval\_in()}} calls \href{https://github.com/JuliaLang/julia/blob/master/src/toplevel.c}{\texttt{jl\_toplevel\_eval\_flex()}} which calls \href{https://github.com/JuliaLang/julia/blob/master/src/interpreter.c}{\texttt{eval()} in \texttt{interpreter.c}}.



The stack dump below shows how the interpreter works its way through various methods of \hyperlink{783803254548423222}{\texttt{Base.println()}} and \hyperlink{8248717042415202230}{\texttt{Base.print()}} before arriving at \href{https://github.com/JuliaLang/julia/blob/master/base/stream.jl}{\texttt{write(s::IO, a::Array\{T\}) where T}}  which does \texttt{ccall(jl\_uv\_write())}.



\href{https://github.com/JuliaLang/julia/blob/master/src/jl\_uv.c}{\texttt{jl\_uv\_write()}} calls \texttt{uv\_write()} to write {\textquotedbl}Hello World!{\textquotedbl} to \texttt{JL\_STDOUT}. See \hyperlink{11668969309999094552}{Libuv wrappers for stdio}.:




\begin{lstlisting}
Hello World!
\end{lstlisting}




\begin{table}[h]

\begin{tabulary}{\linewidth}{|L|L|L|}
\hline
Stack frame & Source code & Notes \\
\hline
\texttt{jl\_uv\_write()} & \texttt{jl\_uv.c} & called though \hyperlink{14245046751182637566}{\texttt{ccall}} \\
\hline
\texttt{julia\_write\_282942} & \texttt{stream.jl} & function \texttt{write!(s::IO, a::Array\{T\}) where T} \\
\hline
\texttt{julia\_print\_284639} & \texttt{ascii.jl} & \texttt{print(io::IO, s::String) = (write(io, s); nothing)} \\
\hline
\texttt{jlcall\_print\_284639} &  &  \\
\hline
\texttt{jl\_apply()} & \texttt{julia.h} &  \\
\hline
\texttt{jl\_trampoline()} & \texttt{builtins.c} &  \\
\hline
\texttt{jl\_apply()} & \texttt{julia.h} &  \\
\hline
\texttt{jl\_apply\_generic()} & \texttt{gf.c} & \texttt{Base.print(Base.TTY, String)} \\
\hline
\texttt{jl\_apply()} & \texttt{julia.h} &  \\
\hline
\texttt{jl\_trampoline()} & \texttt{builtins.c} &  \\
\hline
\texttt{jl\_apply()} & \texttt{julia.h} &  \\
\hline
\texttt{jl\_apply\_generic()} & \texttt{gf.c} & \texttt{Base.print(Base.TTY, String, Char, Char...)} \\
\hline
\texttt{jl\_apply()} & \texttt{julia.h} &  \\
\hline
\texttt{jl\_f\_apply()} & \texttt{builtins.c} &  \\
\hline
\texttt{jl\_apply()} & \texttt{julia.h} &  \\
\hline
\texttt{jl\_trampoline()} & \texttt{builtins.c} &  \\
\hline
\texttt{jl\_apply()} & \texttt{julia.h} &  \\
\hline
\texttt{jl\_apply\_generic()} & \texttt{gf.c} & \texttt{Base.println(Base.TTY, String, String...)} \\
\hline
\texttt{jl\_apply()} & \texttt{julia.h} &  \\
\hline
\texttt{jl\_trampoline()} & \texttt{builtins.c} &  \\
\hline
\texttt{jl\_apply()} & \texttt{julia.h} &  \\
\hline
\texttt{jl\_apply\_generic()} & \texttt{gf.c} & \texttt{Base.println(String,)} \\
\hline
\texttt{jl\_apply()} & \texttt{julia.h} &  \\
\hline
\texttt{do\_call()} & \texttt{interpreter.c} &  \\
\hline
\texttt{eval()} & \texttt{interpreter.c} &  \\
\hline
\texttt{jl\_interpret\_toplevel\_expr()} & \texttt{interpreter.c} &  \\
\hline
\texttt{jl\_toplevel\_eval\_flex()} & \texttt{toplevel.c} &  \\
\hline
\texttt{jl\_toplevel\_eval()} & \texttt{toplevel.c} &  \\
\hline
\texttt{jl\_toplevel\_eval\_in()} & \texttt{builtins.c} &  \\
\hline
\texttt{jl\_f\_top\_eval()} & \texttt{builtins.c} &  \\
\hline
\end{tabulary}

\end{table}



Since our example has just one function call, which has done its job of printing {\textquotedbl}Hello World!{\textquotedbl}, the stack now rapidly unwinds back to \texttt{main()}.



\hypertarget{8766302654766843311}{}


\subsection{\texttt{jl\_atexit\_hook()}}



\texttt{main()} calls \href{https://github.com/JuliaLang/julia/blob/master/src/init.c}{\texttt{jl\_atexit\_hook()}}. This calls \texttt{Base.\_atexit}, then calls \href{https://github.com/JuliaLang/julia/blob/master/src/gc.c}{\texttt{jl\_gc\_run\_all\_finalizers()}} and cleans up libuv handles.



\hypertarget{6367994784846959684}{}


\subsection{\texttt{julia\_save()}}



Finally, \texttt{main()} calls \href{https://github.com/JuliaLang/julia/blob/master/src/init.c}{\texttt{julia\_save()}}, which if requested on the command line, saves the runtime state to a new system image. See \href{https://github.com/JuliaLang/julia/blob/master/src/gf.c}{\texttt{jl\_compile\_all()}} and \href{https://github.com/JuliaLang/julia/blob/master/src/staticdata.c}{\texttt{jl\_save\_system\_image()}}.



\hypertarget{13955728449382648563}{}


\section{Julia 的 AST}



Julia 有两种代码的表现形式。 第一种是解析器返回的表面语法 AST （例如 \hyperlink{10422957797582368651}{\texttt{Meta.parse}} 函数），由宏来操控。是代码编写时的结构化表示，由 \texttt{julia-parser.scm} 用字符流构造而成。 另一种则是底层形式，或者 IR（中间表示），这种形式在进行类型推导和代码生成的时候被使用。在这种底层形式中结点的类型相对更少，所有的宏都会被展开，所有的控制流会被转化成显式的分支和语句的序列。底层的形式由 \texttt{julia-syntax.scm} 构建。



First we will focus on the AST, since it is needed to write macros.



\hypertarget{6198433338459689204}{}


\subsection{Surface syntax AST}



Front end ASTs consist almost entirely of \hyperlink{17120496304147995299}{\texttt{Expr}}s and atoms (e.g. symbols, numbers). There is generally a different expression head for each visually distinct syntactic form. Examples will be given in s-expression syntax. Each parenthesized list corresponds to an Expr, where the first element is the head. For example \texttt{(call f x)} corresponds to \texttt{Expr(:call, :f, :x)} in Julia.



\hypertarget{13191950853363974893}{}


\subsubsection{Calls}




\begin{table}[h]

\begin{tabulary}{\linewidth}{|L|L|}
\hline
Input & AST \\
\hline
\texttt{f(x)} & \texttt{(call f x)} \\
\hline
\texttt{f(x, y=1, z=2)} & \texttt{(call f x (kw y 1) (kw z 2))} \\
\hline
\texttt{f(x; y=1)} & \texttt{(call f (parameters (kw y 1)) x)} \\
\hline
\texttt{f(x...)} & \texttt{(call f (... x))} \\
\hline
\end{tabulary}

\end{table}



\texttt{do} syntax:




\begin{minted}{julia}
f(x) do a,b
    body
end
\end{minted}



parses as \texttt{(do (call f x) (-> (tuple a b) (block body)))}.



\hypertarget{16991843071018324380}{}


\subsubsection{Operators}



Most uses of operators are just function calls, so they are parsed with the head \texttt{call}. However some operators are special forms (not necessarily function calls), and in those cases the operator itself is the expression head. In julia-parser.scm these are referred to as {\textquotedbl}syntactic operators{\textquotedbl}. Some operators (\texttt{+} and \texttt{*}) use N-ary parsing; chained calls are parsed as a single N-argument call. Finally, chains of comparisons have their own special expression structure.




\begin{table}[h]

\begin{tabulary}{\linewidth}{|L|L|}
\hline
Input & AST \\
\hline
\texttt{x+y} & \texttt{(call + x y)} \\
\hline
\texttt{a+b+c+d} & \texttt{(call + a b c d)} \\
\hline
\texttt{2x} & \texttt{(call * 2 x)} \\
\hline
\texttt{a\&\&b} & \texttt{(\&\& a b)} \\
\hline
\texttt{x += 1} & \texttt{(+= x 1)} \\
\hline
\texttt{a ? 1 : 2} & \texttt{(if a 1 2)} \\
\hline
\texttt{a:b} & \texttt{(: a b)} \\
\hline
\texttt{a:b:c} & \texttt{(: a b c)} \\
\hline
\texttt{a,b} & \texttt{(tuple a b)} \\
\hline
\texttt{a==b} & \texttt{(call == a b)} \\
\hline
\texttt{1<i<=n} & \texttt{(comparison 1 < i <= n)} \\
\hline
\texttt{a.b} & \texttt{(. a (quote b))} \\
\hline
\texttt{a.(b)} & \texttt{(. a (tuple b))} \\
\hline
\end{tabulary}

\end{table}



\hypertarget{15884526073773577025}{}


\subsubsection{Bracketed forms}




\begin{table}[h]

\begin{tabulary}{\linewidth}{|L|L|}
\hline
Input & AST \\
\hline
\texttt{a[i]} & \texttt{(ref a i)} \\
\hline
\texttt{t[i;j]} & \texttt{(typed\_vcat t i j)} \\
\hline
\texttt{t[i j]} & \texttt{(typed\_hcat t i j)} \\
\hline
\texttt{t[a b; c d]} & \texttt{(typed\_vcat t (row a b) (row c d))} \\
\hline
\texttt{a\{b\}} & \texttt{(curly a b)} \\
\hline
\texttt{a\{b;c\}} & \texttt{(curly a (parameters c) b)} \\
\hline
\texttt{[x]} & \texttt{(vect x)} \\
\hline
\texttt{[x,y]} & \texttt{(vect x y)} \\
\hline
\texttt{[x;y]} & \texttt{(vcat x y)} \\
\hline
\texttt{[x y]} & \texttt{(hcat x y)} \\
\hline
\texttt{[x y; z t]} & \texttt{(vcat (row x y) (row z t))} \\
\hline
\texttt{[x for y in z, a in b]} & \texttt{(comprehension x (= y z) (= a b))} \\
\hline
\texttt{T[x for y in z]} & \texttt{(typed\_comprehension T x (= y z))} \\
\hline
\texttt{(a, b, c)} & \texttt{(tuple a b c)} \\
\hline
\texttt{(a; b; c)} & \texttt{(block a (block b c))} \\
\hline
\end{tabulary}

\end{table}



\hypertarget{7735912728489467540}{}


\subsubsection{Macros}




\begin{table}[h]

\begin{tabulary}{\linewidth}{|L|L|}
\hline
Input & AST \\
\hline
\texttt{@m x y} & \texttt{(macrocall @m (line) x y)} \\
\hline
\texttt{Base.@m x y} & \texttt{(macrocall (. Base (quote @m)) (line) x y)} \\
\hline
\texttt{@Base.m x y} & \texttt{(macrocall (. Base (quote @m)) (line) x y)} \\
\hline
\end{tabulary}

\end{table}



\hypertarget{5278796056388981234}{}


\subsubsection{Strings}




\begin{table}[h]

\begin{tabulary}{\linewidth}{|L|L|}
\hline
Input & AST \\
\hline
\texttt{{\textquotedbl}a{\textquotedbl}} & \texttt{{\textquotedbl}a{\textquotedbl}} \\
\hline
\texttt{x{\textquotedbl}y{\textquotedbl}} & \texttt{(macrocall @x\_str (line) {\textquotedbl}y{\textquotedbl})} \\
\hline
\texttt{x{\textquotedbl}y{\textquotedbl}z} & \texttt{(macrocall @x\_str (line) {\textquotedbl}y{\textquotedbl} {\textquotedbl}z{\textquotedbl})} \\
\hline
\texttt{{\textquotedbl}x = \$x{\textquotedbl}} & \texttt{(string {\textquotedbl}x = {\textquotedbl} x)} \\
\hline
\texttt{`a b c`} & \texttt{(macrocall @cmd (line) {\textquotedbl}a b c{\textquotedbl})} \\
\hline
\end{tabulary}

\end{table}



Doc string syntax:




\begin{minted}{julia}
"some docs"
f(x) = x
\end{minted}



parses as \texttt{(macrocall (|.| Core {\textquotesingle}@doc) (line) {\textquotedbl}some docs{\textquotedbl} (= (call f x) (block x)))}.



\hypertarget{13863161852089184826}{}


\subsubsection{Imports and such}




\begin{table}[h]

\begin{tabulary}{\linewidth}{|L|L|}
\hline
Input & AST \\
\hline
\texttt{import a} & \texttt{(import (. a))} \\
\hline
\texttt{import a.b.c} & \texttt{(import (. a b c))} \\
\hline
\texttt{import ...a} & \texttt{(import (. . . . a))} \\
\hline
\texttt{import a.b, c.d} & \texttt{(import (. a b) (. c d))} \\
\hline
\texttt{import Base: x} & \texttt{(import (: (. Base) (. x)))} \\
\hline
\texttt{import Base: x, y} & \texttt{(import (: (. Base) (. x) (. y)))} \\
\hline
\texttt{export a, b} & \texttt{(export a b)} \\
\hline
\end{tabulary}

\end{table}



\texttt{using} has the same representation as \texttt{import}, but with expression head \texttt{:using} instead of \texttt{:import}.



\hypertarget{13439801024488074381}{}


\subsubsection{Numbers}



Julia supports more number types than many scheme implementations, so not all numbers are represented directly as scheme numbers in the AST.




\begin{table}[h]

\begin{tabulary}{\linewidth}{|L|L|}
\hline
Input & AST \\
\hline
\texttt{11111111111111111111} & \texttt{(macrocall @int128\_str (null) {\textquotedbl}11111111111111111111{\textquotedbl})} \\
\hline
\texttt{0xfffffffffffffffff} & \texttt{(macrocall @uint128\_str (null) {\textquotedbl}0xfffffffffffffffff{\textquotedbl})} \\
\hline
\texttt{1111...many digits...} & \texttt{(macrocall @big\_str (null) {\textquotedbl}1111....{\textquotedbl})} \\
\hline
\end{tabulary}

\end{table}



\hypertarget{12573206411049142153}{}


\subsubsection{Block forms}



A block of statements is parsed as \texttt{(block stmt1 stmt2 ...)}.



If statement:




\begin{minted}{julia}
if a
    b
elseif c
    d
else
    e
end
\end{minted}



parses as:




\begin{lstlisting}
(if a (block (line 2) b)
    (elseif (block (line 3) c) (block (line 4) d)
            (block (line 5 e))))
\end{lstlisting}



A \texttt{while} loop parses as \texttt{(while condition body)}.



A \texttt{for} loop parses as \texttt{(for (= var iter) body)}. If there is more than one iteration specification, they are parsed as a block: \texttt{(for (block (= v1 iter1) (= v2 iter2)) body)}.



\texttt{break} and \texttt{continue} are parsed as 0-argument expressions \texttt{(break)} and \texttt{(continue)}.



\texttt{let} is parsed as \texttt{(let (= var val) body)} or \texttt{(let (block (= var1 val1) (= var2 val2) ...) body)}, like \texttt{for} loops.



A basic function definition is parsed as \texttt{(function (call f x) body)}. A more complex example:




\begin{minted}{julia}
function f(x::T; k = 1) where T
    return x+1
end
\end{minted}



parses as:




\begin{lstlisting}
(function (where (call f (parameters (kw k 1))
                       (:: x T))
                 T)
          (block (line 2) (return (call + x 1))))
\end{lstlisting}



Type definition:




\begin{minted}{julia}
mutable struct Foo{T<:S}
    x::T
end
\end{minted}



parses as:




\begin{lstlisting}
(struct true (curly Foo (<: T S))
        (block (line 2) (:: x T)))
\end{lstlisting}



The first argument is a boolean telling whether the type is mutable.



\texttt{try} blocks parse as \texttt{(try try\_block var catch\_block finally\_block)}. If no variable is present after \texttt{catch}, \texttt{var} is \texttt{\#f}. If there is no \texttt{finally} clause, then the last argument is not present.



\hypertarget{15188092119950048030}{}


\subsubsection{Quote expressions}



Julia source syntax forms for code quoting (\texttt{quote} and \texttt{:( )}) support interpolation with \texttt{\$}. In Lisp terminology, this means they are actually {\textquotedbl}backquote{\textquotedbl} or {\textquotedbl}quasiquote{\textquotedbl} forms. Internally, there is also a need for code quoting without interpolation. In Julia{\textquotesingle}s scheme code, non-interpolating quote is represented with the expression head \texttt{inert}.



\texttt{inert} expressions are converted to Julia \texttt{QuoteNode} objects. These objects wrap a single value of any type, and when evaluated simply return that value.



A \texttt{quote} expression whose argument is an atom also gets converted to a \texttt{QuoteNode}.



\hypertarget{9438599814670899276}{}


\subsubsection{Line numbers}



Source location information is represented as \texttt{(line line\_num file\_name)} where the third component is optional (and omitted when the current line number, but not file name, changes).



These expressions are represented as \texttt{LineNumberNode}s in Julia.



\hypertarget{8143615541033323666}{}


\subsubsection{Macros}



Macro hygiene is represented through the expression head pair \texttt{escape} and \texttt{hygienic-scope}. The result of a macro expansion is automatically wrapped in \texttt{(hygienic-scope block module)}, to represent the result of the new scope. The user can insert \texttt{(escape block)} inside to interpolate code from the caller.



\hypertarget{16818744617880081407}{}


\subsection{Lowered form}



Lowered form (IR) is more important to the compiler, since it is used for type inference, optimizations like inlining, and code generation. It is also less obvious to the human, since it results from a significant rearrangement of the input syntax.



In addition to \texttt{Symbol}s and some number types, the following data types exist in lowered form:



\begin{itemize}
\item \texttt{Expr}

Has a node type indicated by the \texttt{head} field, and an \texttt{args} field which is a \texttt{Vector\{Any\}} of subexpressions. While almost every part of a surface AST is represented by an \texttt{Expr}, the IR uses only a limited number of \texttt{Expr}s, mostly for calls, conditional branches (\texttt{gotoifnot}), and returns.


\item \texttt{Slot}

Identifies arguments and local variables by consecutive numbering. \texttt{Slot} is an abstract type with subtypes \texttt{SlotNumber} and \texttt{TypedSlot}. Both types have an integer-valued \texttt{id} field giving the slot index. Most slots have the same type at all uses, and so are represented with \texttt{SlotNumber}. The types of these slots are found in the \texttt{slottypes} field of their \texttt{MethodInstance} object. Slots that require per-use type annotations are represented with \texttt{TypedSlot}, which has a \texttt{typ} field.


\item \texttt{CodeInfo}

Wraps the IR of a group of statements. Its \texttt{code} field is an array of expressions to execute.


\item \texttt{GotoNode}

Unconditional branch. The argument is the branch target, represented as an index in the code array to jump to.


\item \texttt{QuoteNode}

Wraps an arbitrary value to reference as data. For example, the function \texttt{f() = :a} contains a \texttt{QuoteNode} whose \texttt{value} field is the symbol \texttt{a}, in order to return the symbol itself instead of evaluating it.


\item \texttt{GlobalRef}

Refers to global variable \texttt{name} in module \texttt{mod}.


\item \texttt{SSAValue}

Refers to a consecutively-numbered (starting at 1) static single assignment (SSA) variable inserted by the compiler. The number (\texttt{id}) of an \texttt{SSAValue} is the code array index of the expression whose value it represents.


\item \texttt{NewvarNode}

Marks a point where a variable (slot) is created. This has the effect of resetting a variable to undefined.

\end{itemize}


\hypertarget{15302433068188215381}{}


\subsubsection{\texttt{Expr} types}



These symbols appear in the \texttt{head} field of \hyperlink{17120496304147995299}{\texttt{Expr}}s in lowered form.



\begin{itemize}
\item \texttt{call}

Function call (dynamic dispatch). \texttt{args[1]} is the function to call, \texttt{args[2:end]} are the arguments.


\item \texttt{invoke}

Function call (static dispatch). \texttt{args[1]} is the MethodInstance to call, \texttt{args[2:end]} are the arguments (including the function that is being called, at \texttt{args[2]}).


\item \texttt{static\_parameter}

Reference a static parameter by index.


\item \texttt{gotoifnot}

Conditional branch. If \texttt{args[1]} is false, goes to the index identified in \texttt{args[2]}.


\item \texttt{=}

Assignment. In the IR, the first argument is always a Slot or a GlobalRef.


\item \texttt{method}

Adds a method to a generic function and assigns the result if necessary.

Has a 1-argument form and a 3-argument form. The 1-argument form arises from the syntax \texttt{function foo end}. In the 1-argument form, the argument is a symbol. If this symbol already names a function in the current scope, nothing happens. If the symbol is undefined, a new function is created and assigned to the identifier specified by the symbol. If the symbol is defined but names a non-function, an error is raised. The definition of {\textquotedbl}names a function{\textquotedbl} is that the binding is constant, and refers to an object of singleton type. The rationale for this is that an instance of a singleton type uniquely identifies the type to add the method to. When the type has fields, it wouldn{\textquotesingle}t be clear whether the method was being added to the instance or its type.

The 3-argument form has the following arguments:

\begin{itemize}
\item \texttt{args[1]}

A function name, or \texttt{false} if unknown. If a symbol, then the expression first behaves like the 1-argument form above. This argument is ignored from then on. When this is \texttt{false}, it means a method is being added strictly by type, \texttt{(::T)(x) = x}.


\item \texttt{args[2]}

A \texttt{SimpleVector} of argument type data. \texttt{args[2][1]} is a \texttt{SimpleVector} of the argument types, and \texttt{args[2][2]} is a \texttt{SimpleVector} of type variables corresponding to the method{\textquotesingle}s static parameters.


\item \texttt{args[3]}

A \texttt{CodeInfo} of the method itself. For {\textquotedbl}out of scope{\textquotedbl} method definitions (adding a method to a function that also has methods defined in different scopes) this is an expression that evaluates to a \texttt{:lambda} expression.

\end{itemize}

\item \texttt{struct\_type}

A 7-argument expression that defines a new \texttt{struct}:

\begin{itemize}
\item \texttt{args[1]}

The name of the \texttt{struct}


\item \texttt{args[2]}

A \texttt{call} expression that creates a \texttt{SimpleVector} specifying its parameters


\item \texttt{args[3]}

A \texttt{call} expression that creates a \texttt{SimpleVector} specifying its fieldnames


\item \texttt{args[4]}

A \texttt{Symbol}, \texttt{GlobalRef}, or \texttt{Expr} specifying the supertype (e.g., \texttt{:Integer}, \texttt{GlobalRef(Core, :Any)}, or \texttt{:(Core.apply\_type(AbstractArray, T, N))})


\item \texttt{args[5]}

A \texttt{call} expression that creates a \texttt{SimpleVector} specifying its fieldtypes


\item \texttt{args[6]}

A Bool, true if \texttt{mutable}


\item \texttt{args[7]}

The number of arguments to initialize. This will be the number of fields, or the minimum number of fields called by an inner constructor{\textquotesingle}s \texttt{new} statement.

\end{itemize}

\item \texttt{abstract\_type}

A 3-argument expression that defines a new abstract type. The arguments are the same as arguments 1, 2, and 4 of \texttt{struct\_type} expressions.


\item \texttt{primitive\_type}

A 4-argument expression that defines a new primitive type. Arguments 1, 2, and 4 are the same as \texttt{struct\_type}. Argument 3 is the number of bits.

\begin{quote}
\textbf{Julia 1.5}

\texttt{struct\_type}, \texttt{abstract\_type}, and \texttt{primitive\_type} were removed in Julia 1.5 and replaced by calls to new builtins.

\end{quote}

\item \texttt{global}

Declares a global binding.


\item \texttt{const}

Declares a (global) variable as constant.


\item \texttt{new}

Allocates a new struct-like object. First argument is the type. The \hyperlink{13888762393600028594}{\texttt{new}} pseudo-function is lowered to this, and the type is always inserted by the compiler.  This is very much an internal-only feature, and does no checking. Evaluating arbitrary \texttt{new} expressions can easily segfault.


\item \texttt{splatnew}

Similar to \texttt{new}, except field values are passed as a single tuple. Works similarly to \texttt{Base.splat(new)} if \texttt{new} were a first-class function, hence the name.


\item \texttt{return}

Returns its argument as the value of the enclosing function.


\item \texttt{isdefined}

\texttt{Expr(:isdefined, :x)} returns a Bool indicating whether \texttt{x} has already been defined in the current scope.


\item \texttt{the\_exception}

Yields the caught exception inside a \texttt{catch} block, as returned by \texttt{jl\_current\_exception()}.


\item \texttt{enter}

Enters an exception handler (\texttt{setjmp}). \texttt{args[1]} is the label of the catch block to jump to on error.  Yields a token which is consumed by \texttt{pop\_exception}.


\item \texttt{leave}

Pop exception handlers. \texttt{args[1]} is the number of handlers to pop.


\item \texttt{pop\_exception}

Pop the stack of current exceptions back to the state at the associated \texttt{enter} when leaving a catch block. \texttt{args[1]} contains the token from the associated \texttt{enter}.

\begin{quote}
\textbf{Julia 1.1}

\texttt{pop\_exception} is new in Julia 1.1.

\end{quote}

\item \texttt{inbounds}

Controls turning bounds checks on or off. A stack is maintained; if the first argument of this expression is true or false (\texttt{true} means bounds checks are disabled), it is pushed onto the stack. If the first argument is \texttt{:pop}, the stack is popped.


\item \texttt{boundscheck}

Has the value \texttt{false} if inlined into a section of code marked with \texttt{@inbounds}, otherwise has the value \texttt{true}.


\item \texttt{loopinfo}

Marks the end of the a loop. Contains metadata that is passed to \texttt{LowerSimdLoop} to either mark the inner loop of \texttt{@simd} expression, or to propagate information to LLVM loop passes.


\item \texttt{copyast}

Part of the implementation of quasi-quote. The argument is a surface syntax AST that is simply copied recursively and returned at run time.


\item \texttt{meta}

Metadata. \texttt{args[1]} is typically a symbol specifying the kind of metadata, and the rest of the arguments are free-form. The following kinds of metadata are commonly used:

\begin{itemize}
\item \texttt{:inline} and \texttt{:noinline}: Inlining hints.

\end{itemize}

\item \texttt{foreigncall}

Statically-computed container for \texttt{ccall} information. The fields are:

\begin{itemize}
\item \texttt{args[1]} : name

The expression that{\textquotesingle}ll be parsed for the foreign function.


\item \texttt{args[2]::Type} : RT

The (literal) return type, computed statically when the containing method was defined.


\item \texttt{args[3]::SimpleVector} (of Types) : AT

The (literal) vector of argument types, computed statically when the containing method was defined.


\item \texttt{args[4]::Int} : nreq

The number of required arguments for a varargs function definition.


\item \texttt{args[5]::QuoteNode\{Symbol\}} : calling convention

The calling convention for the call.


\item \texttt{args[6:length(args[3])]} : arguments

The values for all the arguments (with types of each given in args[3]).


\item \texttt{args[(length(args[3]) + 1):end]} : gc-roots

The additional objects that may need to be gc-rooted for the duration of the call. See \hyperlink{16487312531471662451}{Working with LLVM} for where these are derived from and how they get handled.

\end{itemize}
\end{itemize}


\hypertarget{10862348325946528961}{}


\subsubsection{Method}



A unique{\textquotesingle}d container describing the shared metadata for a single method.



\begin{itemize}
\item \texttt{name}, \texttt{module}, \texttt{file}, \texttt{line}, \texttt{sig}

Metadata to uniquely identify the method for the computer and the human.


\item \texttt{ambig}

Cache of other methods that may be ambiguous with this one.


\item \texttt{specializations}

Cache of all MethodInstance ever created for this Method, used to ensure uniqueness. Uniqueness is required for efficiency, especially for incremental precompile and tracking of method invalidation.


\item \texttt{source}

The original source code (if available, usually compressed).


\item \texttt{generator}

A callable object which can be executed to get specialized source for a specific method signature.


\item \texttt{roots}

Pointers to non-AST things that have been interpolated into the AST, required by compression of the AST, type-inference, or the generation of native code.


\item \texttt{nargs}, \texttt{isva}, \texttt{called}, \texttt{isstaged}, \texttt{pure}

Descriptive bit-fields for the source code of this Method.


\item \texttt{primary\_world}

The world age that {\textquotedbl}owns{\textquotedbl} this Method.

\end{itemize}


\hypertarget{2584833319372808594}{}


\subsubsection{MethodInstance}



A unique{\textquotesingle}d container describing a single callable signature for a Method. See especially \hyperlink{17047801949293328593}{Proper maintenance and care of multi-threading locks} for important details on how to modify these fields safely.



\begin{itemize}
\item \texttt{specTypes}

The primary key for this MethodInstance. Uniqueness is guaranteed through a \texttt{def.specializations} lookup.


\item \texttt{def}

The \texttt{Method} that this function describes a specialization of. Or a \texttt{Module}, if this is a top-level Lambda expanded in Module, and which is not part of a Method.


\item \texttt{sparam\_vals}

The values of the static parameters in \texttt{specTypes} indexed by \texttt{def.sparam\_syms}. For the \texttt{MethodInstance} at \texttt{Method.unspecialized}, this is the empty \texttt{SimpleVector}. But for a runtime \texttt{MethodInstance} from the \texttt{MethodTable} cache, this will always be defined and indexable.


\item \texttt{uninferred}

The uncompressed source code for a toplevel thunk. Additionally, for a generated function, this is one of many places that the source code might be found.


\item \texttt{backedges}

We store the reverse-list of cache dependencies for efficient tracking of incremental reanalysis/recompilation work that may be needed after a new method definitions. This works by keeping a list of the other \texttt{MethodInstance} that have been inferred or optimized to contain a possible call to this \texttt{MethodInstance}. Those optimization results might be stored somewhere in the \texttt{cache}, or it might have been the result of something we didn{\textquotesingle}t want to cache, such as constant propagation. Thus we merge all of those backedges to various cache entries here (there{\textquotesingle}s almost always only the one applicable cache entry with a sentinal value for max\_world anyways).


\item \texttt{cache}

Cache of \texttt{CodeInstance} objects that share this template instantiation.

\end{itemize}


\hypertarget{17684444820224515276}{}


\subsubsection{CodeInstance}



\begin{itemize}
\item \texttt{def}

The \texttt{MethodInstance} that this cache entry is derived from.

\end{itemize}


\begin{itemize}
\item \texttt{rettype}/\texttt{rettype\_const}

The inferred return type for the \texttt{specFunctionObject} field, which (in most cases) is also the computed return type for the function in general.


\item \texttt{inferred}

May contain a cache of the inferred source for this function, or it could be set to \texttt{nothing} to just indicate \texttt{rettype} is inferred.


\item \texttt{ftpr}

The generic jlcall entry point.


\item \texttt{jlcall\_api}

The ABI to use when calling \texttt{fptr}. Some significant ones include:

\begin{itemize}
\item 0 - Not compiled yet


\item 1 - JL\emph{CALLABLE `jl}value\emph{t \emph{(})(jl}function\emph{t *f, jl}value\emph{t *args[nargs], uint32}t nargs)`


\item 2 - Constant (value stored in \texttt{rettype\_const})


\item 3 - With Static-parameters forwarded \texttt{jl\_value\_t *(*)(jl\_svec\_t *sparams, jl\_function\_t *f, jl\_value\_t *args[nargs], uint32\_t nargs)}


\item 4 - Run in interpreter \texttt{jl\_value\_t *(*)(jl\_method\_instance\_t *meth, jl\_function\_t *f, jl\_value\_t *args[nargs], uint32\_t nargs)}

\end{itemize}

\item \texttt{min\_world} / \texttt{max\_world}

The range of world ages for which this method instance is valid to be called. If max\_world is the special token value \texttt{-1}, the value is not yet known. It may continue to be used until we encounter a backedge that requires us to reconsider.

\end{itemize}


\hypertarget{15595975163128328315}{}


\subsubsection{CodeInfo}



A (usually temporary) container for holding lowered source code.



\begin{itemize}
\item \texttt{code}

An \texttt{Any} array of statements


\item \texttt{slotnames}

An array of symbols giving names for each slot (argument or local variable).


\item \texttt{slotflags}

A \texttt{UInt8} array of slot properties, represented as bit flags:

\begin{itemize}
\item 2  - assigned (only false if there are \emph{no} assignment statements with this var on the left)


\item 8  - const (currently unused for local variables)


\item 16 - statically assigned once


\item 32 - might be used before assigned. This flag is only valid after type inference.

\end{itemize}

\item \texttt{ssavaluetypes}

Either an array or an \texttt{Int}.

If an \texttt{Int}, it gives the number of compiler-inserted temporary locations in the function (the length of \texttt{code} array). If an array, specifies a type for each location.


\item \texttt{ssaflags}

Statement-level flags for each expression in the function. Many of these are reserved, but not yet implemented:

\begin{itemize}
\item 0 = inbounds


\item 1,2 = <reserved> inlinehint,always-inline,noinline


\item 3 = <reserved> strict-ieee (strictfp)


\item 4-6 = <unused>


\item 7 = <reserved> has out-of-band info

\end{itemize}

\item \texttt{linetable}

An array of source location objects


\item \texttt{codelocs}

An array of integer indices into the \texttt{linetable}, giving the location associated with each statement.

\end{itemize}


Optional Fields:



\begin{itemize}
\item \texttt{slottypes}

An array of types for the slots.


\item \texttt{rettype}

The inferred return type of the lowered form (IR). Default value is \texttt{Any}.


\item \texttt{method\_for\_inference\_limit\_heuristics}

The \texttt{method\_for\_inference\_heuristics} will expand the given method{\textquotesingle}s generator if necessary during inference.


\item \texttt{parent}

The \texttt{MethodInstance} that {\textquotedbl}owns{\textquotedbl} this object (if applicable).


\item \texttt{min\_world}/\texttt{max\_world}

The range of world ages for which this code was valid at the time when it had been inferred.

\end{itemize}


Boolean properties:



\begin{itemize}
\item \texttt{inferred}

Whether this has been produced by type inference.


\item \texttt{inlineable}

Whether this should be eligible for inlining.


\item \texttt{propagate\_inbounds}

Whether this should propagate \texttt{@inbounds} when inlined for the purpose of eliding \texttt{@boundscheck} blocks.


\item \texttt{pure}

Whether this is known to be a pure function of its arguments, without respect to the state of the method caches or other mutable global state.

\end{itemize}


\hypertarget{4038509094133832716}{}


\section{More about types}



If you{\textquotesingle}ve used Julia for a while, you understand the fundamental role that types play.  Here we try to get under the hood, focusing particularly on \href{@ref}{Parametric Types}.



\hypertarget{8213772846516553388}{}


\subsection{Types and sets (and \texttt{Any} and \texttt{Union\{\}}/\texttt{Bottom})}



It{\textquotesingle}s perhaps easiest to conceive of Julia{\textquotesingle}s type system in terms of sets. While programs manipulate individual values, a type refers to a set of values. This is not the same thing as a collection; for example a \hyperlink{1143189053501747033}{\texttt{Set}} of values is itself a single \texttt{Set} value. Rather, a type describes a set of \emph{possible} values, expressing uncertainty about which value we have.



A \emph{concrete} type \texttt{T} describes the set of values whose direct tag, as returned by the \hyperlink{13440452181855594120}{\texttt{typeof}} function, is \texttt{T}. An \emph{abstract} type describes some possibly-larger set of values.



\hyperlink{15014186392807667022}{\texttt{Any}} describes the entire universe of possible values. \hyperlink{8469131683393450448}{\texttt{Integer}} is a subset of \texttt{Any} that includes \texttt{Int}, \hyperlink{5857518405103968275}{\texttt{Int8}}, and other concrete types. Internally, Julia also makes heavy use of another type known as \texttt{Bottom}, which can also be written as \texttt{Union\{\}}. This corresponds to the empty set.



Julia{\textquotesingle}s types support the standard operations of set theory: you can ask whether \texttt{T1} is a {\textquotedbl}subset{\textquotedbl} (subtype) of \texttt{T2} with \texttt{T1 <: T2}. Likewise, you intersect two types using \hyperlink{1869272868531275554}{\texttt{typeintersect}}, take their union with \hyperlink{5087820771052303592}{\texttt{Union}}, and compute a type that contains their union with \hyperlink{6895589781245489183}{\texttt{typejoin}}:




\begin{minted}{jlcon}
julia> typeintersect(Int, Float64)
Union{}

julia> Union{Int, Float64}
Union{Float64, Int64}

julia> typejoin(Int, Float64)
Real

julia> typeintersect(Signed, Union{UInt8, Int8})
Int8

julia> Union{Signed, Union{UInt8, Int8}}
Union{UInt8, Signed}

julia> typejoin(Signed, Union{UInt8, Int8})
Integer

julia> typeintersect(Tuple{Integer,Float64}, Tuple{Int,Real})
Tuple{Int64,Float64}

julia> Union{Tuple{Integer,Float64}, Tuple{Int,Real}}
Union{Tuple{Int64,Real}, Tuple{Integer,Float64}}

julia> typejoin(Tuple{Integer,Float64}, Tuple{Int,Real})
Tuple{Integer,Real}
\end{minted}



While these operations may seem abstract, they lie at the heart of Julia.  For example, method dispatch is implemented by stepping through the items in a method list until reaching one for which the type of the argument tuple is a subtype of the method signature. For this algorithm to work, it{\textquotesingle}s important that methods be sorted by their specificity, and that the search begins with the most specific methods. Consequently, Julia also implements a partial order on types; this is achieved by functionality that is similar to \texttt{<:}, but with differences that will be discussed below.



\hypertarget{11911810306869937851}{}


\subsection{UnionAll types}



Julia{\textquotesingle}s type system can also express an \emph{iterated union} of types: a union of types over all values of some variable. This is needed to describe parametric types where the values of some parameters are not known.



For example, \hyperlink{15492651498431872487}{\texttt{Array}} has two parameters as in \texttt{Array\{Int,2\}}. If we did not know the element type, we could write \texttt{Array\{T,2\} where T}, which is the union of \texttt{Array\{T,2\}} for all values of \texttt{T}: \texttt{Union\{Array\{Int8,2\}, Array\{Int16,2\}, ...\}}.



Such a type is represented by a \texttt{UnionAll} object, which contains a variable (\texttt{T} in this example, of type \texttt{TypeVar}), and a wrapped type (\texttt{Array\{T,2\}} in this example).



Consider the following methods:




\begin{minted}{julia}
f1(A::Array) = 1
f2(A::Array{Int}) = 2
f3(A::Array{T}) where {T<:Any} = 3
f4(A::Array{Any}) = 4
\end{minted}



The signature - as described in \href{@ref}{Function calls} - of \texttt{f3} is a \texttt{UnionAll} type wrapping a tuple type: \texttt{Tuple\{typeof(f3), Array\{T\}\} where T}. All but \texttt{f4} can be called with \texttt{a = [1,2]}; all but \texttt{f2} can be called with \texttt{b = Any[1,2]}.



Let{\textquotesingle}s look at these types a little more closely:




\begin{minted}{jlcon}
julia> dump(Array)
UnionAll
  var: TypeVar
    name: Symbol T
    lb: Union{}
    ub: Any
  body: UnionAll
    var: TypeVar
      name: Symbol N
      lb: Union{}
      ub: Any
    body: Array{T,N} <: DenseArray{T,N}
\end{minted}



This indicates that \texttt{Array} actually names a \texttt{UnionAll} type. There is one \texttt{UnionAll} type for each parameter, nested. The syntax \texttt{Array\{Int,2\}} is equivalent to \texttt{Array\{Int\}\{2\}}; internally each \texttt{UnionAll} is instantiated with a particular variable value, one at a time, outermost-first. This gives a natural meaning to the omission of trailing type parameters; \texttt{Array\{Int\}} gives a type equivalent to \texttt{Array\{Int,N\} where N}.



A \texttt{TypeVar} is not itself a type, but rather should be considered part of the structure of a \texttt{UnionAll} type. Type variables have lower and upper bounds on their values (in the fields \texttt{lb} and \texttt{ub}). The symbol \texttt{name} is purely cosmetic. Internally, \texttt{TypeVar}s are compared by address, so they are defined as mutable types to ensure that {\textquotedbl}different{\textquotedbl} type variables can be distinguished. However, by convention they should not be mutated.



One can construct \texttt{TypeVar}s manually:




\begin{minted}{jlcon}
julia> TypeVar(:V, Signed, Real)
Signed<:V<:Real
\end{minted}



There are convenience versions that allow you to omit any of these arguments except the \texttt{name} symbol.



The syntax \texttt{Array\{T\} where T<:Integer} is lowered to




\begin{minted}{julia}
let T = TypeVar(:T,Integer)
    UnionAll(T, Array{T})
end
\end{minted}



so it is seldom necessary to construct a \texttt{TypeVar} manually (indeed, this is to be avoided).



\hypertarget{10862279169779752699}{}


\subsection{Free variables}



The concept of a \emph{free} type variable is extremely important in the type system. We say that a variable \texttt{V} is free in type \texttt{T} if \texttt{T} does not contain the \texttt{UnionAll} that introduces variable \texttt{V}. For example, the type \texttt{Array\{Array\{V\} where V<:Integer\}} has no free variables, but the \texttt{Array\{V\}} part inside of it does have a free variable, \texttt{V}.



A type with free variables is, in some sense, not really a type at all. Consider the type \texttt{Array\{Array\{T\}\} where T}, which refers to all homogeneous arrays of arrays. The inner type \texttt{Array\{T\}}, seen by itself, might seem to refer to any kind of array. However, every element of the outer array must have the \emph{same} array type, so \texttt{Array\{T\}} cannot refer to just any old array. One could say that \texttt{Array\{T\}} effectively {\textquotedbl}occurs{\textquotedbl} multiple times, and \texttt{T} must have the same value each {\textquotedbl}time{\textquotedbl}.



For this reason, the function \texttt{jl\_has\_free\_typevars} in the C API is very important. Types for which it returns true will not give meaningful answers in subtyping and other type functions.



\hypertarget{9475610527503799038}{}


\subsection{TypeNames}



The following two \hyperlink{15492651498431872487}{\texttt{Array}} types are functionally equivalent, yet print differently:




\begin{minted}{jlcon}
julia> TV, NV = TypeVar(:T), TypeVar(:N)
(T, N)

julia> Array
Array

julia> Array{TV,NV}
Array{T,N}
\end{minted}



These can be distinguished by examining the \texttt{name} field of the type, which is an object of type \texttt{TypeName}:




\begin{minted}{jlcon}
julia> dump(Array{Int,1}.name)
TypeName
  name: Symbol Array
  module: Module Core
  names: empty SimpleVector
  wrapper: UnionAll
    var: TypeVar
      name: Symbol T
      lb: Union{}
      ub: Any
    body: UnionAll
      var: TypeVar
        name: Symbol N
        lb: Union{}
        ub: Any
      body: Array{T,N} <: DenseArray{T,N}
  cache: SimpleVector
    ...

  linearcache: SimpleVector
    ...

  hash: Int64 -7900426068641098781
  mt: MethodTable
    name: Symbol Array
    defs: Nothing nothing
    cache: Nothing nothing
    max_args: Int64 0
    kwsorter: #undef
    module: Module Core
    : Int64 0
    : Int64 0
\end{minted}



In this case, the relevant field is \texttt{wrapper}, which holds a reference to the top-level type used to make new \texttt{Array} types.




\begin{minted}{jlcon}
julia> pointer_from_objref(Array)
Ptr{Cvoid} @0x00007fcc7de64850

julia> pointer_from_objref(Array.body.body.name.wrapper)
Ptr{Cvoid} @0x00007fcc7de64850

julia> pointer_from_objref(Array{TV,NV})
Ptr{Cvoid} @0x00007fcc80c4d930

julia> pointer_from_objref(Array{TV,NV}.name.wrapper)
Ptr{Cvoid} @0x00007fcc7de64850
\end{minted}



The \texttt{wrapper} field of \hyperlink{15492651498431872487}{\texttt{Array}} points to itself, but for \texttt{Array\{TV,NV\}} it points back to the original definition of the type.



What about the other fields? \texttt{hash} assigns an integer to each type.  To examine the \texttt{cache} field, it{\textquotesingle}s helpful to pick a type that is less heavily used than Array. Let{\textquotesingle}s first create our own type:




\begin{minted}{jlcon}
julia> struct MyType{T,N} end

julia> MyType{Int,2}
MyType{Int64,2}

julia> MyType{Float32, 5}
MyType{Float32,5}
\end{minted}



When you instantiate a parametric type, each concrete type gets saved in a type cache (\texttt{MyType.body.body.name.cache}). However, instances containing free type variables are not cached.



\hypertarget{15137612054834825471}{}


\subsection{Tuple types}



Tuple types constitute an interesting special case.  For dispatch to work on declarations like \texttt{x::Tuple}, the type has to be able to accommodate any tuple.  Let{\textquotesingle}s check the parameters:




\begin{minted}{jlcon}
julia> Tuple
Tuple

julia> Tuple.parameters
svec(Vararg{Any,N} where N)
\end{minted}



Unlike other types, tuple types are covariant in their parameters, so this definition permits \texttt{Tuple} to match any type of tuple:




\begin{minted}{jlcon}
julia> typeintersect(Tuple, Tuple{Int,Float64})
Tuple{Int64,Float64}

julia> typeintersect(Tuple{Vararg{Any}}, Tuple{Int,Float64})
Tuple{Int64,Float64}
\end{minted}



However, if a variadic (\texttt{Vararg}) tuple type has free variables it can describe different kinds of tuples:




\begin{minted}{jlcon}
julia> typeintersect(Tuple{Vararg{T} where T}, Tuple{Int,Float64})
Tuple{Int64,Float64}

julia> typeintersect(Tuple{Vararg{T}} where T, Tuple{Int,Float64})
Union{}
\end{minted}



Notice that when \texttt{T} is free with respect to the \texttt{Tuple} type (i.e. its binding \texttt{UnionAll} type is outside the \texttt{Tuple} type), only one \texttt{T} value must work over the whole type. Therefore a heterogeneous tuple does not match.



Finally, it{\textquotesingle}s worth noting that \texttt{Tuple\{\}} is distinct:




\begin{minted}{jlcon}
julia> Tuple{}
Tuple{}

julia> Tuple{}.parameters
svec()

julia> typeintersect(Tuple{}, Tuple{Int})
Union{}
\end{minted}



What is the {\textquotedbl}primary{\textquotedbl} tuple-type?




\begin{minted}{jlcon}
julia> pointer_from_objref(Tuple)
Ptr{Cvoid} @0x00007f5998a04370

julia> pointer_from_objref(Tuple{})
Ptr{Cvoid} @0x00007f5998a570d0

julia> pointer_from_objref(Tuple.name.wrapper)
Ptr{Cvoid} @0x00007f5998a04370

julia> pointer_from_objref(Tuple{}.name.wrapper)
Ptr{Cvoid} @0x00007f5998a04370
\end{minted}



so \texttt{Tuple == Tuple\{Vararg\{Any\}\}} is indeed the primary type.



\hypertarget{5206945150982308765}{}


\subsection{Diagonal types}



Consider the type \texttt{Tuple\{T,T\} where T}. A method with this signature would look like:




\begin{minted}{julia}
f(x::T, y::T) where {T} = ...
\end{minted}



According to the usual interpretation of a \texttt{UnionAll} type, this \texttt{T} ranges over all types, including \texttt{Any}, so this type should be equivalent to \texttt{Tuple\{Any,Any\}}. However, this interpretation causes some practical problems.



First, a value of \texttt{T} needs to be available inside the method definition. For a call like \texttt{f(1, 1.0)}, it{\textquotesingle}s not clear what \texttt{T} should be. It could be \texttt{Union\{Int,Float64\}}, or perhaps \hyperlink{6175959395021454412}{\texttt{Real}}. Intuitively, we expect the declaration \texttt{x::T} to mean \texttt{T === typeof(x)}. To make sure that invariant holds, we need \texttt{typeof(x) === typeof(y) === T} in this method. That implies the method should only be called for arguments of the exact same type.



It turns out that being able to dispatch on whether two values have the same type is very useful (this is used by the promotion system for example), so we have multiple reasons to want a different interpretation of \texttt{Tuple\{T,T\} where T}. To make this work we add the following rule to subtyping: if a variable occurs more than once in covariant position, it is restricted to ranging over only concrete types. ({\textquotedbl}Covariant position{\textquotedbl} means that only \texttt{Tuple} and \texttt{Union} types occur between an occurrence of a variable and the \texttt{UnionAll} type that introduces it.) Such variables are called {\textquotedbl}diagonal variables{\textquotedbl} or {\textquotedbl}concrete variables{\textquotedbl}.



So for example, \texttt{Tuple\{T,T\} where T} can be seen as \texttt{Union\{Tuple\{Int8,Int8\}, Tuple\{Int16,Int16\}, ...\}}, where \texttt{T} ranges over all concrete types. This gives rise to some interesting subtyping results. For example \texttt{Tuple\{Real,Real\}} is not a subtype of \texttt{Tuple\{T,T\} where T}, because it includes some types like \texttt{Tuple\{Int8,Int16\}} where the two elements have different types. \texttt{Tuple\{Real,Real\}} and \texttt{Tuple\{T,T\} where T} have the non-trivial intersection \texttt{Tuple\{T,T\} where T<:Real}. However, \texttt{Tuple\{Real\}} \emph{is} a subtype of \texttt{Tuple\{T\} where T}, because in that case \texttt{T} occurs only once and so is not diagonal.



Next consider a signature like the following:




\begin{minted}{julia}
f(a::Array{T}, x::T, y::T) where {T} = ...
\end{minted}



In this case, \texttt{T} occurs in invariant position inside \texttt{Array\{T\}}. That means whatever type of array is passed unambiguously determines the value of \texttt{T} – we say \texttt{T} has an \emph{equality constraint} on it. Therefore in this case the diagonal rule is not really necessary, since the array determines \texttt{T} and we can then allow \texttt{x} and \texttt{y} to be of any subtypes of \texttt{T}. So variables that occur in invariant position are never considered diagonal. This choice of behavior is slightly controversial –- some feel this definition should be written as




\begin{minted}{julia}
f(a::Array{T}, x::S, y::S) where {T, S<:T} = ...
\end{minted}



to clarify whether \texttt{x} and \texttt{y} need to have the same type. In this version of the signature they would, or we could introduce a third variable for the type of \texttt{y} if \texttt{x} and \texttt{y} can have different types.



The next complication is the interaction of unions and diagonal variables, e.g.




\begin{minted}{julia}
f(x::Union{Nothing,T}, y::T) where {T} = ...
\end{minted}



Consider what this declaration means. \texttt{y} has type \texttt{T}. \texttt{x} then can have either the same type \texttt{T}, or else be of type \hyperlink{13508459519898889544}{\texttt{Nothing}}. So all of the following calls should match:




\begin{minted}{julia}
f(1, 1)
f("", "")
f(2.0, 2.0)
f(nothing, 1)
f(nothing, "")
f(nothing, 2.0)
\end{minted}



These examples are telling us something: when \texttt{x} is \texttt{nothing::Nothing}, there are no extra constraints on \texttt{y}. It is as if the method signature had \texttt{y::Any}. Indeed, we have the following type equivalence:




\begin{minted}{julia}
(Tuple{Union{Nothing,T},T} where T) == Union{Tuple{Nothing,Any}, Tuple{T,T} where T}
\end{minted}



The general rule is: a concrete variable in covariant position acts like it{\textquotesingle}s not concrete if the subtyping algorithm only \emph{uses} it once. When \texttt{x} has type \texttt{Nothing}, we don{\textquotesingle}t need to use the \texttt{T} in \texttt{Union\{Nothing,T\}}; we only use it in the second slot. This arises naturally from the observation that in \texttt{Tuple\{T\} where T} restricting \texttt{T} to concrete types makes no difference; the type is equal to \texttt{Tuple\{Any\}} either way.



However, appearing in \emph{invariant} position disqualifies a variable from being concrete whether that appearance of the variable is used or not. Otherwise types can behave differently depending on which other types they are compared to, making subtyping not transitive. For example, consider



Tuple\{Int,Int8,Vector\{Integer\}\} <: Tuple\{T,T,Vector\{Union\{Integer,T\}\}\} where T



If the \texttt{T} inside the Union is ignored, then \texttt{T} is concrete and the answer is {\textquotedbl}false{\textquotedbl} since the first two types aren{\textquotesingle}t the same. But consider instead



Tuple\{Int,Int8,Vector\{Any\}\} <: Tuple\{T,T,Vector\{Union\{Integer,T\}\}\} where T



Now we cannot ignore the \texttt{T} in the Union (we must have T == Any), so \texttt{T} is not concrete and the answer is {\textquotedbl}true{\textquotedbl}. That would make the concreteness of \texttt{T} depend on the other type, which is not acceptable since a type must have a clear meaning on its own. Therefore the appearance of \texttt{T} inside \texttt{Vector} is considered in both cases.



\hypertarget{12600482412457091491}{}


\subsection{Subtyping diagonal variables}



The subtyping algorithm for diagonal variables has two components: (1) identifying variable occurrences, and (2) ensuring that diagonal variables range over concrete types only.



The first task is accomplished by keeping counters \texttt{occurs\_inv} and \texttt{occurs\_cov} (in \texttt{src/subtype.c}) for each variable in the environment, tracking the number of invariant and covariant occurrences, respectively. A variable is diagonal when \texttt{occurs\_inv == 0 \&\& occurs\_cov > 1}.



The second task is accomplished by imposing a condition on a variable{\textquotesingle}s lower bound. As the subtyping algorithm runs, it narrows the bounds of each variable (raising lower bounds and lowering upper bounds) to keep track of the range of variable values for which the subtype relation would hold. When we are done evaluating the body of a \texttt{UnionAll} type whose variable is diagonal, we look at the final values of the bounds. Since the variable must be concrete, a contradiction occurs if its lower bound could not be a subtype of a concrete type. For example, an abstract type like \hyperlink{6514416309183787338}{\texttt{AbstractArray}} cannot be a subtype of a concrete type, but a concrete type like \texttt{Int} can be, and the empty type \texttt{Bottom} can be as well. If a lower bound fails this test the algorithm stops with the answer \texttt{false}.



For example, in the problem \texttt{Tuple\{Int,String\} <: Tuple\{T,T\} where T}, we derive that this would be true if \texttt{T} were a supertype of \texttt{Union\{Int,String\}}. However, \texttt{Union\{Int,String\}} is an abstract type, so the relation does not hold.



This concreteness test is done by the function \texttt{is\_leaf\_bound}. Note that this test is slightly different from \texttt{jl\_is\_leaf\_type}, since it also returns \texttt{true} for \texttt{Bottom}. Currently this function is heuristic, and does not catch all possible concrete types. The difficulty is that whether a lower bound is concrete might depend on the values of other type variable bounds. For example, \texttt{Vector\{T\}} is equivalent to the concrete type \texttt{Vector\{Int\}} only if both the upper and lower bounds of \texttt{T} equal \texttt{Int}. We have not yet worked out a complete algorithm for this.



\hypertarget{37604590457653524}{}


\subsection{Introduction to the internal machinery}



Most operations for dealing with types are found in the files \texttt{jltypes.c} and \texttt{subtype.c}. A good way to start is to watch subtyping in action. Build Julia with \texttt{make debug} and fire up Julia within a debugger. \href{@ref}{gdb debugging tips} has some tips which may be useful.



Because the subtyping code is used heavily in the REPL itself–and hence breakpoints in this code get triggered often–it will be easiest if you make the following definition:




\begin{minted}{jlcon}
julia> function mysubtype(a,b)
           ccall(:jl_breakpoint, Cvoid, (Any,), nothing)
           a <: b
       end
\end{minted}



and then set a breakpoint in \texttt{jl\_breakpoint}.  Once this breakpoint gets triggered, you can set breakpoints in other functions.



As a warm-up, try the following:




\begin{minted}{julia}
mysubtype(Tuple{Int,Float64}, Tuple{Integer,Real})
\end{minted}



We can make it more interesting by trying a more complex case:




\begin{minted}{julia}
mysubtype(Tuple{Array{Int,2}, Int8}, Tuple{Array{T}, T} where T)
\end{minted}



\hypertarget{9271541181781970079}{}


\subsection{Subtyping and method sorting}



The \texttt{type\_morespecific} functions are used for imposing a partial order on functions in method tables (from most-to-least specific). Specificity is strict; if \texttt{a} is more specific than \texttt{b}, then \texttt{a} does not equal \texttt{b} and \texttt{b} is not more specific than \texttt{a}.



If \texttt{a} is a strict subtype of \texttt{b}, then it is automatically considered more specific. From there, \texttt{type\_morespecific} employs some less formal rules. For example, \texttt{subtype} is sensitive to the number of arguments, but \texttt{type\_morespecific} may not be. In particular, \texttt{Tuple\{Int,AbstractFloat\}} is more specific than \texttt{Tuple\{Integer\}}, even though it is not a subtype.  (Of \texttt{Tuple\{Int,AbstractFloat\}} and \texttt{Tuple\{Integer,Float64\}}, neither is more specific than the other.)  Likewise, \texttt{Tuple\{Int,Vararg\{Int\}\}} is not a subtype of \texttt{Tuple\{Integer\}}, but it is considered more specific. However, \texttt{morespecific} does get a bonus for length: in particular, \texttt{Tuple\{Int,Int\}} is more specific than \texttt{Tuple\{Int,Vararg\{Int\}\}}.



If you{\textquotesingle}re debugging how methods get sorted, it can be convenient to define the function:




\begin{minted}{julia}
type_morespecific(a, b) = ccall(:jl_type_morespecific, Cint, (Any,Any), a, b)
\end{minted}



which allows you to test whether tuple type \texttt{a} is more specific than tuple type \texttt{b}.



\hypertarget{5831288113328207392}{}


\section{Memory layout of Julia Objects}



\hypertarget{9050896398576860708}{}


\subsection{Object layout (\texttt{jl\_value\_t})}



The \texttt{jl\_value\_t} struct is the name for a block of memory owned by the Julia Garbage Collector, representing the data associated with a Julia object in memory. Absent any type information, it is simply an opaque pointer:




\begin{lstlisting}
typedef struct jl_value_t* jl_pvalue_t;
\end{lstlisting}



Each \texttt{jl\_value\_t} struct is contained in a \texttt{jl\_typetag\_t} struct that contains metadata information about the Julia object, such as its type and garbage collector (gc) reachability:




\begin{lstlisting}
typedef struct {
    opaque metadata;
    jl_value_t value;
} jl_typetag_t;
\end{lstlisting}



The type of any Julia object is an instance of a leaf \texttt{jl\_datatype\_t} object. The \texttt{jl\_typeof()} function can be used to query for it:




\begin{lstlisting}
jl_value_t *jl_typeof(jl_value_t *v);
\end{lstlisting}



The layout of the object depends on its type. Reflection methods can be used to inspect that layout. A field can be accessed by calling one of the get-field methods:




\begin{lstlisting}
jl_value_t *jl_get_nth_field_checked(jl_value_t *v, size_t i);
jl_value_t *jl_get_field(jl_value_t *o, char *fld);
\end{lstlisting}



If the field types are known, a priori, to be all pointers, the values can also be extracted directly as an array access:




\begin{lstlisting}
jl_value_t *v = value->fieldptr[n];
\end{lstlisting}



As an example, a {\textquotedbl}boxed{\textquotedbl} \texttt{uint16\_t} is stored as follows:




\begin{lstlisting}
struct {
    opaque metadata;
    struct {
        uint16_t data;        // -- 2 bytes
    } jl_value_t;
};
\end{lstlisting}



This object is created by \texttt{jl\_box\_uint16()}. Note that the \texttt{jl\_value\_t} pointer references the data portion, not the metadata at the top of the struct.



A value may be stored {\textquotedbl}unboxed{\textquotedbl} in many circumstances (just the data, without the metadata, and possibly not even stored but just kept in registers), so it is unsafe to assume that the address of a box is a unique identifier. The {\textquotedbl}egal{\textquotedbl} test (corresponding to the \texttt{===} function in Julia), should instead be used to compare two unknown objects for equivalence:




\begin{lstlisting}
int jl_egal(jl_value_t *a, jl_value_t *b);
\end{lstlisting}



This optimization should be relatively transparent to the API, since the object will be {\textquotedbl}boxed{\textquotedbl} on-demand, whenever a \texttt{jl\_value\_t} pointer is needed.



Note that modification of a \texttt{jl\_value\_t} pointer in memory is permitted only if the object is mutable. Otherwise, modification of the value may corrupt the program and the result will be undefined. The mutability property of a value can be queried for with:




\begin{lstlisting}
int jl_is_mutable(jl_value_t *v);
\end{lstlisting}



If the object being stored is a \texttt{jl\_value\_t}, the Julia garbage collector must be notified also:




\begin{lstlisting}
void jl_gc_wb(jl_value_t *parent, jl_value_t *ptr);
\end{lstlisting}



However, the \href{@ref}{Embedding Julia} section of the manual is also required reading at this point, for covering other details of boxing and unboxing various types, and understanding the gc interactions.



Mirror structs for some of the built-in types are \href{https://github.com/JuliaLang/julia/blob/master/src/julia.h}{defined in \texttt{julia.h}}. The corresponding global \texttt{jl\_datatype\_t} objects are created by \href{https://github.com/JuliaLang/julia/blob/master/src/jltypes.c}{\texttt{jl\_init\_types} in \texttt{jltypes.c}}.



\hypertarget{660883080955975432}{}


\subsection{Garbage collector mark bits}



The garbage collector uses several bits from the metadata portion of the \texttt{jl\_typetag\_t} to track each object in the system. Further details about this algorithm can be found in the comments of the \href{https://github.com/JuliaLang/julia/blob/master/src/gc.c}{garbage collector implementation in \texttt{gc.c}}.



\hypertarget{14420252243983980472}{}


\subsection{Object allocation}



Most new objects are allocated by \texttt{jl\_new\_structv()}:




\begin{lstlisting}
jl_value_t *jl_new_struct(jl_datatype_t *type, ...);
jl_value_t *jl_new_structv(jl_datatype_t *type, jl_value_t **args, uint32_t na);
\end{lstlisting}



Although, \hyperlink{12980593021531333073}{\texttt{isbits}} objects can be also constructed directly from memory:




\begin{lstlisting}
jl_value_t *jl_new_bits(jl_value_t *bt, void *data)
\end{lstlisting}



And some objects have special constructors that must be used instead of the above functions:



Types:




\begin{lstlisting}
jl_datatype_t *jl_apply_type(jl_datatype_t *tc, jl_tuple_t *params);
jl_datatype_t *jl_apply_array_type(jl_datatype_t *type, size_t dim);
\end{lstlisting}



While these are the most commonly used options, there are more low-level constructors too, which you can find declared in \href{https://github.com/JuliaLang/julia/blob/master/src/julia.h}{\texttt{julia.h}}. These are used in \texttt{jl\_init\_types()} to create the initial types needed to bootstrap the creation of the Julia system image.



Tuples:




\begin{lstlisting}
jl_tuple_t *jl_tuple(size_t n, ...);
jl_tuple_t *jl_tuplev(size_t n, jl_value_t **v);
jl_tuple_t *jl_alloc_tuple(size_t n);
\end{lstlisting}



The representation of tuples is highly unique in the Julia object representation ecosystem. In some cases, a \hyperlink{12342862450082530092}{\texttt{Base.tuple()}} object may be an array of pointers to the objects contained by the tuple equivalent to:




\begin{lstlisting}
typedef struct {
    size_t length;
    jl_value_t *data[length];
} jl_tuple_t;
\end{lstlisting}



However, in other cases, the tuple may be converted to an anonymous \hyperlink{12980593021531333073}{\texttt{isbits}} type and stored unboxed, or it may not stored at all (if it is not being used in a generic context as a \texttt{jl\_value\_t*}).



Symbols:




\begin{lstlisting}
jl_sym_t *jl_symbol(const char *str);
\end{lstlisting}



Functions and MethodInstance:




\begin{lstlisting}
jl_function_t *jl_new_generic_function(jl_sym_t *name);
jl_method_instance_t *jl_new_method_instance(jl_value_t *ast, jl_tuple_t *sparams);
\end{lstlisting}



Arrays:




\begin{lstlisting}
jl_array_t *jl_new_array(jl_value_t *atype, jl_tuple_t *dims);
jl_array_t *jl_new_arrayv(jl_value_t *atype, ...);
jl_array_t *jl_alloc_array_1d(jl_value_t *atype, size_t nr);
jl_array_t *jl_alloc_array_2d(jl_value_t *atype, size_t nr, size_t nc);
jl_array_t *jl_alloc_array_3d(jl_value_t *atype, size_t nr, size_t nc, size_t z);
jl_array_t *jl_alloc_vec_any(size_t n);
\end{lstlisting}



Note that many of these have alternative allocation functions for various special-purposes. The list here reflects the more common usages, but a more complete list can be found by reading the \href{https://github.com/JuliaLang/julia/blob/master/src/julia.h}{\texttt{julia.h} header file}.



Internal to Julia, storage is typically allocated by \texttt{newstruct()} (or \texttt{newobj()} for the special types):




\begin{lstlisting}
jl_value_t *newstruct(jl_value_t *type);
jl_value_t *newobj(jl_value_t *type, size_t nfields);
\end{lstlisting}



And at the lowest level, memory is getting allocated by a call to the garbage collector (in \texttt{gc.c}), then tagged with its type:




\begin{lstlisting}
jl_value_t *jl_gc_allocobj(size_t nbytes);
void jl_set_typeof(jl_value_t *v, jl_datatype_t *type);
\end{lstlisting}



Note that all objects are allocated in multiples of 4 bytes and aligned to the platform pointer size. Memory is allocated from a pool for smaller objects, or directly with \texttt{malloc()} for large objects.



\begin{quote}
\textbf{Singleton Types}

Singleton types have only one instance and no data fields. Singleton instances have a size of 0 bytes, and consist only of their metadata. e.g. \texttt{nothing::Nothing}.

See \hyperlink{14008188290941962431}{Singleton Types} and \href{@ref}{Nothingness and missing values}

\end{quote}


\hypertarget{10481677756025410412}{}


\section{Julia 代码的 eval}



学习 Julia 语言如何运行代码的最难的一部分是 学习如何让所有的小部分工作协同工作来执行一段代码。 



每个代码块通常会通过许多步骤来执行，在转变为期望的结果之前（但愿如此）。并且你可能不熟悉它们的名称，例如（非特定顺序）： flisp，AST，C++，LLVM，\texttt{eval}，\texttt{typeinf}，\texttt{macroexpand}，sysimg（或 system image），启动，变异，解析，执行，即时编译器，解释器解释，装箱，拆箱，内部函数，原始函数



\begin{quote}
\textbf{Definitions}

\begin{itemize}
\item REPL

REPL 表示 读取-求值-输出-循环（Read-Eval-Print Loop）。 我们管这个命令行环境的简称就叫REPL。


\item AST

抽象语法树（Abstract Syntax Tree）是代码结构的数据表现。在这种表现形式下代码被符号化，因此更加方便操作和执行。

\end{itemize}
\end{quote}


\hypertarget{12349293482799060845}{}


\subsection{Julia Execution}



整个进程的千里之行如下：



\begin{itemize}
\item[1.  ] 用户打开了 \texttt{julia}。


\item[2.  ] The C function \texttt{main()} from \texttt{ui/repl.c} gets called. This function processes the command line arguments, filling in the \texttt{jl\_options} struct and setting the variable \texttt{ARGS}. It then initializes 在 \texttt{ui/repl.c} 中的 C 语言的函数 \texttt{main()} 被调用。这个函数处理命令行参数，填充到 \texttt{jl\_options} 结构图并且设置变了 \texttt{ARGS} 。接下来初始化 Julia (通过调用  \href{https://github.com/JuliaLang/julia/blob/master/src/task.c}{\texttt{julia\_init} in \texttt{task.c}} which may load a previously compiled \hyperlink{6082338945993475185}{sysimg}). Finally, it passes off control to Julia by calling \href{https://github.com/JuliaLang/julia/blob/master/base/client.jl}{\texttt{Base.\_start()}}.


\item[3.  ] When \texttt{\_start()} takes over control, the subsequent sequence of commands depends on the command line arguments given. For example, if a filename was supplied, it will proceed to execute that file. Otherwise, it will start an interactive REPL.


\item[4.  ] Skipping the details about how the REPL interacts with the user, let{\textquotesingle}s just say the program ends up with a block of code that it wants to run.


\item[5.  ] If the block of code to run is in a file, \href{https://github.com/JuliaLang/julia/blob/master/src/toplevel.c}{\texttt{jl\_load(char *filename)}} gets invoked to load the file and \hyperlink{14838640034628506824}{parse} it. Each fragment of code is then passed to \texttt{eval} to execute.


\item[6.  ] Each fragment of code (or AST), is handed off to \hyperlink{7507639810592563424}{\texttt{eval()}} to turn into results.


\item[7.  ] \hyperlink{7507639810592563424}{\texttt{eval()}} takes each code fragment and tries to run it in \href{https://github.com/JuliaLang/julia/blob/master/src/toplevel.c}{\texttt{jl\_toplevel\_eval\_flex()}}.


\item[8.  ] \texttt{jl\_toplevel\_eval\_flex()} decides whether the code is a {\textquotedbl}toplevel{\textquotedbl} action (such as \texttt{using} or \texttt{module}), which would be invalid inside a function. If so, it passes off the code to the toplevel interpreter.


\item[9.  ] \texttt{jl\_toplevel\_eval\_flex()} then \hyperlink{16669853702383402486}{expands} the code to eliminate any macros and to {\textquotedbl}lower{\textquotedbl} the AST to make it simpler to execute.


\item[10. ] \texttt{jl\_toplevel\_eval\_flex()} then uses some simple heuristics to decide whether to JIT compiler the  AST or to interpret it directly.


\item[11. ] The bulk of the work to interpret code is handled by \href{https://github.com/JuliaLang/julia/blob/master/src/interpreter.c}{\texttt{eval} in \texttt{interpreter.c}}.


\item[12. ] If instead, the code is compiled, the bulk of the work is handled by \texttt{codegen.cpp}. Whenever a  Julia function is called for the first time with a given set of argument types, \hyperlink{6510123671388929580}{type inference}  will be run on that function. This information is used by the \hyperlink{526576549562645049}{codegen} step to generate  faster code.


\item[13. ] Eventually, the user quits the REPL, or the end of the program is reached, and the \texttt{\_start()}  method returns.


\item[14. ] Just before exiting, \texttt{main()} calls \href{https://github.com/JuliaLang/julia/blob/master/src/init.c}{\texttt{jl\_atexit\_hook(exit\_code)}}.  This calls \texttt{Base.\_atexit()} (which calls any functions registered to \hyperlink{17479944696971324992}{\texttt{atexit()}} inside  Julia). Then it calls \href{https://github.com/JuliaLang/julia/blob/master/src/gc.c}{\texttt{jl\_gc\_run\_all\_finalizers()}}.  Finally, it gracefully cleans up all \texttt{libuv} handles and waits for them to flush and close.

\end{itemize}


\hypertarget{6801832859572424777}{}


\subsection{Parsing}



The Julia parser is a small lisp program written in femtolisp, the source-code for which is distributed inside Julia in \href{https://github.com/JuliaLang/julia/tree/master/src/flisp}{src/flisp}.



The interface functions for this are primarily defined in \href{https://github.com/JuliaLang/julia/blob/master/src/jlfrontend.scm}{\texttt{jlfrontend.scm}}. The code in \href{https://github.com/JuliaLang/julia/blob/master/src/ast.c}{\texttt{ast.c}} handles this handoff on the Julia side.



The other relevant files at this stage are \href{https://github.com/JuliaLang/julia/blob/master/src/julia-parser.scm}{\texttt{julia-parser.scm}}, which handles tokenizing Julia code and turning it into an AST, and \href{https://github.com/JuliaLang/julia/blob/master/src/julia-syntax.scm}{\texttt{julia-syntax.scm}}, which handles transforming complex AST representations into simpler, {\textquotedbl}lowered{\textquotedbl} AST representations which are more suitable for analysis and execution.



If you want to test the parser without re-building Julia in its entirety, you can run the frontend on its own as follows:




\begin{lstlisting}
$ cd src
$ flisp/flisp
> (load "jlfrontend.scm")
> (jl-parse-file "<filename>")
\end{lstlisting}



\hypertarget{13925460440315781353}{}


\subsection{Macro Expansion}



When \hyperlink{7507639810592563424}{\texttt{eval()}} encounters a macro, it expands that AST node before attempting to evaluate the expression. Macro expansion involves a handoff from \hyperlink{7507639810592563424}{\texttt{eval()}} (in Julia), to the parser function \texttt{jl\_macroexpand()} (written in \texttt{flisp}) to the Julia macro itself (written in - what else - Julia) via \texttt{fl\_invoke\_julia\_macro()}, and back.



Typically, macro expansion is invoked as a first step during a call to \hyperlink{6644553029841096787}{\texttt{Meta.lower()}}/\texttt{jl\_expand()}, although it can also be invoked directly by a call to \hyperlink{8018172489611994488}{\texttt{macroexpand()}}/\texttt{jl\_macroexpand()}.



\hypertarget{5553247398724394157}{}


\subsection{Type Inference}



Type inference is implemented in Julia by \href{https://github.com/JuliaLang/julia/blob/master/base/compiler/typeinfer.jl}{\texttt{typeinf()} in \texttt{compiler/typeinfer.jl}}. Type inference is the process of examining a Julia function and determining bounds for the types of each of its variables, as well as bounds on the type of the return value from the function. This enables many future optimizations, such as unboxing of known immutable values, and compile-time hoisting of various run-time operations such as computing field offsets and function pointers. Type inference may also include other steps such as constant propagation and inlining.



\begin{quote}
\textbf{More Definitions}

\begin{itemize}
\item JIT

Just-In-Time Compilation The process of generating native-machine code into memory right when it is needed.


\item LLVM

Low-Level Virtual Machine (a compiler) The Julia JIT compiler is a program/library called libLLVM. Codegen in Julia refers both to the process of taking a Julia AST and turning it into LLVM instructions, and the process of LLVM optimizing that and turning it into native assembly instructions.


\item C++

The programming language that LLVM is implemented in, which means that codegen is also implemented in this language. The rest of Julia{\textquotesingle}s library is implemented in C, in part because its smaller feature set makes it more usable as a cross-language interface layer.


\item box

This term is used to describe the process of taking a value and allocating a wrapper around the data that is tracked by the garbage collector (gc) and is tagged with the object{\textquotesingle}s type.


\item unbox

The reverse of boxing a value. This operation enables more efficient manipulation of data when the type of that data is fully known at compile-time (through type inference).


\item generic function

A Julia function composed of multiple {\textquotedbl}methods{\textquotedbl} that are selected for dynamic dispatch based on the argument type-signature


\item anonymous function or {\textquotedbl}method{\textquotedbl}

A Julia function without a name and without type-dispatch capabilities


\item primitive function

A function implemented in C but exposed in Julia as a named function {\textquotedbl}method{\textquotedbl} (albeit without generic function dispatch capabilities, similar to a anonymous function)


\item intrinsic function

A low-level operation exposed as a function in Julia. These pseudo-functions implement operations on raw bits such as add and sign extend that cannot be expressed directly in any other way. Since they operate on bits directly, they must be compiled into a function and surrounded by a call to \texttt{Core.Intrinsics.box(T, ...)} to reassign type information to the value.

\end{itemize}
\end{quote}


\hypertarget{16251221274618963128}{}


\subsection{JIT Code Generation}



Codegen is the process of turning a Julia AST into native machine code.



The JIT environment is initialized by an early call to \href{https://github.com/JuliaLang/julia/blob/master/src/codegen.cpp}{\texttt{jl\_init\_codegen} in \texttt{codegen.cpp}}.



On demand, a Julia method is converted into a native function by the function \texttt{emit\_function(jl\_method\_instance\_t*)}. (note, when using the MCJIT (in LLVM v3.4+), each function must be JIT into a new module.) This function recursively calls \texttt{emit\_expr()} until the entire function has been emitted.



Much of the remaining bulk of this file is devoted to various manual optimizations of specific code patterns. For example, \texttt{emit\_known\_call()} knows how to inline many of the primitive functions (defined in \href{https://github.com/JuliaLang/julia/blob/master/src/builtins.c}{\texttt{builtins.c}}) for various combinations of argument types.



Other parts of codegen are handled by various helper files:



\begin{itemize}
\item \href{https://github.com/JuliaLang/julia/blob/master/src/debuginfo.cpp}{\texttt{debuginfo.cpp}}

Handles backtraces for JIT functions


\item \href{https://github.com/JuliaLang/julia/blob/master/src/ccall.cpp}{\texttt{ccall.cpp}}

Handles the ccall and llvmcall FFI, along with various \texttt{abi\_*.cpp} files


\item \href{https://github.com/JuliaLang/julia/blob/master/src/intrinsics.cpp}{\texttt{intrinsics.cpp}}

Handles the emission of various low-level intrinsic functions

\end{itemize}


\begin{quote}
\textbf{Bootstrapping}

The process of creating a new system image is called {\textquotedbl}bootstrapping{\textquotedbl}.

The etymology of this word comes from the phrase {\textquotedbl}pulling oneself up by the bootstraps{\textquotedbl}, and refers to the idea of starting from a very limited set of available functions and definitions and ending with the creation of a full-featured environment.

\end{quote}


\hypertarget{9959120445934014648}{}


\subsection{System Image}



The system image is a precompiled archive of a set of Julia files. The \texttt{sys.ji} file distributed with Julia is one such system image, generated by executing the file \href{https://github.com/JuliaLang/julia/blob/master/base/sysimg.jl}{\texttt{sysimg.jl}}, and serializing the resulting environment (including Types, Functions, Modules, and all other defined values) into a file. Therefore, it contains a frozen version of the \texttt{Main}, \texttt{Core}, and \texttt{Base} modules (and whatever else was in the environment at the end of bootstrapping). This serializer/deserializer is implemented by \href{https://github.com/JuliaLang/julia/blob/master/src/staticdata.c}{\texttt{jl\_save\_system\_image}/\texttt{jl\_restore\_system\_image} in \texttt{staticdata.c}}.



If there is no sysimg file (\texttt{jl\_options.image\_file == NULL}), this also implies that \texttt{--build} was given on the command line, so the final result should be a new sysimg file. During Julia initialization, minimal \texttt{Core} and \texttt{Main} modules are created. Then a file named \texttt{boot.jl} is evaluated from the current directory. Julia then evaluates any file given as a command line argument until it reaches the end. Finally, it saves the resulting environment to a {\textquotedbl}sysimg{\textquotedbl} file for use as a starting point for a future Julia run.



\hypertarget{290466951415325789}{}


\section{Calling Conventions}



Julia uses three calling conventions for four distinct purposes:




\begin{table}[h]

\begin{tabulary}{\linewidth}{|L|L|L|}
\hline
Name & Prefix & Purpose \\
\hline
Native & \texttt{julia\_} & Speed via specialized signatures \\
\hline
JL Call & \texttt{jlcall\_} & Wrapper for generic calls \\
\hline
JL Call & \texttt{jl\_} & Builtins \\
\hline
C ABI & \texttt{jlcapi\_} & Wrapper callable from C \\
\hline
\end{tabulary}

\end{table}



\hypertarget{4788166660204734834}{}


\subsection{Julia Native Calling Convention}



The native calling convention is designed for fast non-generic calls. It usually uses a specialized signature.



\begin{itemize}
\item LLVM ghosts (zero-length types) are omitted.


\item LLVM scalars and vectors are passed by value.


\item LLVM aggregates (arrays and structs) are passed by reference.

\end{itemize}


A small return values is returned as LLVM return values. A large return values is returned via the {\textquotedbl}structure return{\textquotedbl} (\texttt{sret}) convention, where the caller provides a pointer to a return slot.



An argument or return values that is a homogeneous tuple is sometimes represented as an LLVM vector instead of an LLVM array.



\hypertarget{10962628785392118342}{}


\subsection{JL Call Convention}



The JL Call convention is for builtins and generic dispatch. Hand-written functions using this convention are declared via the macro \texttt{JL\_CALLABLE}. The convention uses exactly 3 parameters:



\begin{itemize}
\item \texttt{F}  - Julia representation of function that is being applied


\item \texttt{args} - pointer to array of pointers to boxes


\item \texttt{nargs} - length of the array

\end{itemize}


The return value is a pointer to a box.



\hypertarget{16764615067045412370}{}


\subsection{C ABI}



C ABI wrappers enable calling Julia from C. The wrapper calls a function using the native calling convention.



Tuples are always represented as C arrays.



\hypertarget{7542203617935209330}{}


\section{High-level Overview of the Native-Code Generation Process}



\hypertarget{6164157073495091365}{}


\subsection{Representation of Pointers}



When emitting code to an object file, pointers will be emitted as relocations. The deserialization code will ensure any object that pointed to one of these constants gets recreated and contains the right runtime pointer.



Otherwise, they will be emitted as literal constants.



To emit one of these objects, call \texttt{literal\_pointer\_val}. It{\textquotesingle}ll handle tracking the Julia value and the LLVM global, ensuring they are valid both for the current runtime and after deserialization.



When emitted into the object file, these globals are stored as references in a large \texttt{gvals} table. This allows the deserializer to reference them by index, and implement a custom manual mechanism similar to a Global Offset Table (GOT) to restore them.



Function pointers are handled similarly. They are stored as values in a large \texttt{fvals} table. Like globals, this allows the deserializer to reference them by index.



Note that \texttt{extern} functions are handled separately, with names, via the usual symbol resolution mechanism in the linker.



Note too that \texttt{ccall} functions are also handled separately, via a manual GOT and Procedure Linkage Table (PLT).



\hypertarget{9352283582715079729}{}


\subsection{Representation of Intermediate Values}



Values are passed around in a \texttt{jl\_cgval\_t} struct. This represents an R-value, and includes enough information to determine how to assign or pass it somewhere.



They are created via one of the helper constructors, usually: \texttt{mark\_julia\_type} (for immediate values) and \texttt{mark\_julia\_slot} (for pointers to values).



The function \texttt{convert\_julia\_type} can transform between any two types. It returns an R-value with \texttt{cgval.typ} set to \texttt{typ}. It{\textquotesingle}ll cast the object to the requested representation, making heap boxes, allocating stack copies, and computing tagged unions as needed to change the representation.



By contrast \texttt{update\_julia\_type} will change \texttt{cgval.typ} to \texttt{typ}, only if it can be done at zero-cost (i.e. without emitting any code).



\hypertarget{3738811278233217209}{}


\subsection{Union representation}



Inferred union types may be stack allocated via a tagged type representation.



The primitive routines that need to be able to handle tagged unions are:



\begin{itemize}
\item mark-type


\item load-local


\item store-local


\item isa


\item is


\item emit\_typeof


\item emit\_sizeof


\item boxed


\item unbox


\item specialized cc-ret

\end{itemize}


Everything else should be possible to handle in inference by using these primitives to implement union-splitting.



The representation of the tagged-union is as a pair of \texttt{< void* union, byte selector >}. The selector is fixed-size as \texttt{byte \& 0x7f}, and will union-tag the first 126 isbits. It records the one-based depth-first count into the type-union of the isbits objects inside. An index of zero indicates that the \texttt{union*} is actually a tagged heap-allocated \texttt{jl\_value\_t*}, and needs to be treated as normal for a boxed object rather than as a tagged union.



The high bit of the selector (\texttt{byte \& 0x80}) can be tested to determine if the \texttt{void*} is actually a heap-allocated (\texttt{jl\_value\_t*}) box, thus avoiding the cost of re-allocating a box, while maintaining the ability to efficiently handle union-splitting based on the low bits.



It is guaranteed that \texttt{byte \& 0x7f} is an exact test for the type, if the value can be represented by a tag – it will never be marked \texttt{byte = 0x80}. It is not necessary to also test the type-tag when testing \texttt{isa}.



The \texttt{union*} memory region may be allocated at \emph{any} size. The only constraint is that it is big enough to contain the data currently specified by \texttt{selector}. It might not be big enough to contain the union of all types that could be stored there according to the associated Union type field. Use appropriate care when copying.



\hypertarget{5801902447580234191}{}


\subsection{Specialized Calling Convention Signature Representation}



A \texttt{jl\_returninfo\_t} object describes the calling convention details of any callable.



If any of the arguments or return type of a method can be represented unboxed, and the method is not varargs, it{\textquotesingle}ll be given an optimized calling convention signature based on its \texttt{specTypes} and \texttt{rettype} fields.



The general principles are that:



\begin{itemize}
\item Primitive types get passed in int/float registers.


\item Tuples of VecElement types get passed in vector registers.


\item Structs get passed on the stack.


\item Return values are handle similarly to arguments, with a size-cutoff at which they will instead be returned via a hidden sret argument.

\end{itemize}


The total logic for this is implemented by \texttt{get\_specsig\_function} and \texttt{deserves\_sret}.



Additionally, if the return type is a union, it may be returned as a pair of values (a pointer and a tag). If the union values can be stack-allocated, then sufficient space to store them will also be passed as a hidden first argument. It is up to the callee whether the returned pointer will point to this space, a boxed object, or even other constant memory.



\hypertarget{3539827185509825766}{}


\section{Julia 函数}



本文档将解释函数、方法定义以及方法表是如何工作的。



\hypertarget{6316722227009052903}{}


\subsection{方法表}



Julia 中的每个函数都是泛型函数。泛型函数在概念上是单个函数，但由许多定义或方法组成。泛型函数的方法储存在方法表中。方法表（类型 \texttt{MethodTable}）与 \texttt{TypeName} 相关。\texttt{TypeName} 描述了一系列参数化类型。例如，\texttt{Complex\{Float32\}} 和 \texttt{Complex\{Float64\}} 共享相同的 type name 对象 \texttt{Complex}。



Julia 中的所有对象都可能是可调用的，因为每个对象都有类型，而类型又有 \texttt{TypeName}。



\hypertarget{13252419531822255004}{}


\subsection{函数调用}



给定调用 \texttt{f(x,y)}，会执行以下步骤：首先，用 \texttt{typeof(f).name.mt} 访问要使用的方法表。其次，生成一个参数元组类型 \texttt{Tuple\{typeof(f), typeof(x), typeof(y)\}}。请注意，函数本身的类型是第一个元素。这因为该类型可能有参数，所以需要参与派发。这个元组类型会在方法表中查找。



这个派发过程由 \texttt{jl\_apply\_generic} 执行，它有两个参数：一个指向由值 f、x 和 y 组成的数组的指针，以及值的数量（此例中是 3）。



在整个系统中，处理函数和参数列表的 API 有两种：一种单独接收函数和参数，一种接收一个单独的参数结构。在第一种 API 中，「参数」部分\emph{不}包含函数的相关信息，因为它是单独传递的。在第二种 API 中，函数是参数结构的第一个元素。



例如，以下用于执行调用的函数只接收 \texttt{args} 指针，因此 args 数组的第一个元素将会是要调用的函数：




\begin{lstlisting}
jl_value_t *jl_apply(jl_value_t **args, uint32_t nargs)
\end{lstlisting}



这个用于相同功能的入口点单独接收该函数，因此 \texttt{args} 数组中不包含该函数：




\begin{lstlisting}
jl_value_t *jl_call(jl_function_t *f, jl_value_t **args, int32_t nargs);
\end{lstlisting}



\hypertarget{12335264465348807608}{}


\subsection{添加方法}



在上述派发过程中，添加一个新方法在概念上所需的只是（1）一个元组类型，以及（2）方法体的代码。\texttt{jl\_method\_def} 实现了此操作。\texttt{jl\_first\_argument\_datatype} 会被调用，用来从第一个参数的类型中提取相关的方法表。这比派发期间的相应过程复杂得多，因为参数元组类型可能是抽象类型。例如，我们可以定义：




\begin{minted}{julia}
(::Union{Foo{Int},Foo{Int8}})(x) = 0
\end{minted}



这是可行的，因为所有可能的匹配方法都属于同一方法表。



\hypertarget{4974882052749632871}{}


\subsection{创建泛型函数}



因为每个对象都是可调用的，所以创建泛型函数不需要特殊的东西。因此，\texttt{jl\_new\_generic\_function} 只是创建一个新的 \texttt{Function} 的单态类型（大小为 0）并返回它的实例。函数可有一个帮助记忆的「显示名称」，用于调试信息和打印对象。例如，\texttt{Base.sin} 的名称为 \texttt{sin}。按照约定，所创建\emph{类型}的名称与函数名称相同，带前缀 \texttt{\#}。所以 \texttt{typeof(sin)} 即 \texttt{Base.\#sin}。



\hypertarget{2172965036514898807}{}


\subsection{闭包}



闭包只是一个可调用对象，其字段名称对应于被捕获的变量。例如，以下代码：




\begin{minted}{julia}
function adder(x)
    return y->x+y
end
\end{minted}



（大致）降低为：




\begin{minted}{julia}
struct ##1{T}
    x::T
end

(_::##1)(y) = _.x + y

function adder(x)
    return ##1(x)
end
\end{minted}



\hypertarget{5490460475085720426}{}


\subsection{构造函数}



构造函数调用只是对类型的调用。\texttt{Type} 的方法表包含所有的构造函数定义。\texttt{Type} 的所有子类型（\texttt{Type}、\texttt{UnionAll}、\texttt{Union} 和 \texttt{DataType}）目前通过特殊的安排方式共享一个方法表。



\hypertarget{3874805480384047373}{}


\subsection{内置函数}



「内置」函数定义在 \texttt{Core} 模块中，有：




\begin{lstlisting}
=== typeof sizeof <: isa typeassert throw tuple getfield setfield! fieldtype
nfields isdefined arrayref arrayset arraysize applicable invoke apply_type _apply
_expr svec
\end{lstlisting}



这些都是单态对象，其类型为 \texttt{Builtin} 的子类型，而或后者为 \texttt{Function} 的子类型。它们的用处是在运行时暴露遵循「jlcall」调用约定的入口点。




\begin{lstlisting}
jl_value_t *(jl_value_t*, jl_value_t**, uint32_t)
\end{lstlisting}



内建函数的方法表是空的。相反地，它们具有单独的 catch-all 方法缓存条目（\texttt{Tuple\{Vararg\{Any\}\}}），其 jlcall fptr 指向正确的函数。这是一种 hack，但效果相当不错。



\hypertarget{8084690442149965313}{}


\subsection{关键字参数}



关键字参数的工作方式是将每个具有关键字参数的方法表与一个特殊的隐藏函数对象相关联。该函数称为「keyword argument sorter」、「keyword sorter」或「kwsorter」，存储在 \texttt{MethodTable} 对象的 \texttt{kwsorter} 字段中。在 kwsorter 函数的每个定义与通常的方法表中的某个函数具有相同的参数，除了前面还有一个 \texttt{NamedTuple} 参数，该参数给出所传递关键字参数的名称和值。kwsorter 的作用是根据名称将关键字参数移到预先要求的位置，并对任何所需的默认值表达式进行求值和替换。其返回结果是一个通常的位置参数列表，接着会被传递给另一个由编译器生成的函数。



理解该过程的最简单方法是查看关键字参数方法的定义的降低方式。代码：




\begin{minted}{julia}
function circle(center, radius; color = black, fill::Bool = true, options...)
    # draw
end
\end{minted}



实际上生成\emph{三个}方法定义。第一个方法是一个接收所有参数（包括关键字参数）作为其位置参数的函数，其代码包含该方法体。它有一个自动生成的名称：




\begin{minted}{julia}
function #circle#1(color, fill::Bool, options, circle, center, radius)
    # draw
end
\end{minted}



第二个方法是原始 \texttt{circle} 函数的普通定义，负责处理没有传递关键字参数的情况：




\begin{minted}{julia}
function circle(center, radius)
    #circle#1(black, true, pairs(NamedTuple()), circle, center, radius)
end
\end{minted}



这只是派发到第一个方法，传递默认值。\texttt{pairs} 应用于其余的参数组成的具名元组，以提供键值对迭代。请注意，如果方法不接受其余的关键字参数，那么此参数不存在。



最后，kwsorter 定义为：




\begin{lstlisting}
function (::Core.kwftype(typeof(circle)))(kws, circle, center, radius)
    if haskey(kws, :color)
        color = kws.color
    else
        color = black
    end
    # etc.

    # put remaining kwargs in `options`
    options = structdiff(kws, NamedTuple{(:color, :fill)})

    # if the method doesn't accept rest keywords, throw an error
    # unless `options` is empty

    #circle#1(color, fill, pairs(options), circle, center, radius)
end
\end{lstlisting}



函数 \texttt{Core.kwftype(t)} 创建字段 \texttt{t.name.mt.kwsorter}（如果它未被创建），并返回该函数的类型。



此设计的特点是不使用关键字参数的调用点不需要特殊处理；这一切的工作方式好像它们根本不是语言的一部分。不使用关键字参数的调用点直接派发到被调用函数的 kwsorter。例如，调用：




\begin{minted}{julia}
circle((0,0), 1.0, color = red; other...)
\end{minted}



降低为：




\begin{minted}{julia}
kwfunc(circle)(merge((color = red,), other), circle, (0,0), 1.0)
\end{minted}



\texttt{kwfunc}（也在 \texttt{Core} 中）可获取被调用函数的 kwsorter。关键字 splatting 函数（编写为 \texttt{other...}）调用具名元组 \texttt{merge} 函数。此函数进一步解包了 \texttt{other} 的每个\emph{元素}，预期中每个元素包含两个值（一个符号和一个值）。当然，如果所有 splatted 参数都是具名元组，则可使用更高效的实现。请注意，原来的 \texttt{circle} 被传递，以处理闭包。



\hypertarget{1871194914272945034}{}


\subsection{Compiler efficiency issues}



为每个函数生成新类型在与 Julia 的「默认专门化所有参数」这一设计理念结合使用时，可能对编译器资源的使用产生严重后果。实际上，此设计的初始实现经历了更长的测试和构造时间、高内存占用以及比基线大近乎 2 倍的系统镜像。在一个幼稚的实现中，该问题非常严重，以至于系统几乎无法使用。需要进行几项重要的优化才能使设计变得可行。



第一个问题是函数值参数的不同值导致函数的过度专门化。许多函数只是将参数「传递」到其它地方，例如，到另一个函数或存储位置。这种函数不需要为每个可能传入的闭包专门化。幸运的是，这种情况很容易区分，只需考虑函数是否\emph{调用}它的某个参数（即，参数出现在某处的「头部位置」）。性能关键的高阶函数，如 \texttt{map}，肯定会直接调用它们的参数函数，因此仍然会按预期进行专门化。此优化通过在前端记录 \texttt{analyze-variables} 传递期间所调用的参数来实现。当 \texttt{cache\_method} 看到某个在 \texttt{Function} 类型层次结构的参数传递到声明为 \texttt{Any} 或 \texttt{Function} 的槽时，它的行为就好像应用了 \texttt{@nospecialize} 注释一样。这种启发式方法在实践中似乎非常有效。



下一个问题涉及方法缓存哈希表的结构。经验研究表明，绝大多数动态分派调用只涉及一个或两个元素。反过来看，只考虑第一个元素便可解决许多这些情况。（旁白：单派发的支持者根本不会对此感到惊讶。但是，这个观点意味着「多重派发在实践中很容易优化」，因此我们应该使用它，而\emph{不是}「我们应该使用单派发」！）因此，方法缓存使用第一个参数作为其主键。但请注意，这对应于函数调用的元组类型的\emph{第二个}元素（第一个元素是函数本身的类型）。通常，头部位置的类型非常少变化——实际上，大多数函数属于没有参数的单态类型。但是，构造函数不是这种情况，一个方法表便保存了所有类型的构造函数。因此，\texttt{Type} 方法表是特殊的，使用元组类型的\emph{第一个}元素而不是第二个。



前端为所有闭包生成类型声明。起初，这通过生成通常的类型声明来实现。但是，这产生了大量的构造函数，这些构造函数全都很简单（只是将所有参数传递给 \hyperlink{13888762393600028594}{\texttt{new}}）。因为方法是部分排序的，所以插入所有这些方法是 O(n{\textasciicircum}2)，此外要保留的方法实在太多了。这可通过直接生成 \texttt{struct\_type} 表达式（绕过默认的构造函数生成）并直接使用 \texttt{new} 来创建闭包的实例来优化。这事并不漂亮，但你需要做你该做的。



下个问题是 \texttt{@test} 宏，它为每个测试用例生成一个 0 参数闭包。这不是必需的，因为每个用例只需运行一次。因此，\texttt{@test} 被改写以展开到一个 try-catch 块中，该块记录测试结果（true、false 或所引发的异常）并对它调用测试套件处理程序。



\hypertarget{3626588894035984514}{}


\section{笛卡尔}



The (non-exported) Cartesian module provides macros that facilitate writing multidimensional algorithms. Most often you can write such algorithms with \href{https://julialang.org/blog/2016/02/iteration}{straightforward techniques}; however, there are a few cases where \texttt{Base.Cartesian} is still useful or necessary.



\hypertarget{10560451956896766301}{}


\subsection{Principles of usage}



A simple example of usage is:




\begin{minted}{julia}
@nloops 3 i A begin
    s += @nref 3 A i
end
\end{minted}



which generates the following code:




\begin{minted}{julia}
for i_3 = axes(A, 3)
    for i_2 = axes(A, 2)
        for i_1 = axes(A, 1)
            s += A[i_1, i_2, i_3]
        end
    end
end
\end{minted}



In general, Cartesian allows you to write generic code that contains repetitive elements, like the nested loops in this example.  Other applications include repeated expressions (e.g., loop unwinding) or creating function calls with variable numbers of arguments without using the {\textquotedbl}splat{\textquotedbl} construct (\texttt{i...}).



\hypertarget{3961768779038303546}{}


\subsection{基本语法}



The (basic) syntax of \texttt{@nloops} is as follows:



\begin{itemize}
\item The first argument must be an integer (\emph{not} a variable) specifying the number of loops.


\item The second argument is the symbol-prefix used for the iterator variable. Here we used \texttt{i}, and variables \texttt{i\_1, i\_2, i\_3} were generated.


\item The third argument specifies the range for each iterator variable. If you use a variable (symbol) here, it{\textquotesingle}s taken as \texttt{axes(A, dim)}. More flexibly, you can use the anonymous-function expression syntax described below.


\item The last argument is the body of the loop. Here, that{\textquotesingle}s what appears between the \texttt{begin...end}.

\end{itemize}


There are some additional features of \texttt{@nloops} described in the \hyperlink{6401299442402093832}{reference section}.



\texttt{@nref} follows a similar pattern, generating \texttt{A[i\_1,i\_2,i\_3]} from \texttt{@nref 3 A i}. The general practice is to read from left to right, which is why \texttt{@nloops} is \texttt{@nloops 3 i A expr} (as in \texttt{for i\_2 = axes(A, 2)}, where \texttt{i\_2} is to the left and the range is to the right) whereas \texttt{@nref} is \texttt{@nref 3 A i} (as in \texttt{A[i\_1,i\_2,i\_3]}, where the array comes first).



If you{\textquotesingle}re developing code with Cartesian, you may find that debugging is easier when you examine the generated code, using \texttt{@macroexpand}:






\begin{minted}{jlcon}
julia> @macroexpand @nref 2 A i
:(A[i_1, i_2])
\end{minted}





\hypertarget{13048573846185312344}{}


\subsubsection{Supplying the number of expressions}



The first argument to both of these macros is the number of expressions, which must be an integer. When you{\textquotesingle}re writing a function that you intend to work in multiple dimensions, this may not be something you want to hard-code. The recommended approach is to use a \texttt{@generated function}.  Here{\textquotesingle}s an example:




\begin{minted}{julia}
@generated function mysum(A::Array{T,N}) where {T,N}
    quote
        s = zero(T)
        @nloops $N i A begin
            s += @nref $N A i
        end
        s
    end
end
\end{minted}



Naturally, you can also prepare expressions or perform calculations before the \texttt{quote} block.



\hypertarget{10509900364879728464}{}


\subsubsection{Anonymous-function expressions as macro arguments}



Perhaps the single most powerful feature in \texttt{Cartesian} is the ability to supply anonymous-function expressions that get evaluated at parsing time.  Let{\textquotesingle}s consider a simple example:




\begin{minted}{julia}
@nexprs 2 j->(i_j = 1)
\end{minted}



\texttt{@nexprs} generates \texttt{n} expressions that follow a pattern. This code would generate the following statements:




\begin{minted}{julia}
i_1 = 1
i_2 = 1
\end{minted}



In each generated statement, an {\textquotedbl}isolated{\textquotedbl} \texttt{j} (the variable of the anonymous function) gets replaced by values in the range \texttt{1:2}. Generally speaking, Cartesian employs a LaTeX-like syntax.  This allows you to do math on the index \texttt{j}.  Here{\textquotesingle}s an example computing the strides of an array:




\begin{minted}{julia}
s_1 = 1
@nexprs 3 j->(s_{j+1} = s_j * size(A, j))
\end{minted}



would generate expressions




\begin{minted}{julia}
s_1 = 1
s_2 = s_1 * size(A, 1)
s_3 = s_2 * size(A, 2)
s_4 = s_3 * size(A, 3)
\end{minted}



Anonymous-function expressions have many uses in practice.



\hypertarget{908996570436533510}{}


\paragraph{Macro reference}


\hypertarget{4938945836201444124}{} 
\hyperlink{4938945836201444124}{\texttt{Base.Cartesian.@nloops}}  -- {Macro.}

\begin{adjustwidth}{2em}{0pt}


\begin{minted}{julia}
@nloops N itersym rangeexpr bodyexpr
@nloops N itersym rangeexpr preexpr bodyexpr
@nloops N itersym rangeexpr preexpr postexpr bodyexpr
\end{minted}

Generate \texttt{N} nested loops, using \texttt{itersym} as the prefix for the iteration variables. \texttt{rangeexpr} may be an anonymous-function expression, or a simple symbol \texttt{var} in which case the range is \texttt{axes(var, d)} for dimension \texttt{d}.

Optionally, you can provide {\textquotedbl}pre{\textquotedbl} and {\textquotedbl}post{\textquotedbl} expressions. These get executed first and last, respectively, in the body of each loop. For example:


\begin{lstlisting}
@nloops 2 i A d -> j_d = min(i_d, 5) begin
    s += @nref 2 A j
end
\end{lstlisting}

would generate:


\begin{lstlisting}
for i_2 = axes(A, 2)
    j_2 = min(i_2, 5)
    for i_1 = axes(A, 1)
        j_1 = min(i_1, 5)
        s += A[j_1, j_2]
    end
end
\end{lstlisting}

If you want just a post-expression, supply \hyperlink{9331422207248206047}{\texttt{nothing}} for the pre-expression. Using parentheses and semicolons, you can supply multi-statement expressions.



\href{https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/cartesian.jl#L9-L37}{\texttt{source}}


\end{adjustwidth}
\hypertarget{5318613607184308860}{} 
\hyperlink{5318613607184308860}{\texttt{Base.Cartesian.@nref}}  -- {Macro.}

\begin{adjustwidth}{2em}{0pt}


\begin{minted}{julia}
@nref N A indexexpr
\end{minted}

Generate expressions like \texttt{A[i\_1, i\_2, ...]}. \texttt{indexexpr} can either be an iteration-symbol prefix, or an anonymous-function expression.

\textbf{Examples}


\begin{minted}{jlcon}
julia> @macroexpand Base.Cartesian.@nref 3 A i
:(A[i_1, i_2, i_3])
\end{minted}



\href{https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/cartesian.jl#L72-L83}{\texttt{source}}


\end{adjustwidth}
\hypertarget{5592996802344748158}{} 
\hyperlink{5592996802344748158}{\texttt{Base.Cartesian.@nextract}}  -- {Macro.}

\begin{adjustwidth}{2em}{0pt}


\begin{minted}{julia}
@nextract N esym isym
\end{minted}

Generate \texttt{N} variables \texttt{esym\_1}, \texttt{esym\_2}, ..., \texttt{esym\_N} to extract values from \texttt{isym}. \texttt{isym} can be either a \texttt{Symbol} or anonymous-function expression.

\texttt{@nextract 2 x y} would generate


\begin{lstlisting}
x_1 = y[1]
x_2 = y[2]
\end{lstlisting}

while \texttt{@nextract 3 x d->y[2d-1]} yields


\begin{lstlisting}
x_1 = y[1]
x_2 = y[3]
x_3 = y[5]
\end{lstlisting}



\href{https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/cartesian.jl#L132-L149}{\texttt{source}}


\end{adjustwidth}
\hypertarget{17386123129446980507}{} 
\hyperlink{17386123129446980507}{\texttt{Base.Cartesian.@nexprs}}  -- {Macro.}

\begin{adjustwidth}{2em}{0pt}


\begin{minted}{julia}
@nexprs N expr
\end{minted}

Generate \texttt{N} expressions. \texttt{expr} should be an anonymous-function expression.

\textbf{Examples}


\begin{minted}{jlcon}
julia> @macroexpand Base.Cartesian.@nexprs 4 i -> y[i] = A[i+j]
quote
    y[1] = A[1 + j]
    y[2] = A[2 + j]
    y[3] = A[3 + j]
    y[4] = A[4 + j]
end
\end{minted}



\href{https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/cartesian.jl#L111-L126}{\texttt{source}}


\end{adjustwidth}
\hypertarget{16431416314224139891}{} 
\hyperlink{16431416314224139891}{\texttt{Base.Cartesian.@ncall}}  -- {Macro.}

\begin{adjustwidth}{2em}{0pt}


\begin{minted}{julia}
@ncall N f sym...
\end{minted}

Generate a function call expression. \texttt{sym} represents any number of function arguments, the last of which may be an anonymous-function expression and is expanded into \texttt{N} arguments.

For example, \texttt{@ncall 3 func a} generates


\begin{lstlisting}
func(a_1, a_2, a_3)
\end{lstlisting}

while \texttt{@ncall 2 func a b i->c[i]} yields


\begin{lstlisting}
func(a, b, c[1], c[2])
\end{lstlisting}



\href{https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/cartesian.jl#L89-L103}{\texttt{source}}


\end{adjustwidth}
\hypertarget{4425932542618492714}{} 
\hyperlink{4425932542618492714}{\texttt{Base.Cartesian.@ntuple}}  -- {Macro.}

\begin{adjustwidth}{2em}{0pt}


\begin{minted}{julia}
@ntuple N expr
\end{minted}

Generates an \texttt{N}-tuple. \texttt{@ntuple 2 i} would generate \texttt{(i\_1, i\_2)}, and \texttt{@ntuple 2 k->k+1} would generate \texttt{(2,3)}.



\href{https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/cartesian.jl#L193-L198}{\texttt{source}}


\end{adjustwidth}
\hypertarget{5463798602076286002}{} 
\hyperlink{5463798602076286002}{\texttt{Base.Cartesian.@nall}}  -- {Macro.}

\begin{adjustwidth}{2em}{0pt}


\begin{minted}{julia}
@nall N expr
\end{minted}

Check whether all of the expressions generated by the anonymous-function expression \texttt{expr} evaluate to \texttt{true}.

\texttt{@nall 3 d->(i\_d > 1)} would generate the expression \texttt{(i\_1 > 1 \&\& i\_2 > 1 \&\& i\_3 > 1)}. This can be convenient for bounds-checking.



\href{https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/cartesian.jl#L160-L168}{\texttt{source}}


\end{adjustwidth}
\hypertarget{11114957141394185901}{} 
\hyperlink{11114957141394185901}{\texttt{Base.Cartesian.@nany}}  -- {Macro.}

\begin{adjustwidth}{2em}{0pt}


\begin{minted}{julia}
@nany N expr
\end{minted}

Check whether any of the expressions generated by the anonymous-function expression \texttt{expr} evaluate to \texttt{true}.

\texttt{@nany 3 d->(i\_d > 1)} would generate the expression \texttt{(i\_1 > 1 || i\_2 > 1 || i\_3 > 1)}.



\href{https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/cartesian.jl#L177-L184}{\texttt{source}}


\end{adjustwidth}
\hypertarget{2428714678347040919}{} 
\hyperlink{2428714678347040919}{\texttt{Base.Cartesian.@nif}}  -- {Macro.}

\begin{adjustwidth}{2em}{0pt}


\begin{minted}{julia}
@nif N conditionexpr expr
@nif N conditionexpr expr elseexpr
\end{minted}

Generates a sequence of \texttt{if ... elseif ... else ... end} statements. For example:


\begin{lstlisting}
@nif 3 d->(i_d >= size(A,d)) d->(error("Dimension ", d, " too big")) d->println("All OK")
\end{lstlisting}

would generate:


\begin{lstlisting}
if i_1 > size(A, 1)
    error("Dimension ", 1, " too big")
elseif i_2 > size(A, 2)
    error("Dimension ", 2, " too big")
else
    println("All OK")
end
\end{lstlisting}



\href{https://github.com/JuliaLang/julia/blob/44fa15b1502a45eac76c9017af94332d4557b251/base/cartesian.jl#L204-L221}{\texttt{source}}


\end{adjustwidth}

\hypertarget{8046590092133914049}{}


\section{Talking to the compiler (the \texttt{:meta} mechanism)}



In some circumstances, one might wish to provide hints or instructions that a given block of code has special properties: you might always want to inline it, or you might want to turn on special compiler optimization passes.  Starting with version 0.4, Julia has a convention that these instructions can be placed inside a \texttt{:meta} expression, which is typically (but not necessarily) the first expression in the body of a function.



\texttt{:meta} expressions are created with macros. As an example, consider the implementation of the \texttt{@inline} macro:




\begin{minted}{julia}
macro inline(ex)
    esc(isa(ex, Expr) ? pushmeta!(ex, :inline) : ex)
end
\end{minted}



Here, \texttt{ex} is expected to be an expression defining a function. A statement like this:




\begin{minted}{julia}
@inline function myfunction(x)
    x*(x+3)
end
\end{minted}



gets turned into an expression like this:




\begin{minted}{julia}
quote
    function myfunction(x)
        Expr(:meta, :inline)
        x*(x+3)
    end
end
\end{minted}



\texttt{Base.pushmeta!(ex, :symbol, args...)} appends \texttt{:symbol} to the end of the \texttt{:meta} expression, creating a new \texttt{:meta} expression if necessary. If \texttt{args} is specified, a nested expression containing \texttt{:symbol} and these arguments is appended instead, which can be used to specify additional information.



To use the metadata, you have to parse these \texttt{:meta} expressions. If your implementation can be performed within Julia, \texttt{Base.popmeta!} is very handy: \texttt{Base.popmeta!(body, :symbol)} will scan a function \emph{body} expression (one without the function signature) for the first \texttt{:meta} expression containing \texttt{:symbol}, extract any arguments, and return a tuple \texttt{(found::Bool, args::Array\{Any\})}. If the metadata did not have any arguments, or \texttt{:symbol} was not found, the \texttt{args} array will be empty.



Not yet provided is a convenient infrastructure for parsing \texttt{:meta} expressions from C++.



\hypertarget{9937121124855315153}{}


\section{子数组}



Julia 的 \texttt{SubArray} 类型是编码父类型 \hyperlink{6514416309183787338}{\texttt{AbstractArray}} 的“视图”的一个容器。本页介绍了 \texttt{SubArray} 的一些设计原则和实现。



One of the major design goals is to ensure high performance for views of both \hyperlink{1761039776681330940}{\texttt{IndexLinear}} and \hyperlink{4052302263500310575}{\texttt{IndexCartesian}} arrays. Furthermore, views of \texttt{IndexLinear} arrays should themselves be \texttt{IndexLinear} to the extent that it is possible.



\hypertarget{5581126844733696350}{}


\subsection{Index replacement}



Consider making 2d slices of a 3d array:






\begin{minted}{jlcon}
julia> A = rand(2,3,4);

julia> S1 = view(A, :, 1, 2:3)
2×2 view(::Array{Float64,3}, :, 1, 2:3) with eltype Float64:
 0.200586  0.066423
 0.298614  0.956753

julia> S2 = view(A, 1, :, 2:3)
3×2 view(::Array{Float64,3}, 1, :, 2:3) with eltype Float64:
 0.200586  0.066423
 0.246837  0.646691
 0.648882  0.276021
\end{minted}





\texttt{view} drops {\textquotedbl}singleton{\textquotedbl} dimensions (ones that are specified by an \texttt{Int}), so both \texttt{S1} and \texttt{S2} are two-dimensional \texttt{SubArray}s. Consequently, the natural way to index these is with \texttt{S1[i,j]}. To extract the value from the parent array \texttt{A}, the natural approach is to replace \texttt{S1[i,j]} with \texttt{A[i,1,(2:3)[j]]} and \texttt{S2[i,j]} with \texttt{A[1,i,(2:3)[j]]}.



The key feature of the design of SubArrays is that this index replacement can be performed without any runtime overhead.



\hypertarget{2778530023624514912}{}


\subsection{SubArray design}



\hypertarget{13587272900516328040}{}


\subsubsection{Type parameters and fields}



The strategy adopted is first and foremost expressed in the definition of the type:




\begin{minted}{julia}
struct SubArray{T,N,P,I,L} <: AbstractArray{T,N}
    parent::P
    indices::I
    offset1::Int       # for linear indexing and pointer, only valid when L==true
    stride1::Int       # used only for linear indexing
    ...
end
\end{minted}



\texttt{SubArray} has 5 type parameters.  The first two are the standard element type and dimensionality.  The next is the type of the parent \texttt{AbstractArray}.  The most heavily-used is the fourth parameter, a \texttt{Tuple} of the types of the indices for each dimension. The final one, \texttt{L}, is only provided as a convenience for dispatch; it{\textquotesingle}s a boolean that represents whether the index types support fast linear indexing. More on that later.



If in our example above \texttt{A} is a \texttt{Array\{Float64, 3\}}, our \texttt{S1} case above would be a \texttt{SubArray\{Float64,2,Array\{Float64,3\},Tuple\{Base.Slice\{Base.OneTo\{Int64\}\},Int64,UnitRange\{Int64\}\},false\}}. Note in particular the tuple parameter, which stores the types of the indices used to create \texttt{S1}. Likewise,




\begin{minted}{jlcon}
julia> S1.indices
(Base.Slice(Base.OneTo(2)), 1, 2:3)
\end{minted}



Storing these values allows index replacement, and having the types encoded as parameters allows one to dispatch to efficient algorithms.



\hypertarget{7039991064739471489}{}


\subsubsection{Index translation}



Performing index translation requires that you do different things for different concrete \texttt{SubArray} types.  For example, for \texttt{S1}, one needs to apply the \texttt{i,j} indices to the first and third dimensions of the parent array, whereas for \texttt{S2} one needs to apply them to the second and third.  The simplest approach to indexing would be to do the type-analysis at runtime:




\begin{minted}{julia}
parentindices = Vector{Any}()
for thisindex in S.indices
    ...
    if isa(thisindex, Int)
        # Don't consume one of the input indices
        push!(parentindices, thisindex)
    elseif isa(thisindex, AbstractVector)
        # Consume an input index
        push!(parentindices, thisindex[inputindex[j]])
        j += 1
    elseif isa(thisindex, AbstractMatrix)
        # Consume two input indices
        push!(parentindices, thisindex[inputindex[j], inputindex[j+1]])
        j += 2
    elseif ...
end
S.parent[parentindices...]
\end{minted}



Unfortunately, this would be disastrous in terms of performance: each element access would allocate memory, and involves the running of a lot of poorly-typed code.



The better approach is to dispatch to specific methods to handle each type of stored index. That{\textquotesingle}s what \texttt{reindex} does: it dispatches on the type of the first stored index and consumes the appropriate number of input indices, and then it recurses on the remaining indices. In the case of \texttt{S1}, this expands to




\begin{minted}{julia}
Base.reindex(S1, S1.indices, (i, j)) == (i, S1.indices[2], S1.indices[3][j])
\end{minted}



for any pair of indices \texttt{(i,j)} (except \hyperlink{4571802376991525093}{\texttt{CartesianIndex}}s and arrays thereof, see below).



This is the core of a \texttt{SubArray}; indexing methods depend upon \texttt{reindex} to do this index translation. Sometimes, though, we can avoid the indirection and make it even faster.



\hypertarget{18413909182716267462}{}


\subsubsection{Linear indexing}



Linear indexing can be implemented efficiently when the entire array has a single stride that separates successive elements, starting from some offset. This means that we can pre-compute these values and represent linear indexing simply as an addition and multiplication, avoiding the indirection of \texttt{reindex} and (more importantly) the slow computation of the cartesian coordinates entirely.



For \texttt{SubArray} types, the availability of efficient linear indexing is based purely on the types of the indices, and does not depend on values like the size of the parent array. You can ask whether a given set of indices supports fast linear indexing with the internal \texttt{Base.viewindexing} function:




\begin{minted}{jlcon}
julia> Base.viewindexing(S1.indices)
IndexCartesian()

julia> Base.viewindexing(S2.indices)
IndexLinear()
\end{minted}



This is computed during construction of the \texttt{SubArray} and stored in the \texttt{L} type parameter as a boolean that encodes fast linear indexing support. While not strictly necessary, it means that we can define dispatch directly on \texttt{SubArray\{T,N,A,I,true\}} without any intermediaries.



Since this computation doesn{\textquotesingle}t depend on runtime values, it can miss some cases in which the stride happens to be uniform:




\begin{minted}{jlcon}
julia> A = reshape(1:4*2, 4, 2)
4×2 reshape(::UnitRange{Int64}, 4, 2) with eltype Int64:
 1  5
 2  6
 3  7
 4  8

julia> diff(A[2:2:4,:][:])
3-element Array{Int64,1}:
 2
 2
 2
\end{minted}



A view constructed as \texttt{view(A, 2:2:4, :)} happens to have uniform stride, and therefore linear indexing indeed could be performed efficiently.  However, success in this case depends on the size of the array: if the first dimension instead were odd,




\begin{minted}{jlcon}
julia> A = reshape(1:5*2, 5, 2)
5×2 reshape(::UnitRange{Int64}, 5, 2) with eltype Int64:
 1   6
 2   7
 3   8
 4   9
 5  10

julia> diff(A[2:2:4,:][:])
3-element Array{Int64,1}:
 2
 3
 2
\end{minted}



then \texttt{A[2:2:4,:]} does not have uniform stride, so we cannot guarantee efficient linear indexing.  Since we have to base this decision based purely on types encoded in the parameters of the \texttt{SubArray}, \texttt{S = view(A, 2:2:4, :)} cannot implement efficient linear indexing.



\hypertarget{6217885754113158897}{}


\subsubsection{A few details}



\begin{itemize}
\item Note that the \texttt{Base.reindex} function is agnostic to the types of the input indices; it simply determines how and where the stored indices should be reindexed. It not only supports integer indices, but it supports non-scalar indexing, too. This means that views of views don{\textquotesingle}t need two levels of indirection; they can simply re-compute the indices into the original parent array!


\item Hopefully by now it{\textquotesingle}s fairly clear that supporting slices means that the dimensionality, given by the parameter \texttt{N}, is not necessarily equal to the dimensionality of the parent array or the length of the \texttt{indices} tuple.  Neither do user-supplied indices necessarily line up with entries in the \texttt{indices} tuple (e.g., the second user-supplied index might correspond to the third dimension of the parent array, and the third element in the \texttt{indices} tuple).

What might be less obvious is that the dimensionality of the stored parent array must be equal to the number of effective indices in the \texttt{indices} tuple. Some examples:


\begin{minted}{julia}
A = reshape(1:35, 5, 7) # A 2d parent Array
S = view(A, 2:7)         # A 1d view created by linear indexing
S = view(A, :, :, 1:1)   # Appending extra indices is supported
\end{minted}

Naively, you{\textquotesingle}d think you could just set \texttt{S.parent = A} and \texttt{S.indices = (:,:,1:1)}, but supporting this dramatically complicates the reindexing process, especially for views of views. Not only do you need to dispatch on the types of the stored indices, but you need to examine whether a given index is the final one and {\textquotedbl}merge{\textquotedbl} any remaining stored indices together. This is not an easy task, and even worse: it{\textquotesingle}s slow since it implicitly depends upon linear indexing.

Fortunately, this is precisely the computation that \texttt{ReshapedArray} performs, and it does so linearly if possible. Consequently, \texttt{view} ensures that the parent array is the appropriate dimensionality for the given indices by reshaping it if needed. The inner \texttt{SubArray} constructor ensures that this invariant is satisfied.


\item \hyperlink{4571802376991525093}{\texttt{CartesianIndex}} and arrays thereof throw a nasty wrench into the \texttt{reindex} scheme. Recall that \texttt{reindex} simply dispatches on the type of the stored indices in order to determine how many passed indices should be used and where they should go. But with \texttt{CartesianIndex}, there{\textquotesingle}s no longer a one-to-one correspondence between the number of passed arguments and the number of dimensions that they index into. If we return to the above example of \texttt{Base.reindex(S1, S1.indices, (i, j))}, you can see that the expansion is incorrect for \texttt{i, j = CartesianIndex(), CartesianIndex(2,1)}. It should \emph{skip} the \texttt{CartesianIndex()} entirely and return:


\begin{minted}{julia}
(CartesianIndex(2,1)[1], S1.indices[2], S1.indices[3][CartesianIndex(2,1)[2]])
\end{minted}

Instead, though, we get:


\begin{minted}{julia}
(CartesianIndex(), S1.indices[2], S1.indices[3][CartesianIndex(2,1)])
\end{minted}

Doing this correctly would require \emph{combined} dispatch on both the stored and passed indices across all combinations of dimensionalities in an intractable manner. As such, \texttt{reindex} must never be called with \texttt{CartesianIndex} indices. Fortunately, the scalar case is easily handled by first flattening the \texttt{CartesianIndex} arguments to plain integers. Arrays of \texttt{CartesianIndex}, however, cannot be split apart into orthogonal pieces so easily. Before attempting to use \texttt{reindex}, \texttt{view} must ensure that there are no arrays of \texttt{CartesianIndex} in the argument list. If there are, it can simply {\textquotedbl}punt{\textquotedbl} by avoiding the \texttt{reindex} calculation entirely, constructing a nested \texttt{SubArray} with two levels of indirection instead.

\end{itemize}


\hypertarget{9194487374122863540}{}


\section{isbits Union Optimizations}



In Julia, the \texttt{Array} type holds both {\textquotedbl}bits{\textquotedbl} values as well as heap-allocated {\textquotedbl}boxed{\textquotedbl} values. The distinction is whether the value itself is stored inline (in the direct allocated memory of the array), or if the memory of the array is simply a collection of pointers to objects allocated elsewhere. In terms of performance, accessing values inline is clearly an advantage over having to follow a pointer to the actual value. The definition of {\textquotedbl}isbits{\textquotedbl} generally means any Julia type with a fixed, determinate size, meaning no {\textquotedbl}pointer{\textquotedbl} fields, see \texttt{?isbitstype}.



Julia also supports Union types, quite literally the union of a set of types. Custom Union type definitions can be extremely handy for applications wishing to {\textquotedbl}cut across{\textquotedbl} the nominal type system (i.e. explicit subtype relationships) and define methods or functionality on these, otherwise unrelated, set of types. A compiler challenge, however, is in determining how to treat these Union types. The naive approach (and indeed, what Julia itself did pre-0.7), is to simply make a {\textquotedbl}box{\textquotedbl} and then a pointer in the box to the actual value, similar to the previously mentioned {\textquotedbl}boxed{\textquotedbl} values. This is unfortunate, however, because of the number of small, primitive {\textquotedbl}bits{\textquotedbl} types (think \texttt{UInt8}, \texttt{Int32}, \texttt{Float64}, etc.) that would easily fit themselves inline in this {\textquotedbl}box{\textquotedbl} without needing any indirection for value access. There are two main ways Julia can take advantage of this optimization as of 0.7: isbits Union fields in types, and isbits Union Arrays.



\hypertarget{4239563333738868441}{}


\subsection{isbits Union Structs}



Julia now includes an optimization wherein {\textquotedbl}isbits Union{\textquotedbl} fields in types (\texttt{mutable struct}, \texttt{struct}, etc.) will be stored inline. This is accomplished by determining the {\textquotedbl}inline size{\textquotedbl} of the Union type (e.g. \texttt{Union\{UInt8, Int16\}} will have a size of two bytes, which represents the size needed of the largest Union type \texttt{Int16}), and in addition, allocating an extra {\textquotedbl}type tag byte{\textquotedbl} (\texttt{UInt8}), whose value signals the type of the actual value stored inline of the {\textquotedbl}Union bytes{\textquotedbl}. The type tag byte value is the index of the actual value{\textquotesingle}s type in the Union type{\textquotesingle}s order of types. For example, a type tag value of \texttt{0x02} for a field with type \texttt{Union\{Nothing, UInt8, Int16\}} would indicate that an \texttt{Int16} value is stored in the 16 bits of the field in the structure{\textquotesingle}s memory; a \texttt{0x01} value would indicate that a \texttt{UInt8} value was stored in the first 8 bits of the 16 bits of the field{\textquotesingle}s memory. Lastly, a value of \texttt{0x00} signals that the \texttt{nothing} value will be returned for this field, even though, as a singleton type with a single type instance, it technically has a size of 0. The type tag byte for a type{\textquotesingle}s Union field is stored directly after the field{\textquotesingle}s computed Union memory.



\hypertarget{3119783438553475290}{}


\subsection{isbits Union Arrays}



Julia can now also store {\textquotedbl}isbits Union{\textquotedbl} values inline in an Array, as opposed to requiring an indirection box. The optimization is accomplished by storing an extra {\textquotedbl}type tag array{\textquotedbl} of bytes, one byte per array element, alongside the bytes of the actual array data. This type tag array serves the same function as the type field case: its value signals the type of the actual stored Union value in the array. In terms of layout, a Julia Array can include extra {\textquotedbl}buffer{\textquotedbl} space before and after its actual data values, which are tracked in the \texttt{a->offset} and \texttt{a->maxsize} fields of the \texttt{jl\_array\_t*} type. The {\textquotedbl}type tag array{\textquotedbl} is treated exactly as another \texttt{jl\_array\_t*}, but which shares the same \texttt{a->offset}, \texttt{a->maxsize}, and \texttt{a->len} fields. So the formula to access an isbits Union Array{\textquotesingle}s type tag bytes is \texttt{a->data + (a->maxsize - a->offset) * a->elsize + a->offset}; i.e. the Array{\textquotesingle}s \texttt{a->data} pointer is already shifted by \texttt{a->offset}, so correcting for that, we follow the data all the way to the max of what it can hold \texttt{a->maxsize}, then adjust by \texttt{a->ofset} more bytes to account for any present {\textquotedbl}front buffering{\textquotedbl} the array might be doing. This layout in particular allows for very efficient resizing operations as the type tag data only ever has to move when the actual array{\textquotesingle}s data has to move.



\hypertarget{6450179845418792741}{}


\section{System Image Building}



\hypertarget{2889722918811470983}{}


\subsection{Building the Julia system image}



Julia ships with a preparsed system image containing the contents of the \texttt{Base} module, named \texttt{sys.ji}.  This file is also precompiled into a shared library called \texttt{sys.\{so,dll,dylib\}} on as many platforms as possible, so as to give vastly improved startup times.  On systems that do not ship with a precompiled system image file, one can be generated from the source files shipped in Julia{\textquotesingle}s \texttt{DATAROOTDIR/julia/base} folder.



This operation is useful for multiple reasons.  A user may:



\begin{itemize}
\item Build a precompiled shared library system image on a platform that did not ship with one, thereby improving startup times.


\item Modify \texttt{Base}, rebuild the system image and use the new \texttt{Base} next time Julia is started.


\item Include a \texttt{userimg.jl} file that includes packages into the system image, thereby creating a system image that has packages embedded into the startup environment.

\end{itemize}


The \href{https://github.com/JuliaLang/PackageCompiler.jl}{\texttt{PackageCompiler.jl} package} contains convenient wrapper functions to automate this process.



\hypertarget{6216163822526201376}{}


\subsection{System image optimized for multiple microarchitectures}



The system image can be compiled simultaneously for multiple CPU microarchitectures under the same instruction set architecture (ISA). Multiple versions of the same function may be created with minimum dispatch point inserted into shared functions in order to take advantage of different ISA extensions or other microarchitecture features. The version that offers the best performance will be selected automatically at runtime based on available CPU features.



\hypertarget{7911922725601251657}{}


\subsubsection{Specifying multiple system image targets}



A multi-microarchitecture system image can be enabled by passing multiple targets during system image compilation. This can be done either with the \texttt{JULIA\_CPU\_TARGET} make option or with the \texttt{-C} command line option when running the compilation command manually. Multiple targets are separated by \texttt{;} in the option string. The syntax for each target is a CPU name followed by multiple features separated by \texttt{,}. All features supported by LLVM are supported and a feature can be disabled with a \texttt{-} prefix. (\texttt{+} prefix is also allowed and ignored to be consistent with LLVM syntax). Additionally, a few special features are supported to control the function cloning behavior.



\begin{itemize}
\item[1. ] \texttt{clone\_all}

By default, only functions that are the most likely to benefit from  the microarchitecture features will be cloned.  When \texttt{clone\_all} is specified for a target, however,  \textbf{all} functions in the system image will be cloned for the target.  The negative form \texttt{-clone\_all} can be used to prevent the built-in  heuristic from cloning all functions.


\item[2. ] \texttt{base(<n>)}

Where \texttt{<n>} is a placeholder for a non-negative number (e.g. \texttt{base(0)}, \texttt{base(1)}).  By default, a partially cloned (i.e. not \texttt{clone\_all}) target will use functions  from the default target (first one specified) if a function is not cloned.  This behavior can be changed by specifying a different base with the \texttt{base(<n>)} option.  The \texttt{n}th target (0-based) will be used as the base target instead of the default (\texttt{0}th) one.  The base target has to be either \texttt{0} or another \texttt{clone\_all} target.  Specifying a non-\texttt{clone\_all} target as the base target will cause an error.


\item[3. ] \texttt{opt\_size}

This causes the function for the target to be optimized for size when there isn{\textquotesingle}t a significant  runtime performance impact. This corresponds to \texttt{-Os} GCC and Clang option.


\item[4. ] \texttt{min\_size}

This causes the function for the target to be optimized for size that might have  a significant runtime performance impact. This corresponds to \texttt{-Oz} Clang option.

\end{itemize}


As an example, at the time of this writing, the following string is used in the creation of the official \texttt{x86\_64} Julia binaries downloadable from julialang.org:




\begin{lstlisting}
generic;sandybridge,-xsaveopt,clone_all;haswell,-rdrnd,base(1)
\end{lstlisting}



This creates a system image with three separate targets; one for a generic \texttt{x86\_64} processor, one with a \texttt{sandybridge} ISA (explicitly excluding \texttt{xsaveopt}) that explicitly clones all functions, and one targeting the \texttt{haswell} ISA, based off of the \texttt{sandybridge} sysimg version, and also excluding \texttt{rdrnd}.  When a Julia implementation loads the generated sysimg, it will check the host processor for matching CPU capability flags, enabling the highest ISA level possible.  Note that the base level (\texttt{generic}) requires the \texttt{cx16} instruction, which is disabled in some virtualization software and must be enabled for the \texttt{generic} target to be loaded.  Alternatively, a sysimg could be generated with the target \texttt{generic,-cx16} for greater compatibility, however note that this may cause performance and stability problems in some code.



\hypertarget{6161913736473072394}{}


\subsubsection{Implementation overview}



This is a brief overview of different part involved in the implementation. See code comments for each components for more implementation details.



\begin{itemize}
\item[1. ] System image compilation

The parsing and cloning decision are done in \texttt{src/processor*}.  We currently support cloning of function based on the present of loops, simd instructions,  or other math operations (e.g. fastmath, fma, muladd).  This information is passed on to \texttt{src/llvm-multiversioning.cpp} which does the actual cloning.  In addition to doing the cloning and insert dispatch slots  (see comments in \texttt{MultiVersioning::runOnModule} for how this is done),  the pass also generates metadata so that the runtime can load and initialize the  system image correctly.  A detail description of the metadata is available in \texttt{src/processor.h}.


\item[2. ] System image loading

The loading and initialization of the system image is done in \texttt{src/processor*} by  parsing the metadata saved during system image generation.  Host feature detection and selection decision are done in \texttt{src/processor\_*.cpp}  depending on the ISA. The target selection will prefer exact CPU name match,  larger vector register size, and larget number of features.  An overview of this process is in \texttt{src/processor.cpp}.

\end{itemize}


\hypertarget{5125896206531208336}{}


\section{Working with LLVM}



This is not a replacement for the LLVM documentation, but a collection of tips for working on LLVM for Julia.



\hypertarget{8956364453365125987}{}


\subsection{Overview of Julia to LLVM Interface}



Julia dynamically links against LLVM by default. Build with \texttt{USE\_LLVM\_SHLIB=0} to link statically.



The code for lowering Julia AST to LLVM IR or interpreting it directly is in directory \texttt{src/}.




\begin{table}[h]

\begin{tabulary}{\linewidth}{|L|L|}
\hline
File & Description \\
\hline
\texttt{builtins.c} & Builtin functions \\
\hline
\texttt{ccall.cpp} & Lowering \hyperlink{14245046751182637566}{\texttt{ccall}} \\
\hline
\texttt{cgutils.cpp} & Lowering utilities, notably for array and tuple accesses \\
\hline
\texttt{codegen.cpp} & Top-level of code generation, pass list, lowering builtins \\
\hline
\texttt{debuginfo.cpp} & Tracks debug information for JIT code \\
\hline
\texttt{disasm.cpp} & Handles native object file and JIT code diassembly \\
\hline
\texttt{gf.c} & Generic functions \\
\hline
\texttt{intrinsics.cpp} & Lowering intrinsics \\
\hline
\texttt{llvm-simdloop.cpp} & Custom LLVM pass for \hyperlink{8155428559748374852}{\texttt{@simd}} \\
\hline
\texttt{sys.c} & I/O and operating system utility functions \\
\hline
\end{tabulary}

\end{table}



Some of the \texttt{.cpp} files form a group that compile to a single object.



The difference between an intrinsic and a builtin is that a builtin is a first class function that can be used like any other Julia function.  An intrinsic can operate only on unboxed data, and therefore its arguments must be statically typed.



\hypertarget{8366324567299313031}{}


\subsubsection{Alias Analysis}



Julia currently uses LLVM{\textquotesingle}s \href{http://llvm.org/docs/LangRef.html\#tbaa-metadata}{Type Based Alias Analysis}. To find the comments that document the inclusion relationships, look for \texttt{static MDNode*} in \texttt{src/codegen.cpp}.



The \texttt{-O} option enables LLVM{\textquotesingle}s \href{http://llvm.org/docs/AliasAnalysis.html\#the-basicaa-pass}{Basic Alias Analysis}.



\hypertarget{13120458447023898074}{}


\subsection{Building Julia with a different version of LLVM}



The default version of LLVM is specified in \texttt{deps/Versions.make}. You can override it by creating a file called \texttt{Make.user} in the top-level directory and adding a line to it such as:




\begin{lstlisting}
LLVM_VER = 6.0.1
\end{lstlisting}



Besides the LLVM release numerals, you can also use \texttt{LLVM\_VER = svn} to build against the latest development version of LLVM.



You can also specify to build a debug version of LLVM, by setting either \texttt{LLVM\_DEBUG = 1} or \texttt{LLVM\_DEBUG = Release} in your \texttt{Make.user} file. The former will be a fully unoptimized build of LLVM and the latter will produce an optimized build of LLVM. Depending on your needs the latter will suffice and it quite a bit faster. If you use \texttt{LLVM\_DEBUG = Release} you will also want to set \texttt{LLVM\_ASSERTIONS = 1} to enable diagonstics for different passes. Only \texttt{LLVM\_DEBUG = 1} implies that option by default.



\hypertarget{3429896864083237221}{}


\subsection{Passing options to LLVM}



You can pass options to LLVM via the environment variable \texttt{JULIA\_LLVM\_ARGS}. Here are example settings using \texttt{bash} syntax:



\begin{itemize}
\item \texttt{export JULIA\_LLVM\_ARGS = -print-after-all} dumps IR after each pass.


\item \texttt{export JULIA\_LLVM\_ARGS = -debug-only=loop-vectorize} dumps LLVM \texttt{DEBUG(...)} diagnostics for loop vectorizer. If you get warnings about {\textquotedbl}Unknown command line argument{\textquotedbl}, rebuild LLVM with \texttt{LLVM\_ASSERTIONS = 1}.

\end{itemize}


\hypertarget{7270369944062365114}{}


\subsection{Debugging LLVM transformations in isolation}



On occasion, it can be useful to debug LLVM{\textquotesingle}s transformations in isolation from the rest of the Julia system, e.g. because reproducing the issue inside \texttt{julia} would take too long, or because one wants to take advantage of LLVM{\textquotesingle}s tooling (e.g. bugpoint). To get unoptimized IR for the entire system image, pass the \texttt{--output-unopt-bc unopt.bc} option to the system image build process, which will output the unoptimized IR to an \texttt{unopt.bc} file. This file can then be passed to LLVM tools as usual. \texttt{libjulia} can function as an LLVM pass plugin and can be loaded into LLVM tools, to make julia-specific passes available in this environment. In addition, it exposes the \texttt{-julia} meta-pass, which runs the entire Julia pass-pipeline over the IR. As an example, to generate a system image, one could do:




\begin{lstlisting}
opt -load libjulia.so -julia -o opt.bc unopt.bc
llc -o sys.o opt.bc
cc -shared -o sys.so sys.o
\end{lstlisting}



This system image can then be loaded by \texttt{julia} as usual.



Alternatively, you can use \texttt{--output-jit-bc jit.bc} to obtain a trace of all IR passed to the JIT. This is useful for code that cannot be run as part of the sysimg generation process (e.g. because it creates unserializable state). However, the resulting \texttt{jit.bc} does not include sysimage data, and can thus not be used as such.



It is also possible to dump an LLVM IR module for just one Julia function, using:




\begin{minted}{julia}
fun, T = +, Tuple{Int,Int} # Substitute your function of interest here
optimize = false
open("plus.ll", "w") do file
    println(file, InteractiveUtils._dump_function(fun, T, false, false, false, true, :att, optimize, :default))
end
\end{minted}



These files can be processed the same way as the unoptimized sysimg IR shown above.



\hypertarget{18346154193244616171}{}


\subsection{Improving LLVM optimizations for Julia}



Improving LLVM code generation usually involves either changing Julia lowering to be more friendly to LLVM{\textquotesingle}s passes, or improving a pass.



If you are planning to improve a pass, be sure to read the \href{http://llvm.org/docs/DeveloperPolicy.html}{LLVM developer policy}. The best strategy is to create a code example in a form where you can use LLVM{\textquotesingle}s \texttt{opt} tool to study it and the pass of interest in isolation.



\begin{itemize}
\item[1. ] Create an example Julia code of interest.


\item[2. ] Use \texttt{JULIA\_LLVM\_ARGS = -print-after-all} to dump the IR.


\item[3. ] Pick out the IR at the point just before the pass of interest runs.


\item[4. ] Strip the debug metadata and fix up the TBAA metadata by hand.

\end{itemize}


The last step is labor intensive.  Suggestions on a better way would be appreciated.



\hypertarget{9068676689189894192}{}


\subsection{The jlcall calling convention}



Julia has a generic calling convention for unoptimized code, which looks somewhat as follows:




\begin{lstlisting}
jl_value_t *any_unoptimized_call(jl_value_t *, jl_value_t **, int);
\end{lstlisting}



where the first argument is the boxed function object, the second argument is an on-stack array of arguments and the third is the number of arguments. Now, we could perform a straightforward lowering and emit an alloca for the argument array. However, this would betray the SSA nature of the uses at the call site, making optimizations (including GC root placement), significantly harder. Instead, we emit it as follows:




\begin{lstlisting}
%bitcast = bitcast @any_unoptimized_call to %jl_value_t *(*)(%jl_value_t *, %jl_value_t *)
call cc 37 %jl_value_t *%bitcast(%jl_value_t *%arg1, %jl_value_t *%arg2)
\end{lstlisting}



The special \texttt{cc 37} annotation marks the fact that this call site is really using the jlcall calling convention. This allows us to retain the SSA-ness of the uses throughout the optimizer. GC root placement will later lower this call to the original C ABI. In the code the calling convention number is represented by the \texttt{JLCALL\_F\_CC} constant. In addition, there is the \texttt{JLCALL\_CC} calling convention which functions similarly, but omits the first argument.



\hypertarget{1193214752065867769}{}


\subsection{GC root placement}



GC root placement is done by an LLVM pass late in the pass pipeline. Doing GC root placement this late enables LLVM to make more aggressive optimizations around code that requires GC roots, as well as allowing us to reduce the number of required GC roots and GC root store operations (since LLVM doesn{\textquotesingle}t understand our GC, it wouldn{\textquotesingle}t otherwise know what it is and is not allowed to do with values stored to the GC frame, so it{\textquotesingle}ll conservatively do very little). As an example, consider an error path




\begin{minted}{julia}
if some_condition()
    #= Use some variables maybe =#
    error("An error occurred")
end
\end{minted}



During constant folding, LLVM may discover that the condition is always false, and can remove the basic block. However, if GC root lowering is done early, the GC root slots used in the deleted block, as well as any values kept alive in those slots only because they were used in the error path, would be kept alive by LLVM. By doing GC root lowering late, we give LLVM the license to do any of its usual optimizations (constant folding, dead code elimination, etc.), without having to worry (too much) about which values may or may not be GC tracked.



However, in order to be able to do late GC root placement, we need to be able to identify a) which pointers are GC tracked and b) all uses of such pointers. The goal of the GC placement pass is thus simple:



Minimize the number of needed GC roots/stores to them subject to the constraint that at every safepoint, any live GC-tracked pointer (i.e. for which there is a path after this point that contains a use of this pointer) is in some GC slot.



\hypertarget{8769102480019606347}{}


\subsubsection{Representation}



The primary difficulty is thus choosing an IR representation that allows us to identify GC-tracked pointers and their uses, even after the program has been run through the optimizer. Our design makes use of three LLVM features to achieve this:



\begin{itemize}
\item Custom address spaces


\item Operand Bundles


\item Non-integral pointers

\end{itemize}


Custom address spaces allow us to tag every point with an integer that needs to be preserved through optimizations. The compiler may not insert casts between address spaces that did not exist in the original program and it must never change the address space of a pointer on a load/store/etc operation. This allows us to annotate which pointers are GC-tracked in an optimizer-resistant way. Note that metadata would not be able to achieve the same purpose. Metadata is supposed to always be discardable without altering the semantics of the program. However, failing to identify a GC-tracked pointer alters the resulting program behavior dramatically - it{\textquotesingle}ll probably crash or return wrong results. We currently use three different address spaces (their numbers are defined in \texttt{src/codegen\_shared.cpp}):



\begin{itemize}
\item GC Tracked Pointers (currently 10): These are pointers to boxed values that may be put into a GC frame. It is loosely equivalent to a \texttt{jl\_value\_t*} pointer on the C side. N.B. It is illegal to ever have a pointer in this address space that may not be stored to a GC slot.


\item Derived Pointers (currently 11): These are pointers that are derived from some GC tracked pointer. Uses of these pointers generate uses of the original pointer. However, they need not themselves be known to the GC. The GC root placement pass MUST always find the GC tracked pointer from which this pointer is derived and use that as the pointer to root.


\item Callee Rooted Pointers (currently 12): This is a utility address space to express the notion of a callee rooted value. All values of this address space MUST be storable to a GC root (though it is possible to relax this condition in the future), but unlike the other pointers need not be rooted if passed to a call (they do still need to be rooted if they are live across another safepoint between the definition and the call).


\item Pointers loaded from tracked object (currently 13): This is used by arrays, which themselves contain a pointer to the managed data. This data area is owned by the array, but is not a GC-tracked object by itself. The compiler guarantees that as long as this pointer is live, the object that this pointer was loaded from will keep being live.

\end{itemize}


\hypertarget{10709955215160021117}{}


\subsubsection{Invariants}



The GC root placement pass makes use of several invariants, which need to be observed by the frontend and are preserved by the optimizer.



First, only the following address space casts are allowed:



\begin{itemize}
\item 0->\{Tracked,Derived,CalleeRooted\}: It is allowable to decay an untracked pointer to any of the others. However, do note that the optimizer has broad license to not root such a value. It is never safe to have a value in address space 0 in any part of the program if it is (or is derived from) a value that requires a GC root.


\item Tracked->Derived: This is the standard decay route for interior values. The placement pass will look for these to identify the base pointer for any use.


\item Tracked->CalleeRooted: Addrspace CalleeRooted serves merely as a hint that a GC root is not required. However, do note that the Derived->CalleeRooted decay is prohibited, since pointers should generally be storable to a GC slot, even in this address space.

\end{itemize}


Now let us consider what constitutes a use:



\begin{itemize}
\item Loads whose loaded values is in one of the address spaces


\item Stores of a value in one of the address spaces to a location


\item Stores to a pointer in one of the address spaces


\item Calls for which a value in one of the address spaces is an operand


\item Calls in jlcall ABI, for which the argument array contains a value


\item Return instructions.

\end{itemize}


We explicitly allow load/stores and simple calls in address spaces Tracked/Derived. Elements of jlcall argument arrays must always be in address space Tracked (it is required by the ABI that they are valid \texttt{jl\_value\_t*} pointers). The same is true for return instructions (though note that struct return arguments are allowed to have any of the address spaces). The only allowable use of an address space CalleeRooted pointer is to pass it to a call (which must have an appropriately typed operand).



Further, we disallow \texttt{getelementptr} in addrspace Tracked. This is because unless the operation is a noop, the resulting pointer will not be validly storable to a GC slot and may thus not be in this address space. If such a pointer is required, it should be decayed to addrspace Derived first.



Lastly, we disallow \texttt{inttoptr}/\texttt{ptrtoint} instructions in these address spaces. Having these instructions would mean that some \texttt{i64} values are really GC tracked. This is problematic, because it breaks that stated requirement that we{\textquotesingle}re able to identify GC-relevant pointers. This invariant is accomplished using the LLVM {\textquotedbl}non-integral pointers{\textquotedbl} feature, which is new in LLVM 5.0. It prohibits the optimizer from making optimizations that would introduce these operations. Note we can still insert static constants at JIT time by using \texttt{inttoptr} in address space 0 and then decaying to the appropriate address space afterwards.



\hypertarget{5598613901277707990}{}


\subsubsection{Supporting \texttt{ccall}}



One important aspect missing from the discussion so far is the handling of \hyperlink{14245046751182637566}{\texttt{ccall}}. \hyperlink{14245046751182637566}{\texttt{ccall}} has the peculiar feature that the location and scope of a use do not coincide. As an example consider:




\begin{minted}{julia}
A = randn(1024)
ccall(:foo, Cvoid, (Ptr{Float64},), A)
\end{minted}



In lowering, the compiler will insert a conversion from the array to the pointer which drops the reference to the array value. However, we of course need to make sure that the array does stay alive while we{\textquotesingle}re doing the \hyperlink{14245046751182637566}{\texttt{ccall}}. To understand how this is done, first recall the lowering of the above code:




\begin{minted}{julia}
return $(Expr(:foreigncall, :(:foo), Cvoid, svec(Ptr{Float64}), 0, :(:ccall), Expr(:foreigncall, :(:jl_array_ptr), Ptr{Float64}, svec(Any), 0, :(:ccall), :(A)), :(A)))
\end{minted}



The last \texttt{:(A)}, is an extra argument list inserted during lowering that informs the code generator which Julia level values need to be kept alive for the duration of this \hyperlink{14245046751182637566}{\texttt{ccall}}. We then take this information and represent it in an {\textquotedbl}operand bundle{\textquotedbl} at the IR level. An operand bundle is essentially a fake use that is attached to the call site. At the IR level, this looks like so:




\begin{lstlisting}
call void inttoptr (i64 ... to void (double*)*)(double* %5) [ "jl_roots"(%jl_value_t addrspace(10)* %A) ]
\end{lstlisting}



The GC root placement pass will treat the \texttt{jl\_roots} operand bundle as if it were a regular operand. However, as a final step, after the GC roots are inserted, it will drop the operand bundle to avoid confusing instruction selection.



\hypertarget{9100387688336588039}{}


\subsubsection{Supporting \texttt{pointer\_from\_objref}}



\hyperlink{9366554937543398846}{\texttt{pointer\_from\_objref}} is special because it requires the user to take explicit control of GC rooting. By our above invariants, this function is illegal, because it performs an address space cast from 10 to 0. However, it can be useful, in certain situations, so we provide a special intrinsic:




\begin{lstlisting}
declared %jl_value_t *julia.pointer_from_objref(%jl_value_t addrspace(10)*)
\end{lstlisting}



which is lowered to the corresponding address space cast after GC root lowering. Do note however that by using this intrinsic, the caller assumes all responsibility for making sure that the value in question is rooted. Further this intrinsic is not considered a use, so the GC root placement pass will not provide a GC root for the function. As a result, the external rooting must be arranged while the value is still tracked by the system. I.e. it is not valid to attempt to use the result of this operation to establish a global root - the optimizer may have already dropped the value.



\hypertarget{13949345143972752854}{}


\subsubsection{Keeping values alive in the absence of uses}



In certain cases it is necessary to keep an object alive, even though there is no compiler-visible use of said object. This may be case for low level code that operates on the memory-representation of an object directly or code that needs to interface with C code. In order to allow this, we provide the following intrinsics at the LLVM level:




\begin{lstlisting}
token @llvm.julia.gc_preserve_begin(...)
void @llvm.julia.gc_preserve_end(token)
\end{lstlisting}



(The \texttt{llvm.} in the name is required in order to be able to use the \texttt{token} type). The semantics of these intrinsics are as follows: At any safepoint that is dominated by a \texttt{gc\_preserve\_begin} call, but that is not not dominated by a corresponding \texttt{gc\_preserve\_end} call (i.e. a call whose argument is the token returned by a \texttt{gc\_preserve\_begin} call), the values passed as arguments to that \texttt{gc\_preserve\_begin} will be kept live. Note that the \texttt{gc\_preserve\_begin} still counts as a regular use of those values, so the standard lifetime semantics will ensure that the values will be kept alive before entering the preserve region.



\hypertarget{12315144918899798229}{}


\section{printf() and stdio in the Julia runtime}



\hypertarget{12808189198177172525}{}


\subsection{Libuv wrappers for stdio}



\texttt{julia.h} defines \href{http://docs.libuv.org}{libuv} wrappers for the \texttt{stdio.h} streams:




\begin{lstlisting}
uv_stream_t *JL_STDIN;
uv_stream_t *JL_STDOUT;
uv_stream_t *JL_STDERR;
\end{lstlisting}



... and corresponding output functions:




\begin{lstlisting}
int jl_printf(uv_stream_t *s, const char *format, ...);
int jl_vprintf(uv_stream_t *s, const char *format, va_list args);
\end{lstlisting}



These \texttt{printf} functions are used by the \texttt{.c} files in the \texttt{src/} and \texttt{ui/} directories wherever stdio is needed to ensure that output buffering is handled in a unified way.



In special cases, like signal handlers, where the full libuv infrastructure is too heavy, \texttt{jl\_safe\_printf()} can be used to \hyperlink{16947913578760238729}{\texttt{write(2)}} directly to \texttt{STDERR\_FILENO}:




\begin{lstlisting}
void jl_safe_printf(const char *str, ...);
\end{lstlisting}



\hypertarget{9919396910097555458}{}


\subsection{Interface between JL\_STD* and Julia code}



\hyperlink{3330957653919693521}{\texttt{Base.stdin}}, \hyperlink{18181294266083891471}{\texttt{Base.stdout}} and \hyperlink{6150355911915549172}{\texttt{Base.stderr}} are bound to the \texttt{JL\_STD*} libuv streams defined in the runtime.



Julia{\textquotesingle}s \texttt{\_\_init\_\_()} function (in \texttt{base/sysimg.jl}) calls \texttt{reinit\_stdio()} (in \texttt{base/stream.jl}) to create Julia objects for \hyperlink{3330957653919693521}{\texttt{Base.stdin}}, \hyperlink{18181294266083891471}{\texttt{Base.stdout}} and \hyperlink{6150355911915549172}{\texttt{Base.stderr}}.



\texttt{reinit\_stdio()} uses \hyperlink{14245046751182637566}{\texttt{ccall}} to retrieve pointers to \texttt{JL\_STD*} and calls \texttt{jl\_uv\_handle\_type()} to inspect the type of each stream.  It then creates a Julia \texttt{Base.IOStream}, \texttt{Base.TTY} or \texttt{Base.PipeEndpoint} object to represent each stream, e.g.:




\begin{lstlisting}
$ julia -e 'println(typeof((stdin, stdout, stderr)))'
Tuple{Base.TTY,Base.TTY,Base.TTY}

$ julia -e 'println(typeof((stdin, stdout, stderr)))' < /dev/null 2>/dev/null
Tuple{IOStream,Base.TTY,IOStream}

$ echo hello | julia -e 'println(typeof((stdin, stdout, stderr)))' | cat
Tuple{Base.PipeEndpoint,Base.PipeEndpoint,Base.TTY}
\end{lstlisting}



The \hyperlink{8104134490906192097}{\texttt{Base.read}} and \hyperlink{16947913578760238729}{\texttt{Base.write}} methods for these streams use \hyperlink{14245046751182637566}{\texttt{ccall}} to call libuv wrappers in \texttt{src/jl\_uv.c}, e.g.:




\begin{lstlisting}
stream.jl: function write(s::IO, p::Ptr, nb::Integer)
               -> ccall(:jl_uv_write, ...)
  jl_uv.c:          -> int jl_uv_write(uv_stream_t *stream, ...)
                        -> uv_write(uvw, stream, buf, ...)
\end{lstlisting}



\hypertarget{10878739879441287330}{}


\subsection{printf() during initialization}



The libuv streams relied upon by \texttt{jl\_printf()} etc., are not available until midway through initialization of the runtime (see \texttt{init.c}, \texttt{init\_stdio()}).  Error messages or warnings that need to be printed before this are routed to the standard C library \texttt{fwrite()} function by the following mechanism:



In \texttt{sys.c}, the \texttt{JL\_STD*} stream pointers are statically initialized to integer constants: \texttt{STD*\_FILENO (0, 1 and 2)}. In \texttt{jl\_uv.c} the \texttt{jl\_uv\_puts()} function checks its \texttt{uv\_stream\_t* stream} argument and calls \texttt{fwrite()} if stream is set to \texttt{STDOUT\_FILENO} or \texttt{STDERR\_FILENO}.



This allows for uniform use of \texttt{jl\_printf()} throughout the runtime regardless of whether or not any particular piece of code is reachable before initialization is complete.



\hypertarget{15654976823361224335}{}


\subsection{Legacy \texttt{ios.c} library}



The \texttt{src/support/ios.c} library is inherited from \href{https://github.com/JeffBezanson/femtolisp}{femtolisp}. It provides cross-platform buffered file IO and in-memory temporary buffers.



\texttt{ios.c} is still used by:



\begin{itemize}
\item \texttt{src/flisp/*.c}


\item \texttt{src/dump.c} – for serialization file IO and for memory buffers.


\item \texttt{src/staticdata.c} – for serialization file IO and for memory buffers.


\item \texttt{base/iostream.jl} – for file IO (see \texttt{base/fs.jl} for libuv equivalent).

\end{itemize}


Use of \texttt{ios.c} in these modules is mostly self-contained and separated from the libuv I/O system. However, there is \href{https://github.com/JuliaLang/julia/blob/master/src/flisp/print.c\#L654}{one place} where femtolisp calls through to \texttt{jl\_printf()} with a legacy \texttt{ios\_t} stream.



There is a hack in \texttt{ios.h} that makes the \texttt{ios\_t.bm} field line up with the \texttt{uv\_stream\_t.type} and ensures that the values used for \texttt{ios\_t.bm} to not overlap with valid \texttt{UV\_HANDLE\_TYPE} values.  This allows \texttt{uv\_stream\_t} pointers to point to \texttt{ios\_t} streams.



This is needed because \texttt{jl\_printf()} caller \texttt{jl\_static\_show()} is passed an \texttt{ios\_t} stream by femtolisp{\textquotesingle}s \texttt{fl\_print()} function. Julia{\textquotesingle}s \texttt{jl\_uv\_puts()} function has special handling for this:




\begin{lstlisting}
if (stream->type > UV_HANDLE_TYPE_MAX) {
    return ios_write((ios_t*)stream, str, n);
}
\end{lstlisting}



\hypertarget{7768027532525655179}{}


\section{边界检查}



和许多其他现代编程语言一样，Julia 在访问数组元素的时候也要通过边界检查来确保程序安全。当循环次数很多，或者在其他性能敏感的场景下，你可能希望不进行边界检查以提高运行时性能。比如要使用矢量 (SIMD) 指令，循环体就不能有分支语句，因此无法进行边界检查。Julia 提供了一个宏 \texttt{@inbounds(...)} 来告诉编译器在指定语句块不进行边界检查。用户自定义的数组类型可以通过宏 \texttt{@boundscheck(...)} 来达到上下文敏感的代码选择目的。



\hypertarget{2199104062335216769}{}


\subsection{移除边界检查}



宏 \texttt{@boundscheck(...)} 把代码块标记为要执行边界检查。但当这些代码块被被宏 \texttt{@inbounds(...)} 标记的代码包裹时，它们可能会被编译器移除。仅当\texttt{@boundscheck(...)} 代码块被调用函数包裹时，编译器会移除它们。比如你可能这样写的 \texttt{sum} 方法： 




\begin{minted}{julia}
function sum(A::AbstractArray)
    r = zero(eltype(A))
    for i = 1:length(A)
        @inbounds r += A[i]
    end
    return r
end
\end{minted}



使用自定义的类数组类型 \texttt{MyArray}，我们有：




\begin{minted}{julia}
@inline getindex(A::MyArray, i::Real) = (@boundscheck checkbounds(A,i); A.data[to_index(i)])
\end{minted}



当 \texttt{getindex} 被 \texttt{sum} 包裹时，对 \texttt{checkbounds(A,i)} 的调用会被忽略。如果存在多层包裹，最多只有一个 \texttt{@boundscheck} 被忽略。这个规则用来防止将来代码被改变时潜在的多余忽略。



\hypertarget{10208484018202603417}{}


\subsection{Propagating inbounds}



There may be certain scenarios where for code-organization reasons you want more than one layer between the \texttt{@inbounds} and \texttt{@boundscheck} declarations. For instance, the default \texttt{getindex} methods have the chain \texttt{getindex(A::AbstractArray, i::Real)} calls \texttt{getindex(IndexStyle(A), A, i)} calls \texttt{\_getindex(::IndexLinear, A, i)}.



To override the {\textquotedbl}one layer of inlining{\textquotedbl} rule, a function may be marked with \hyperlink{4942611866585954207}{\texttt{Base.@propagate\_inbounds}} to propagate an inbounds context (or out of bounds context) through one additional layer of inlining.



\hypertarget{17261866997775737461}{}


\subsection{The bounds checking call hierarchy}



The overall hierarchy is:



\begin{itemize}
\item \texttt{checkbounds(A, I...)} which calls

\begin{itemize}
\item \texttt{checkbounds(Bool, A, I...)} which calls

\begin{itemize}
\item \texttt{checkbounds\_indices(Bool, axes(A), I)} which recursively calls

\begin{itemize}
\item \texttt{checkindex} for each dimension

\end{itemize}
\end{itemize}
\end{itemize}
\end{itemize}


Here \texttt{A} is the array, and \texttt{I} contains the {\textquotedbl}requested{\textquotedbl} indices. \texttt{axes(A)} returns a tuple of {\textquotedbl}permitted{\textquotedbl} indices of \texttt{A}.



\texttt{checkbounds(A, I...)} throws an error if the indices are invalid, whereas \texttt{checkbounds(Bool, A, I...)} returns \texttt{false} in that circumstance.  \texttt{checkbounds\_indices} discards any information about the array other than its \texttt{axes} tuple, and performs a pure indices-vs-indices comparison: this allows relatively few compiled methods to serve a huge variety of array types. Indices are specified as tuples, and are usually compared in a 1-1 fashion with individual dimensions handled by calling another important function, \texttt{checkindex}: typically,




\begin{minted}{julia}
checkbounds_indices(Bool, (IA1, IA...), (I1, I...)) = checkindex(Bool, IA1, I1) &
                                                      checkbounds_indices(Bool, IA, I)
\end{minted}



so \texttt{checkindex} checks a single dimension.  All of these functions, including the unexported \texttt{checkbounds\_indices} have docstrings accessible with \texttt{?} .



If you have to customize bounds checking for a specific array type, you should specialize \texttt{checkbounds(Bool, A, I...)}. However, in most cases you should be able to rely on \texttt{checkbounds\_indices} as long as you supply useful \texttt{axes} for your array type.



If you have novel index types, first consider specializing \texttt{checkindex}, which handles a single index for a particular dimension of an array.  If you have a custom multidimensional index type (similar to \texttt{CartesianIndex}), then you may have to consider specializing \texttt{checkbounds\_indices}.



Note this hierarchy has been designed to reduce the likelihood of method ambiguities.  We try to make \texttt{checkbounds} the place to specialize on array type, and try to avoid specializations on index types; conversely, \texttt{checkindex} is intended to be specialized only on index type (especially, the last argument).



\hypertarget{17038639605096915302}{}


\section{Proper maintenance and care of multi-threading locks}



The following strategies are used to ensure that the code is dead-lock free (generally by addressing the 4th Coffman condition: circular wait).



\begin{quote}
\begin{itemize}
\item[1. ] structure code such that only one lock will need to be acquired at a time


\item[2. ] always acquire shared locks in the same order, as given by the table below


\item[3. ] avoid constructs that expect to need unrestricted recursion

\end{itemize}
\end{quote}


\hypertarget{13071695811965191352}{}


\subsection{Locks}



Below are all of the locks that exist in the system and the mechanisms for using them that avoid the potential for deadlocks (no Ostrich algorithm allowed here):



The following are definitely leaf locks (level 1), and must not try to acquire any other lock:



\begin{quote}
\begin{itemize}
\item safepoint

\begin{quote}
Note that this lock is acquired implicitly by \texttt{JL\_LOCK} and \texttt{JL\_UNLOCK}. use the \texttt{\_NOGC} variants to avoid that for level 1 locks.

While holding this lock, the code must not do any allocation or hit any safepoints. Note that there are safepoints when doing allocation, enabling / disabling GC, entering / restoring exception frames, and taking / releasing locks.

\end{quote}

\item shared\_map


\item finalizers


\item pagealloc


\item gc\emph{perm}lock


\item flisp

\begin{quote}
flisp itself is already threadsafe, this lock only protects the \texttt{jl\_ast\_context\_list\_t} pool

\end{quote}
\end{itemize}
\end{quote}


The following is a leaf lock (level 2), and only acquires level 1 locks (safepoint) internally:



\begin{quote}
\begin{itemize}
\item typecache


\item Module->lock

\end{itemize}
\end{quote}


The following is a level 3 lock, which can only acquire level 1 or level 2 locks internally:



\begin{quote}
\begin{itemize}
\item Method->writelock

\end{itemize}
\end{quote}


The following is a level 4 lock, which can only recurse to acquire level 1, 2, or 3 locks:



\begin{quote}
\begin{itemize}
\item MethodTable->writelock

\end{itemize}
\end{quote}


No Julia code may be called while holding a lock above this point.



The following are a level 6 lock, which can only recurse to acquire locks at lower levels:



\begin{quote}
\begin{itemize}
\item codegen


\item jl\emph{modules}mutex

\end{itemize}
\end{quote}


The following is an almost root lock (level end-1), meaning only the root look may be held when trying to acquire it:



\begin{quote}
\begin{itemize}
\item typeinf

\begin{quote}
this one is perhaps one of the most tricky ones, since type-inference can be invoked from many points

currently the lock is merged with the codegen lock, since they call each other recursively

\end{quote}
\end{itemize}
\end{quote}


The following lock synchronizes IO operation. Be aware that doing any I/O (for example, printing warning messages or debug information) while holding any other lock listed above may result in pernicious and hard-to-find deadlocks. BE VERY CAREFUL!



\begin{quote}
\begin{itemize}
\item iolock


\item Individual ThreadSynchronizers locks

\begin{quote}
this may continue to be held after releasing the iolock, or acquired without it, but be very careful to never attempt to acquire the iolock while holding it

\end{quote}
\end{itemize}
\end{quote}


The following is the root lock, meaning no other lock shall be held when trying to acquire it:



\begin{quote}
\begin{itemize}
\item toplevel

\begin{quote}
this should be held while attempting a top-level action (such as making a new type or defining a new method): trying to obtain this lock inside a staged function will cause a deadlock condition!

additionally, it{\textquotesingle}s unclear if \emph{any} code can safely run in parallel with an arbitrary toplevel expression, so it may require all threads to get to a safepoint first

\end{quote}
\end{itemize}
\end{quote}


\hypertarget{9065842407229995149}{}


\subsection{Broken Locks}



The following locks are broken:



\begin{itemize}
\item toplevel

\begin{quote}
doesn{\textquotesingle}t exist right now

fix: create it

\end{quote}

\item Module->lock

\begin{quote}
This is vulnerable to deadlocks since it can{\textquotesingle}t be certain it is acquired in sequence. Some operations (such as \texttt{import\_module}) are missing a lock.

fix: replace with \texttt{jl\_modules\_mutex}?

\end{quote}

\item loading.jl: \texttt{require} and \texttt{register\_root\_module}

\begin{quote}
This file potentially has numerous problems.

fix: needs locks

\end{quote}
\end{itemize}


\hypertarget{1067922422509615580}{}


\subsection{Shared Global Data Structures}



These data structures each need locks due to being shared mutable global state. It is the inverse list for the above lock priority list. This list does not include level 1 leaf resources due to their simplicity.



MethodTable modifications (def, cache, kwsorter type) : MethodTable->writelock



Type declarations : toplevel lock



Type application : typecache lock



Global variable tables : Module->lock



Module serializer : toplevel lock



JIT \& type-inference : codegen lock



MethodInstance/CodeInstance updates : Method->writelock, codegen lock



\begin{quote}
\begin{itemize}
\item These are set at construction and immutable:

\begin{itemize}
\item specTypes


\item sparam\_vals


\item def

\end{itemize}
\end{itemize}
\end{quote}


\begin{quote}
\begin{itemize}
\item These are set by \texttt{jl\_type\_infer} (while holding codegen lock):

\begin{itemize}
\item cache


\item rettype


\item inferred

\end{itemize}
\end{itemize}
\end{quote}



\begin{lstlisting}
    * valid ages
\end{lstlisting}



\begin{quote}
\begin{itemize}
\item \texttt{inInference} flag:

\begin{itemize}
\item optimization to quickly avoid recurring into \texttt{jl\_type\_infer} while it is already running


\item actual state (of setting \texttt{inferred}, then \texttt{fptr}) is protected by codegen lock

\end{itemize}
\end{itemize}
\end{quote}


\begin{quote}
\begin{itemize}
\item Function pointers:

\begin{itemize}
\item these transition once, from \texttt{NULL} to a value, while the codegen lock is held

\end{itemize}

\item Code-generator cache (the contents of \texttt{functionObjectsDecls}):

\begin{itemize}
\item these can transition multiple times, but only while the codegen lock is held


\item it is valid to use old version of this, or block for new versions of this, so races are benign, as long as the code is careful not to reference other data in the method instance (such as \texttt{rettype}) and assume it is coordinated, unless also holding the codegen lock

\end{itemize}
\end{itemize}
\end{quote}


LLVMContext : codegen lock



Method : Method->writelock



\begin{itemize}
\item roots array (serializer and codegen)


\item invoke / specializations / tfunc modifications

\end{itemize}


\hypertarget{10976543622473505620}{}


\section{Arrays with custom indices}



Conventionally, Julia{\textquotesingle}s arrays are indexed starting at 1, whereas some other languages start numbering at 0, and yet others (e.g., Fortran) allow you to specify arbitrary starting indices.  While there is much merit in picking a standard (i.e., 1 for Julia), there are some algorithms which simplify considerably if you can index outside the range \texttt{1:size(A,d)} (and not just \texttt{0:size(A,d)-1}, either). To facilitate such computations, Julia supports arrays with arbitrary indices.



The purpose of this page is to address the question, {\textquotedbl}what do I have to do to support such arrays in my own code?{\textquotedbl}  First, let{\textquotesingle}s address the simplest case: if you know that your code will never need to handle arrays with unconventional indexing, hopefully the answer is {\textquotedbl}nothing.{\textquotedbl} Old code, on conventional arrays, should function essentially without alteration as long as it was using the exported interfaces of Julia. If you find it more convenient to just force your users to supply traditional arrays where indexing starts at one, you can add




\begin{minted}{julia}
Base.require_one_based_indexing(arrays...)
\end{minted}



where \texttt{arrays...} is a list of the array objects that you wish to check for anything that violates 1-based indexing.



\hypertarget{12133789893433293548}{}


\subsection{Generalizing existing code}



As an overview, the steps are:



\begin{itemize}
\item replace many uses of \texttt{size} with \texttt{axes}


\item replace \texttt{1:length(A)} with \texttt{eachindex(A)}, or in some cases \texttt{LinearIndices(A)}


\item replace explicit allocations like \texttt{Array\{Int\}(undef, size(B))} with \texttt{similar(Array\{Int\}, axes(B))}

\end{itemize}


These are described in more detail below.



\hypertarget{3112549925833933267}{}


\subsubsection{Things to watch out for}



Because unconventional indexing breaks many people{\textquotesingle}s assumptions that all arrays start indexing with 1, there is always the chance that using such arrays will trigger errors. The most frustrating bugs would be incorrect results or segfaults (total crashes of Julia). For example, consider the following function:




\begin{minted}{julia}
function mycopy!(dest::AbstractVector, src::AbstractVector)
    length(dest) == length(src) || throw(DimensionMismatch("vectors must match"))
    # OK, now we're safe to use @inbounds, right? (not anymore!)
    for i = 1:length(src)
        @inbounds dest[i] = src[i]
    end
    dest
end
\end{minted}



This code implicitly assumes that vectors are indexed from 1; if \texttt{dest} starts at a different index than \texttt{src}, there is a chance that this code would trigger a segfault. (If you do get segfaults, to help locate the cause try running julia with the option \texttt{--check-bounds=yes}.)



\hypertarget{1628519832551402952}{}


\subsubsection{Using \texttt{axes} for bounds checks and loop iteration}



\texttt{axes(A)} (reminiscent of \texttt{size(A)}) returns a tuple of \texttt{AbstractUnitRange} objects, specifying the range of valid indices along each dimension of \texttt{A}.  When \texttt{A} has unconventional indexing, the ranges may not start at 1.  If you just want the range for a particular dimension \texttt{d}, there is \texttt{axes(A, d)}.



Base implements a custom range type, \texttt{OneTo}, where \texttt{OneTo(n)} means the same thing as \texttt{1:n} but in a form that guarantees (via the type system) that the lower index is 1. For any new \hyperlink{6514416309183787338}{\texttt{AbstractArray}} type, this is the default returned by \texttt{axes}, and it indicates that this array type uses {\textquotedbl}conventional{\textquotedbl} 1-based indexing.



For bounds checking, note that there are dedicated functions \texttt{checkbounds} and \texttt{checkindex} which can sometimes simplify such tests.



\hypertarget{15690038127583202025}{}


\subsubsection{Linear indexing (\texttt{LinearIndices})}



Some algorithms are most conveniently (or efficiently) written in terms of a single linear index, \texttt{A[i]} even if \texttt{A} is multi-dimensional. Regardless of the array{\textquotesingle}s native indices, linear indices always range from \texttt{1:length(A)}. However, this raises an ambiguity for one-dimensional arrays (a.k.a., \hyperlink{12517057979818647811}{\texttt{AbstractVector}}): does \texttt{v[i]} mean linear indexing , or Cartesian indexing with the array{\textquotesingle}s native indices?



For this reason, your best option may be to iterate over the array with \texttt{eachindex(A)}, or, if you require the indices to be sequential integers, to get the index range by calling \texttt{LinearIndices(A)}. This will return \texttt{axes(A, 1)} if A is an AbstractVector, and the equivalent of \texttt{1:length(A)} otherwise.



By this definition, 1-dimensional arrays always use Cartesian indexing with the array{\textquotesingle}s native indices. To help enforce this, it{\textquotesingle}s worth noting that the index conversion functions will throw an error if shape indicates a 1-dimensional array with unconventional indexing (i.e., is a \texttt{Tuple\{UnitRange\}} rather than a tuple of \texttt{OneTo}). For arrays with conventional indexing, these functions continue to work the same as always.



Using \texttt{axes} and \texttt{LinearIndices}, here is one way you could rewrite \texttt{mycopy!}:




\begin{minted}{julia}
function mycopy!(dest::AbstractVector, src::AbstractVector)
    axes(dest) == axes(src) || throw(DimensionMismatch("vectors must match"))
    for i in LinearIndices(src)
        @inbounds dest[i] = src[i]
    end
    dest
end
\end{minted}



\hypertarget{8664586686165592487}{}


\subsubsection{Allocating storage using generalizations of \texttt{similar}}



Storage is often allocated with \texttt{Array\{Int\}(undef, dims)} or \texttt{similar(A, args...)}. When the result needs to match the indices of some other array, this may not always suffice. The generic replacement for such patterns is to use \texttt{similar(storagetype, shape)}.  \texttt{storagetype} indicates the kind of underlying {\textquotedbl}conventional{\textquotedbl} behavior you{\textquotesingle}d like, e.g., \texttt{Array\{Int\}} or \texttt{BitArray} or even \texttt{dims->zeros(Float32, dims)} (which would allocate an all-zeros array). \texttt{shape} is a tuple of \hyperlink{8469131683393450448}{\texttt{Integer}} or \texttt{AbstractUnitRange} values, specifying the indices that you want the result to use. Note that a convenient way of producing an all-zeros array that matches the indices of A is simply \texttt{zeros(A)}.



Let{\textquotesingle}s walk through a couple of explicit examples. First, if \texttt{A} has conventional indices, then \texttt{similar(Array\{Int\}, axes(A))} would end up calling \texttt{Array\{Int\}(undef, size(A))}, and thus return an array.  If \texttt{A} is an \texttt{AbstractArray} type with unconventional indexing, then \texttt{similar(Array\{Int\}, axes(A))} should return something that {\textquotedbl}behaves like{\textquotedbl} an \texttt{Array\{Int\}} but with a shape (including indices) that matches \texttt{A}.  (The most obvious implementation is to allocate an \texttt{Array\{Int\}(undef, size(A))} and then {\textquotedbl}wrap{\textquotedbl} it in a type that shifts the indices.)



Note also that \texttt{similar(Array\{Int\}, (axes(A, 2),))} would allocate an \texttt{AbstractVector\{Int\}} (i.e., 1-dimensional array) that matches the indices of the columns of \texttt{A}.



\hypertarget{4699181205936675892}{}


\subsection{Writing custom array types with non-1 indexing}



Most of the methods you{\textquotesingle}ll need to define are standard for any \texttt{AbstractArray} type, see \hyperlink{9718377734213742156}{Abstract Arrays}. This page focuses on the steps needed to define unconventional indexing.



\hypertarget{5924242856598341681}{}


\subsubsection{Custom \texttt{AbstractUnitRange} types}



If you{\textquotesingle}re writing a non-1 indexed array type, you will want to specialize \texttt{axes} so it returns a \texttt{UnitRange}, or (perhaps better) a custom \texttt{AbstractUnitRange}.  The advantage of a custom type is that it {\textquotedbl}signals{\textquotedbl} the allocation type for functions like \texttt{similar}. If we{\textquotesingle}re writing an array type for which indexing will start at 0, we likely want to begin by creating a new \texttt{AbstractUnitRange}, \texttt{ZeroRange}, where \texttt{ZeroRange(n)} is equivalent to \texttt{0:n-1}.



In general, you should probably \emph{not} export \texttt{ZeroRange} from your package: there may be other packages that implement their own \texttt{ZeroRange}, and having multiple distinct \texttt{ZeroRange} types is (perhaps counterintuitively) an advantage: \texttt{ModuleA.ZeroRange} indicates that \texttt{similar} should create a \texttt{ModuleA.ZeroArray}, whereas \texttt{ModuleB.ZeroRange} indicates a \texttt{ModuleB.ZeroArray} type.  This design allows peaceful coexistence among many different custom array types.



Note that the Julia package \href{https://github.com/JuliaArrays/CustomUnitRanges.jl}{CustomUnitRanges.jl} can sometimes be used to avoid the need to write your own \texttt{ZeroRange} type.



\hypertarget{5545377887498946318}{}


\subsubsection{Specializing \texttt{axes}}



Once you have your \texttt{AbstractUnitRange} type, then specialize \texttt{axes}:




\begin{minted}{julia}
Base.axes(A::ZeroArray) = map(n->ZeroRange(n), A.size)
\end{minted}



where here we imagine that \texttt{ZeroArray} has a field called \texttt{size} (there would be other ways to implement this).



In some cases, the fallback definition for \texttt{axes(A, d)}:




\begin{minted}{julia}
axes(A::AbstractArray{T,N}, d) where {T,N} = d <= N ? axes(A)[d] : OneTo(1)
\end{minted}



may not be what you want: you may need to specialize it to return something other than \texttt{OneTo(1)} when \texttt{d > ndims(A)}.  Likewise, in \texttt{Base} there is a dedicated function \texttt{axes1} which is equivalent to \texttt{axes(A, 1)} but which avoids checking (at runtime) whether \texttt{ndims(A) > 0}. (This is purely a performance optimization.)  It is defined as:




\begin{minted}{julia}
axes1(A::AbstractArray{T,0}) where {T} = OneTo(1)
axes1(A::AbstractArray) = axes(A)[1]
\end{minted}



If the first of these (the zero-dimensional case) is problematic for your custom array type, be sure to specialize it appropriately.



\hypertarget{5556461946249659648}{}


\subsubsection{Specializing \texttt{similar}}



Given your custom \texttt{ZeroRange} type, then you should also add the following two specializations for \texttt{similar}:




\begin{minted}{julia}
function Base.similar(A::AbstractArray, T::Type, shape::Tuple{ZeroRange,Vararg{ZeroRange}})
    # body
end

function Base.similar(f::Union{Function,DataType}, shape::Tuple{ZeroRange,Vararg{ZeroRange}})
    # body
end
\end{minted}



Both of these should allocate your custom array type.



\hypertarget{16440701718956142132}{}


\subsubsection{Specializing \texttt{reshape}}



Optionally, define a method




\begin{lstlisting}
Base.reshape(A::AbstractArray, shape::Tuple{ZeroRange,Vararg{ZeroRange}}) = ...
\end{lstlisting}



and you can \texttt{reshape} an array so that the result has custom indices.



\hypertarget{18101383726856776769}{}


\subsubsection{For objects that mimic AbstractArray but are not subtypes}



\texttt{has\_offset\_axes} depends on having \texttt{axes} defined for the objects you call it on. If there is some reason you don{\textquotesingle}t have an \texttt{axes} method defined for your object, consider defining a method




\begin{minted}{julia}
Base.has_offset_axes(obj::MyNon1IndexedArraylikeObject) = true
\end{minted}



This will allow code that assumes 1-based indexing to detect a problem and throw a helpful error, rather than returning incorrect results or segfaulting julia.



\hypertarget{12667413576127681892}{}


\subsubsection{Catching errors}



If your new array type triggers errors in other code, one helpful debugging step can be to comment out \texttt{@boundscheck} in your \texttt{getindex} and \texttt{setindex!} implementation. This will ensure that every element access checks bounds. Or, restart julia with \texttt{--check-bounds=yes}.



In some cases it may also be helpful to temporarily disable \texttt{size} and \texttt{length} for your new array type, since code that makes incorrect assumptions frequently uses these functions.



\hypertarget{860188194179028487}{}


\section{Module loading}



\hyperlink{16690217505788642360}{\texttt{Base.require}} is responsible for loading modules and it also manages the precompilation cache. It is the implementation of the \texttt{import} statement.



\hypertarget{8895570116735182580}{}


\subsection{Experimental features}



The features below are experimental and not part of the stable Julia API. Before building upon them inform yourself about the current thinking and whether they might change soon.



\hypertarget{14149276766401458683}{}


\subsubsection{Module loading callbacks}



It is possible to listen to the modules loaded by \texttt{Base.require}, by registering a callback.




\begin{minted}{julia}
loaded_packages = Channel{Symbol}()
callback = (mod::Symbol) -> put!(loaded_packages, mod)
push!(Base.package_callbacks, callback)
\end{minted}



Please note that the symbol given to the callback is a non-unique identifier and it is the responsibility of the callback provider to walk the module chain to determine the fully qualified name of the loaded binding.



The callback below is an example of how to do that:




\begin{minted}{julia}
# Get the fully-qualified name of a module.
function module_fqn(name::Symbol)
    fqn = fullname(Base.root_module(name))
    return join(fqn, '.')
end
\end{minted}



\hypertarget{17787937227289045576}{}


\section{类型推导}



\hypertarget{2654942546276234129}{}


\subsection{类型推导是如何工作的}



\href{https://en.wikipedia.org/wiki/Type\_inference}{类型推导}指的是由输入值的类型推导其他值得类型得过程。



这两篇博客 (\href{https://juliacomputing.com/blog/2016/04/04/inference-convergence.html}{1}, \href{https://juliacomputing.com/blog/2017/05/15/inference-converage2.html}{2}) 描述了 Julia 的类型推导实现。



\hypertarget{4685549306288927755}{}


\subsection{调试 compiler.jl}



You can start a Julia session, edit \texttt{compiler/*.jl} (for example to insert \texttt{print} statements), and then replace \texttt{Core.Compiler} in your running session by navigating to \texttt{base} and executing \texttt{include({\textquotedbl}compiler/compiler.jl{\textquotedbl})}. This trick typically leads to much faster development than if you rebuild Julia for each change.



Alternatively, you can use the \href{https://github.com/timholy/Revise.jl}{Revise.jl} package to track the compiler changes by using the command \texttt{Revise.track(Core.Compiler)} at the beginning of your Julia session. As explained in the \href{https://timholy.github.io/Revise.jl/stable/}{Revise documentation}, the modifications to the compiler will be reflected when the modified files are saved.



A convenient entry point into inference is \texttt{typeinf\_code}. Here{\textquotesingle}s a demo running inference on \texttt{convert(Int, UInt(1))}:




\begin{minted}{julia}
# Get the method
atypes = Tuple{Type{Int}, UInt}  # argument types
mths = methods(convert, atypes)  # worth checking that there is only one
m = first(mths)

# Create variables needed to call `typeinf_code`
params = Core.Compiler.Params(typemax(UInt))  # parameter is the world age,
                                              # typemax(UInt) -> most recent
sparams = Core.svec()      # this particular method doesn't have type-parameters
optimize = true            # run all inference optimizations
types = Tuple{typeof(convert), atypes.parameters...} # Tuple{typeof(convert), Type{Int}, UInt}
Core.Compiler.typeinf_code(m, types, sparams, optimize, params)
\end{minted}



If your debugging adventures require a \texttt{MethodInstance}, you can look it up by calling \texttt{Core.Compiler.specialize\_method} using many of the variables above. A \texttt{CodeInfo} object may be obtained with




\begin{minted}{julia}
# Returns the CodeInfo object for `convert(Int, ::UInt)`:
ci = (@code_typed convert(Int, UInt(1)))[1]
\end{minted}



\hypertarget{3650644351684738912}{}


\subsection{The inlining algorithm (inline\_worthy)}



Much of the hardest work for inlining runs in \texttt{inlining\_pass}. However, if your question is {\textquotedbl}why didn{\textquotesingle}t my function inline?{\textquotedbl} then you will most likely be interested in \texttt{isinlineable} and its primary callee, \texttt{inline\_worthy}. \texttt{isinlineable} handles a number of special cases (e.g., critical functions like \texttt{next} and \texttt{done}, incorporating a bonus for functions that return tuples, etc.). The main decision-making happens in \texttt{inline\_worthy}, which returns \texttt{true} if the function should be inlined.



\texttt{inline\_worthy} implements a cost-model, where {\textquotedbl}cheap{\textquotedbl} functions get inlined; more specifically, we inline functions if their anticipated run-time is not large compared to the time it would take to \href{https://en.wikipedia.org/wiki/Calling\_convention}{issue a call} to them if they were not inlined. The cost-model is extremely simple and ignores many important details: for example, all \texttt{for} loops are analyzed as if they will be executed once, and the cost of an \texttt{if...else...end} includes the summed cost of all branches. It{\textquotesingle}s also worth acknowledging that we currently lack a suite of functions suitable for testing how well the cost model predicts the actual run-time cost, although \href{https://github.com/JuliaCI/BaseBenchmarks.jl}{BaseBenchmarks} provides a great deal of indirect information about the successes and failures of any modification to the inlining algorithm.



The foundation of the cost-model is a lookup table, implemented in \texttt{add\_tfunc} and its callers, that assigns an estimated cost (measured in CPU cycles) to each of Julia{\textquotesingle}s intrinsic functions. These costs are based on \href{http://ithare.com/wp-content/uploads/part101\_infographics\_v08.png}{standard ranges for common architectures} (see \href{https://www.agner.org/optimize/instruction\_tables.pdf}{Agner Fog{\textquotesingle}s analysis} for more detail).



We supplement this low-level lookup table with a number of special cases. For example, an \texttt{:invoke} expression (a call for which all input and output types were inferred in advance) is assigned a fixed cost (currently 20 cycles). In contrast, a \texttt{:call} expression, for functions other than intrinsics/builtins, indicates that the call will require dynamic dispatch, in which case we assign a cost set by \texttt{Params.inline\_nonleaf\_penalty} (currently set at 1000). Note that this is not a {\textquotedbl}first-principles{\textquotedbl} estimate of the raw cost of dynamic dispatch, but a mere heuristic indicating that dynamic dispatch is extremely expensive.



Each statement gets analyzed for its total cost in a function called \texttt{statement\_cost}. You can run this yourself by following the sketch below, where \texttt{f} is your function and \texttt{tt} is the Tuple-type of the arguments:




\begin{minted}{julia}
# A demo on `fill(3.5, (2, 3))`
f = fill
tt = Tuple{Float64, Tuple{Int,Int}}
# Create the objects we need to interact with the compiler
params = Core.Compiler.Params(typemax(UInt))
mi = Base.method_instances(f, tt)[1]
ci = code_typed(f, tt)[1][1]
opt = Core.Compiler.OptimizationState(mi, params)
# Calculate cost of each statement
cost(stmt::Expr) = Core.Compiler.statement_cost(stmt, -1, ci, opt.sptypes, opt.slottypes, opt.params)
cost(stmt) = 0
cst = map(cost, ci.code)

# output

31-element Array{Int64,1}:
  0
  0
 20
  4
  1
  1
  1
  0
  0
  0
  ⋮
  0
  0
  0
  0
  0
  0
  0
  0
  0
\end{minted}



The output is a \texttt{Vector\{Int\}} holding the estimated cost of each statement in \texttt{ci.code}.  Note that \texttt{ci} includes the consequences of inlining callees, and consequently the costs do too.



\chapter{Developing/debugging Julia's C code}


\hypertarget{14100866936909376046}{}


\section{报告和分析崩溃（段错误）}



So you managed to break Julia.  Congratulations!  Collected here are some general procedures you can undergo for common symptoms encountered when something goes awry.  Including the information from these debugging steps can greatly help the maintainers when tracking down a segfault or trying to figure out why your script is running slower than expected.



If you{\textquotesingle}ve been directed to this page, find the symptom that best matches what you{\textquotesingle}re experiencing and follow the instructions to generate the debugging information requested.  Table of symptoms:



\begin{itemize}
\item \href{@ref}{自举启动阶段的段错误 (\texttt{sysimg.jl})}


\item \href{@ref}{运行脚本时的段错误}


\item \href{@ref}{启动 Julia 时发生的段错误}

\end{itemize}


\hypertarget{13046485394122703550}{}


\subsection{版本/环境信息}



No matter the error, we will always need to know what version of Julia you are running. When Julia first starts up, a header is printed out with a version number and date. Please also include the output of \texttt{versioninfo()} (exported from the \hyperlink{11698106121547091928}{\texttt{InteractiveUtils}} standard library) in any report you create:




\begin{minted}{jlcon}
julia> using InteractiveUtils

julia> versioninfo()
Julia Version 1.4.2
Commit 44fa15b150* (2020-05-23 18:35 UTC)
Platform Info:
  OS: Windows (x86_64-w64-mingw32)
  CPU: Intel(R) Core(TM) i7-5600U CPU @ 2.60GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, broadwell)
Environment:
  JULIA_PKG_SERVER = https://mirrors.bfsu.edu.cn/julia/static
\end{minted}



\hypertarget{3553581061539675492}{}


\subsection{Segfaults during bootstrap (\texttt{sysimg.jl})}



Segfaults toward the end of the \texttt{make} process of building Julia are a common symptom of something going wrong while Julia is preparsing the corpus of code in the \texttt{base/} folder.  Many factors can contribute toward this process dying unexpectedly, however it is as often as not due to an error in the C-code portion of Julia, and as such must typically be debugged with a debug build inside of \texttt{gdb}.  Explicitly:



Create a debug build of Julia:




\begin{lstlisting}
$ cd <julia_root>
$ make debug
\end{lstlisting}



Note that this process will likely fail with the same error as a normal \texttt{make} incantation, however this will create a debug executable that will offer \texttt{gdb} the debugging symbols needed to get accurate backtraces.  Next, manually run the bootstrap process inside of \texttt{gdb}:




\begin{lstlisting}
$ cd base/
$ gdb -x ../contrib/debug_bootstrap.gdb
\end{lstlisting}



This will start \texttt{gdb}, attempt to run the bootstrap process using the debug build of Julia, and print out a backtrace if (when) it segfaults.  You may need to hit \texttt{<enter>} a few times to get the full backtrace.  Create a \href{https://gist.github.com}{gist} with the backtrace, the \hyperlink{4601189142062189569}{version info}, and any other pertinent information you can think of and open a new \href{https://github.com/JuliaLang/julia/issues?q=is\%3Aopen}{issue} on Github with a link to the gist.



\hypertarget{17337880191991868567}{}


\subsection{Segfaults when running a script}



The procedure is very similar to \hyperlink{13671941627037387928}{Segfaults during bootstrap (\texttt{sysimg.jl})}.  Create a debug build of Julia, and run your script inside of a debugged Julia process:




\begin{lstlisting}
$ cd <julia_root>
$ make debug
$ gdb --args usr/bin/julia-debug <path_to_your_script>
\end{lstlisting}



Note that \texttt{gdb} will sit there, waiting for instructions.  Type \texttt{r} to run the process, and \texttt{bt} to generate a backtrace once it segfaults:




\begin{lstlisting}
(gdb) r
Starting program: /home/sabae/src/julia/usr/bin/julia-debug ./test.jl
...
(gdb) bt
\end{lstlisting}



Create a \href{https://gist.github.com}{gist} with the backtrace, the \hyperlink{4601189142062189569}{version info}, and any other pertinent information you can think of and open a new \href{https://github.com/JuliaLang/julia/issues?q=is\%3Aopen}{issue} on Github with a link to the gist.



\hypertarget{8599391806074935874}{}


\subsection{Errors during Julia startup}



Occasionally errors occur during Julia{\textquotesingle}s startup process (especially when using binary distributions, as opposed to compiling from source) such as the following:




\begin{minted}{julia}
$ julia
exec: error -5
\end{minted}



These errors typically indicate something is not getting loaded properly very early on in the bootup phase, and our best bet in determining what{\textquotesingle}s going wrong is to use external tools to audit the disk activity of the \texttt{julia} process:



\begin{itemize}
\item On Linux, use \texttt{strace}:


\begin{lstlisting}
$ strace julia
\end{lstlisting}


\item On OSX, use \texttt{dtruss}:


\begin{lstlisting}
$ dtruss -f julia
\end{lstlisting}

\end{itemize}


Create a \href{https://gist.github.com}{gist} with the \texttt{strace}/ \texttt{dtruss} output, the \hyperlink{4601189142062189569}{version info}, and any other pertinent information and open a new \href{https://github.com/JuliaLang/julia/issues?q=is\%3Aopen}{issue} on Github with a link to the gist.



\hypertarget{17259129457802099150}{}


\subsection{术语表}



A few terms have been used as shorthand in this guide:



\begin{itemize}
\item \texttt{<julia\_root>} refers to the root directory of the Julia source tree; e.g. it should contain folders such as \texttt{base}, \texttt{deps}, \texttt{src}, \texttt{test}, etc.....

\end{itemize}


\hypertarget{9756537906535455458}{}


\section{gdb 调试提示}



\hypertarget{12713077053871939955}{}


\subsection{显示 Julia 变量}



在 \texttt{gdb} 中, 任何 \texttt{jl\_value\_t*} 类型的变量 \texttt{obj} 的展示可以通过使用：




\begin{lstlisting}
(gdb) call jl_(obj)
\end{lstlisting}



这个对象会在 \texttt{julia} 会话中展示，而不是在 gdb 会话中。这是一种行之有效的方式来发现由 Julia 的 C 代码操控的对象的类型和值。



同样，如果你在调试一些 Julia 内部的东西 （比如 \texttt{compiler.jl} ），你可以通过使用这些来打印 \texttt{obj} ：




\begin{minted}{julia}
ccall(:jl_, Cvoid, (Any,), obj)
\end{minted}



这是一种很好的方法，可以避免 Julia 的输出流初始化顺序引起的问题。



Julia的 flisp 解释器使用 \texttt{value\_t} 对象；能够通过  \texttt{call fl\_print(fl\_ctx, ios\_stdout, obj)} 来展示。



\hypertarget{1284180401016634793}{}


\subsection{有用的用于检查的 Julia 变量}



While the addresses of many variables, like singletons, can be useful to print for many failures, there are a number of additional variables (see \texttt{julia.h} for a complete list) that are even more useful.



\begin{itemize}
\item (when in \texttt{jl\_apply\_generic}) \texttt{mfunc} and \texttt{jl\_uncompress\_ast(mfunc->def, mfunc->code)} :: for figuring out a bit about the call-stack


\item \texttt{jl\_lineno} and \texttt{jl\_filename} :: for figuring out what line in a test to go start debugging from (or figure out how far into a file has been parsed)


\item \texttt{\$1} :: not really a variable, but still a useful shorthand for referring to the result of the last gdb command (such as \texttt{print})


\item \texttt{jl\_options} :: sometimes useful, since it lists all of the command line options that were successfully parsed


\item \texttt{jl\_uv\_stderr} :: because who doesn{\textquotesingle}t like to be able to interact with stdio

\end{itemize}


\hypertarget{7178558395386377758}{}


\subsection{Useful Julia functions for Inspecting those variables}



\begin{itemize}
\item \texttt{jl\_gdblookup(\$rip)} :: For looking up the current function and line. (use \texttt{\$eip} on i686 platforms)


\item \texttt{jlbacktrace()} :: For dumping the current Julia backtrace stack to stderr. Only usable after \texttt{record\_backtrace()} has been called.


\item \texttt{jl\_dump\_llvm\_value(Value*)} :: For invoking \texttt{Value->dump()} in gdb, where it doesn{\textquotesingle}t work natively. For example, \texttt{f->linfo->functionObject}, \texttt{f->linfo->specFunctionObject}, and \texttt{to\_function(f->linfo)}.


\item \texttt{Type->dump()} :: only works in lldb. Note: add something like \texttt{;1} to prevent lldb from printing its prompt over the output


\item \texttt{jl\_eval\_string({\textquotedbl}expr{\textquotedbl})} :: for invoking side-effects to modify the current state or to lookup symbols


\item \texttt{jl\_typeof(jl\_value\_t*)} :: for extracting the type tag of a Julia value (in gdb, call \texttt{macro define jl\_typeof jl\_typeof} first, or pick something short like \texttt{ty} for the first arg to define a shorthand)

\end{itemize}


\hypertarget{1392415358123037898}{}


\subsection{Inserting breakpoints for inspection from gdb}



In your \texttt{gdb} session, set a breakpoint in \texttt{jl\_breakpoint} like so:




\begin{lstlisting}
(gdb) break jl_breakpoint
\end{lstlisting}



Then within your Julia code, insert a call to \texttt{jl\_breakpoint} by adding




\begin{minted}{julia}
ccall(:jl_breakpoint, Cvoid, (Any,), obj)
\end{minted}



where \texttt{obj} can be any variable or tuple you want to be accessible in the breakpoint.



It{\textquotesingle}s particularly helpful to back up to the \texttt{jl\_apply} frame, from which you can display the arguments to a function using, e.g.,




\begin{lstlisting}
(gdb) call jl_(args[0])
\end{lstlisting}



Another useful frame is \texttt{to\_function(jl\_method\_instance\_t *li, bool cstyle)}. The \texttt{jl\_method\_instance\_t*} argument is a struct with a reference to the final AST sent into the compiler. However, the AST at this point will usually be compressed; to view the AST, call \texttt{jl\_uncompress\_ast} and then pass the result to \texttt{jl\_}:




\begin{lstlisting}
#2  0x00007ffff7928bf7 in to_function (li=0x2812060, cstyle=false) at codegen.cpp:584
584          abort();
(gdb) p jl_(jl_uncompress_ast(li, li->ast))
\end{lstlisting}



\hypertarget{10952602490249170772}{}


\subsection{Inserting breakpoints upon certain conditions}



\hypertarget{796097711199942153}{}


\subsubsection{Loading a particular file}



Let{\textquotesingle}s say the file is \texttt{sysimg.jl}:




\begin{lstlisting}
(gdb) break jl_load if strcmp(fname, "sysimg.jl")==0
\end{lstlisting}



\hypertarget{11262037379695434792}{}


\subsubsection{Calling a particular method}




\begin{lstlisting}
(gdb) break jl_apply_generic if strcmp((char*)(jl_symbol_name)(jl_gf_mtable(F)->name), "method_to_break")==0
\end{lstlisting}



Since this function is used for every call, you will make everything 1000x slower if you do this.



\hypertarget{12553217263049394878}{}


\subsection{Dealing with signals}



Julia requires a few signal to function property. The profiler uses \texttt{SIGUSR2} for sampling and the garbage collector uses \texttt{SIGSEGV} for threads synchronization. If you are debugging some code that uses the profiler or multiple threads, you may want to let the debugger ignore these signals since they can be triggered very often during normal operations. The command to do this in GDB is (replace \texttt{SIGSEGV} with \texttt{SIGUSRS} or other signals you want to ignore):




\begin{lstlisting}
(gdb) handle SIGSEGV noprint nostop pass
\end{lstlisting}



The corresponding LLDB command is (after the process is started):




\begin{lstlisting}
(lldb) pro hand -p true -s false -n false SIGSEGV
\end{lstlisting}



If you are debugging a segfault with threaded code, you can set a breakpoint on \texttt{jl\_critical\_error} (\texttt{sigdie\_handler} should also work on Linux and BSD) in order to only catch the actual segfault rather than the GC synchronization points.



\hypertarget{8144212274800572894}{}


\subsection{Debugging during Julia{\textquotesingle}s build process (bootstrap)}



Errors that occur during \texttt{make} need special handling. Julia is built in two stages, constructing \texttt{sys0} and \texttt{sys.ji}. To see what commands are running at the time of failure, use \texttt{make VERBOSE=1}.



At the time of this writing, you can debug build errors during the \texttt{sys0} phase from the \texttt{base} directory using:




\begin{lstlisting}
julia/base$ gdb --args ../usr/bin/julia-debug -C native --build ../usr/lib/julia/sys0 sysimg.jl
\end{lstlisting}



You might need to delete all the files in \texttt{usr/lib/julia/} to get this to work.



You can debug the \texttt{sys.ji} phase using:




\begin{lstlisting}
julia/base$ gdb --args ../usr/bin/julia-debug -C native --build ../usr/lib/julia/sys -J ../usr/lib/julia/sys0.ji sysimg.jl
\end{lstlisting}



By default, any errors will cause Julia to exit, even under gdb. To catch an error {\textquotedbl}in the act{\textquotedbl}, set a breakpoint in \texttt{jl\_error} (there are several other useful spots, for specific kinds of failures, including: \texttt{jl\_too\_few\_args}, \texttt{jl\_too\_many\_args}, and \texttt{jl\_throw}).



Once an error is caught, a useful technique is to walk up the stack and examine the function by inspecting the related call to \texttt{jl\_apply}. To take a real-world example:




\begin{lstlisting}
Breakpoint 1, jl_throw (e=0x7ffdf42de400) at task.c:802
802 {
(gdb) p jl_(e)
ErrorException("auto_unbox: unable to determine argument type")
$2 = void
(gdb) bt 10
#0  jl_throw (e=0x7ffdf42de400) at task.c:802
#1  0x00007ffff65412fe in jl_error (str=0x7ffde56be000 <_j_str267> "auto_unbox:
   unable to determine argument type")
   at builtins.c:39
#2  0x00007ffde56bd01a in julia_convert_16886 ()
#3  0x00007ffff6541154 in jl_apply (f=0x7ffdf367f630, args=0x7fffffffc2b0, nargs=2) at julia.h:1281
...
\end{lstlisting}



The most recent \texttt{jl\_apply} is at frame \#3, so we can go back there and look at the AST for the function \texttt{julia\_convert\_16886}. This is the uniqued name for some method of \texttt{convert}. \texttt{f} in this frame is a \texttt{jl\_function\_t*}, so we can look at the type signature, if any, from the \texttt{specTypes} field:




\begin{lstlisting}
(gdb) f 3
#3  0x00007ffff6541154 in jl_apply (f=0x7ffdf367f630, args=0x7fffffffc2b0, nargs=2) at julia.h:1281
1281            return f->fptr((jl_value_t*)f, args, nargs);
(gdb) p f->linfo->specTypes
$4 = (jl_tupletype_t *) 0x7ffdf39b1030
(gdb) p jl_( f->linfo->specTypes )
Tuple{Type{Float32}, Float64}           # <-- type signature for julia_convert_16886
\end{lstlisting}



Then, we can look at the AST for this function:




\begin{lstlisting}
(gdb) p jl_( jl_uncompress_ast(f->linfo, f->linfo->ast) )
Expr(:lambda, Array{Any, 1}[:#s29, :x], Array{Any, 1}[Array{Any, 1}[], Array{Any, 1}[Array{Any, 1}[:#s29, :Any, 0], Array{Any, 1}[:x, :Any, 0]], Array{Any, 1}[], 0], Expr(:body,
Expr(:line, 90, :float.jl)::Any,
Expr(:return, Expr(:call, :box, :Float32, Expr(:call, :fptrunc, :Float32, :x)::Any)::Any)::Any)::Any)::Any
\end{lstlisting}



Finally, and perhaps most usefully, we can force the function to be recompiled in order to step through the codegen process. To do this, clear the cached \texttt{functionObject} from the \texttt{jl\_lamdbda\_info\_t*}:




\begin{lstlisting}
(gdb) p f->linfo->functionObject
$8 = (void *) 0x1289d070
(gdb) set f->linfo->functionObject = NULL
\end{lstlisting}



Then, set a breakpoint somewhere useful (e.g. \texttt{emit\_function}, \texttt{emit\_expr}, \texttt{emit\_call}, etc.), and run codegen:




\begin{lstlisting}
(gdb) p jl_compile(f)
... # your breakpoint here
\end{lstlisting}



\hypertarget{15283936980874101721}{}


\subsection{Debugging precompilation errors}



Module precompilation spawns a separate Julia process to precompile each module. Setting a breakpoint or catching failures in a precompile worker requires attaching a debugger to the worker. The easiest approach is to set the debugger watch for new process launches matching a given name. For example:




\begin{lstlisting}
(gdb) attach -w -n julia-debug
\end{lstlisting}



or:




\begin{lstlisting}
(lldb) process attach -w -n julia-debug
\end{lstlisting}



Then run a script/command to start precompilation. As described earlier, use conditional breakpoints in the parent process to catch specific file-loading events and narrow the debugging window. (some operating systems may require alternative approaches, such as following each \texttt{fork} from the parent process)



\hypertarget{2874239207045478266}{}


\subsection{Mozilla{\textquotesingle}s Record and Replay Framework (rr)}



Julia now works out of the box with \href{http://rr-project.org/}{rr}, the lightweight recording and deterministic debugging framework from Mozilla. This allows you to replay the trace of an execution deterministically.  The replayed execution{\textquotesingle}s address spaces, register contents, syscall data etc are exactly the same in every run.



A recent version of rr (3.1.0 or higher) is required.



\hypertarget{8199500901675456324}{}


\subsubsection{Reproducing concurrency bugs with rr}



rr simulates a single-threaded machine by default. In order to debug concurrent code you can use \texttt{rr record --chaos} which will cause rr to simulate between one to eight cores, chosen randomly. You might therefore want to set \texttt{JULIA\_NUM\_THREADS=8} and rerun your code under rr until you have caught your bug.



\hypertarget{1705795605392310931}{}


\section{在Julia中使用Valgrind}



\href{http://valgrind.org/}{Valgrind} is a tool for memory debugging, memory leak detection, and profiling.  This section describes things to keep in mind when using Valgrind to debug memory issues with Julia.



\hypertarget{527857279218691176}{}


\subsection{General considerations}



By default, Valgrind assumes that there is no self modifying code in the programs it runs.  This assumption works fine in most instances but fails miserably for a just-in-time compiler like \texttt{julia}.  For this reason it is crucial to pass \texttt{--smc-check=all-non-file} to \texttt{valgrind}, else code may crash or behave unexpectedly (often in subtle ways).



In some cases, to better detect memory errors using Valgrind it can help to compile \texttt{julia} with memory pools disabled.  The compile-time flag \texttt{MEMDEBUG} disables memory pools in Julia, and \texttt{MEMDEBUG2} disables memory pools in FemtoLisp.  To build \texttt{julia} with both flags, add the following line to \texttt{Make.user}:




\begin{minted}{julia}
CFLAGS = -DMEMDEBUG -DMEMDEBUG2
\end{minted}



Another thing to note: if your program uses multiple workers processes, it is likely that you want all such worker processes to run under Valgrind, not just the parent process.  To do this, pass \texttt{--trace-children=yes} to \texttt{valgrind}.



\hypertarget{9183907630008953484}{}


\subsection{Suppressions}



Valgrind will typically display spurious warnings as it runs.  To reduce the number of such warnings, it helps to provide a \href{http://valgrind.org/docs/manual/manual-core.html\#manual-core.suppress}{suppressions file} to Valgrind.  A sample suppressions file is included in the Julia source distribution at \texttt{contrib/valgrind-julia.supp}.



The suppressions file can be used from the \texttt{julia/} source directory as follows:




\begin{lstlisting}
$ valgrind --smc-check=all-non-file --suppressions=contrib/valgrind-julia.supp ./julia progname.jl
\end{lstlisting}



Any memory errors that are displayed should either be reported as bugs or contributed as additional suppressions.  Note that some versions of Valgrind are \href{https://github.com/JuliaLang/julia/issues/8314\#issuecomment-55766210}{shipped with insufficient default suppressions}, so that may be one thing to consider before submitting any bugs.



\hypertarget{10173787738831416739}{}


\subsection{Running the Julia test suite under Valgrind}



It is possible to run the entire Julia test suite under Valgrind, but it does take quite some time (typically several hours).  To do so, run the following command from the \texttt{julia/test/} directory:




\begin{lstlisting}
valgrind --smc-check=all-non-file --trace-children=yes --suppressions=$PWD/../contrib/valgrind-julia.supp ../julia runtests.jl all
\end{lstlisting}



If you would like to see a report of {\textquotedbl}definite{\textquotedbl} memory leaks, pass the flags \texttt{--leak-check=full --show-leak-kinds=definite} to \texttt{valgrind} as well.



\hypertarget{11463604234155946056}{}


\subsection{Caveats}



Valgrind currently \href{https://bugs.kde.org/show\_bug.cgi?id=136779}{does not support multiple rounding modes}, so code that adjusts the rounding mode will behave differently when run under Valgrind.



In general, if after setting \texttt{--smc-check=all-non-file} you find that your program behaves differently when run under Valgrind, it may help to pass \texttt{--tool=none} to \texttt{valgrind} as you investigate further.  This will enable the minimal Valgrind machinery but will also run much faster than when the full memory checker is enabled.



\hypertarget{7868060637958278195}{}


\section{Sanitizer support}



\hypertarget{527857279218691176}{}


\subsection{General considerations}



Using Clang{\textquotesingle}s sanitizers obviously require you to use Clang (\texttt{USECLANG=1}), but there{\textquotesingle}s another catch: most sanitizers require a run-time library, provided by the host compiler, while the instrumented code generated by Julia{\textquotesingle}s JIT relies on functionality from that library. This implies that the LLVM version of your host compiler matches that of the LLVM library used within Julia.



An easy solution is to have an dedicated build folder for providing a matching toolchain, by building with \texttt{BUILD\_LLVM\_CLANG=1}. You can then refer to this toolchain from another build folder by specifying \texttt{USECLANG=1} while overriding the \texttt{CC} and \texttt{CXX} variables.



\hypertarget{1061650975116506198}{}


\subsection{Address Sanitizer (ASAN)}



For detecting or debugging memory bugs, you can use Clang{\textquotesingle}s \href{http://clang.llvm.org/docs/AddressSanitizer.html}{address sanitizer (ASAN)}. By compiling with \texttt{SANITIZE=1} you enable ASAN for the Julia compiler and its generated code. In addition, you can specify \texttt{LLVM\_SANITIZE=1} to sanitize the LLVM library as well. Note that these options incur a high performance and memory cost. For example, using ASAN for Julia and LLVM makes \texttt{testall1} takes 8-10 times as long while using 20 times as much memory (this can be reduced to respectively a factor of 3 and 4 by using the options described below).



By default, Julia sets the \texttt{allow\_user\_segv\_handler=1} ASAN flag, which is required for signal delivery to work properly. You can define other options using the \texttt{ASAN\_OPTIONS} environment flag, in which case you{\textquotesingle}ll need to repeat the default option mentioned before. For example, memory usage can be reduced by specifying \texttt{fast\_unwind\_on\_malloc=0} and \texttt{malloc\_context\_size=2}, at the cost of backtrace accuracy. For now, Julia also sets \texttt{detect\_leaks=0}, but this should be removed in the future.



\hypertarget{11752764117060042950}{}


\subsection{Memory Sanitizer (MSAN)}



For detecting use of uninitialized memory, you can use Clang{\textquotesingle}s \href{http://clang.llvm.org/docs/MemorySanitizer.html}{memory sanitizer (MSAN)} by compiling with \texttt{SANITIZE\_MEMORY=1}.
